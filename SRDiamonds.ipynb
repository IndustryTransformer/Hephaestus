{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "carat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cut",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "color",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "depth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "table",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "395eef60-2c3d-4a5d-907c-4868e5f03839",
       "rows": [
        [
         "0",
         "0.23",
         "Ideal",
         "E",
         "SI2",
         "61.5",
         "55.0",
         "326",
         "3.95",
         "3.98",
         "2.43"
        ],
        [
         "1",
         "0.21",
         "Premium",
         "E",
         "SI1",
         "59.8",
         "61.0",
         "326",
         "3.89",
         "3.84",
         "2.31"
        ],
        [
         "2",
         "0.23",
         "Good",
         "E",
         "VS1",
         "56.9",
         "65.0",
         "327",
         "4.05",
         "4.07",
         "2.31"
        ],
        [
         "3",
         "0.29",
         "Premium",
         "I",
         "VS2",
         "62.4",
         "58.0",
         "334",
         "4.2",
         "4.23",
         "2.63"
        ],
        [
         "4",
         "0.31",
         "Good",
         "J",
         "SI2",
         "63.3",
         "58.0",
         "335",
         "4.34",
         "4.35",
         "2.75"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  target     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0     326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0     326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0     327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0     334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0     335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pytorch_lightning as L\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import hephaestus.single_row_models as sr\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# Load and preprocess the dataset (assuming you have a CSV file)\n",
    "df = pd.read_csv(\"./data/diamonds.csv\")\n",
    "df = df.rename(columns={\"price\": \"target\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "color",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a4b13072-5412-4baa-9d9d-ba41d4b4a884",
       "rows": [
        [
         "0",
         "E"
        ],
        [
         "1",
         "E"
        ],
        [
         "2",
         "E"
        ],
        [
         "3",
         "I"
        ],
        [
         "4",
         "J"
        ],
        [
         "5",
         "J"
        ],
        [
         "6",
         "I"
        ],
        [
         "7",
         "H"
        ],
        [
         "8",
         "E"
        ],
        [
         "9",
         "H"
        ],
        [
         "10",
         "J"
        ],
        [
         "11",
         "J"
        ],
        [
         "12",
         "F"
        ],
        [
         "13",
         "J"
        ],
        [
         "14",
         "E"
        ],
        [
         "15",
         "E"
        ],
        [
         "16",
         "I"
        ],
        [
         "17",
         "J"
        ],
        [
         "18",
         "J"
        ],
        [
         "19",
         "J"
        ],
        [
         "20",
         "I"
        ],
        [
         "21",
         "E"
        ],
        [
         "22",
         "H"
        ],
        [
         "23",
         "J"
        ],
        [
         "24",
         "J"
        ],
        [
         "25",
         "G"
        ],
        [
         "26",
         "I"
        ],
        [
         "27",
         "J"
        ],
        [
         "28",
         "D"
        ],
        [
         "29",
         "F"
        ],
        [
         "30",
         "F"
        ],
        [
         "31",
         "F"
        ],
        [
         "32",
         "E"
        ],
        [
         "33",
         "E"
        ],
        [
         "34",
         "D"
        ],
        [
         "35",
         "F"
        ],
        [
         "36",
         "E"
        ],
        [
         "37",
         "H"
        ],
        [
         "38",
         "D"
        ],
        [
         "39",
         "I"
        ],
        [
         "40",
         "I"
        ],
        [
         "41",
         "J"
        ],
        [
         "42",
         "D"
        ],
        [
         "43",
         "D"
        ],
        [
         "44",
         "H"
        ],
        [
         "45",
         "F"
        ],
        [
         "46",
         "H"
        ],
        [
         "47",
         "H"
        ],
        [
         "48",
         "E"
        ],
        [
         "49",
         "H"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 53940
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      color\n",
       "0         E\n",
       "1         E\n",
       "2         E\n",
       "3         I\n",
       "4         J\n",
       "...     ...\n",
       "53935     D\n",
       "53936     D\n",
       "53937     D\n",
       "53938     H\n",
       "53939     D\n",
       "\n",
       "[53940 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.loc[:, \"color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleRowConfig(numeric_token='[NUMERIC_EMBEDDING]', numeric_mask='[NUMERIC_MASK]', numeric_col_tokens=['carat', 'depth', 'table', 'x', 'y', 'z'], categorical_col_tokens=['cut', 'color', 'clarity'], tokens=['[PAD]', '[NUMERIC_MASK]', '[MASK]', '[UNK]', '[NUMERIC_EMBEDDING]', 'carat', 'depth', 'table', 'x', 'y', 'z', 'I1', 'SI2', 'F', 'G', 'VS1', 'D', 'IF', 'I', 'H', 'Very Good', 'VVS1', 'Fair', 'E', 'J', 'Ideal', 'VS2', 'SI1', 'Premium', 'Good', 'VVS2', 'cut', 'color', 'clarity'], token_dict={'[PAD]': 0, '[NUMERIC_MASK]': 1, '[MASK]': 2, '[UNK]': 3, '[NUMERIC_EMBEDDING]': 4, 'carat': 5, 'depth': 6, 'table': 7, 'x': 8, 'y': 9, 'z': 10, 'I1': 11, 'SI2': 12, 'F': 13, 'G': 14, 'VS1': 15, 'D': 16, 'IF': 17, 'I': 18, 'H': 19, 'Very Good': 20, 'VVS1': 21, 'Fair': 22, 'E': 23, 'J': 24, 'Ideal': 25, 'VS2': 26, 'SI1': 27, 'Premium': 28, 'Good': 29, 'VVS2': 30, 'cut': 31, 'color': 32, 'clarity': 33}, token_decoder_dict={0: '[PAD]', 1: '[NUMERIC_MASK]', 2: '[MASK]', 3: '[UNK]', 4: '[NUMERIC_EMBEDDING]', 5: 'carat', 6: 'depth', 7: 'table', 8: 'x', 9: 'y', 10: 'z', 11: 'I1', 12: 'SI2', 13: 'F', 14: 'G', 15: 'VS1', 16: 'D', 17: 'IF', 18: 'I', 19: 'H', 20: 'Very Good', 21: 'VVS1', 22: 'Fair', 23: 'E', 24: 'J', 25: 'Ideal', 26: 'VS2', 27: 'SI1', 28: 'Premium', 29: 'Good', 30: 'VVS2', 31: 'cut', 32: 'color', 33: 'clarity'}, n_tokens=34, numeric_indices=tensor([ 5,  6,  7,  8,  9, 10]), categorical_indices=tensor([31, 32, 33]), object_tokens=['I1', 'SI2', 'F', 'G', 'VS1', 'D', 'IF', 'I', 'H', 'Very Good', 'VVS1', 'Fair', 'E', 'J', 'Ideal', 'VS2', 'SI1', 'Premium', 'Good', 'VVS2'], numeric_mask_token=1, reservoir_vocab=['[PAD]', '[NUMERIC_MASK]', 'carat', '2', 'SI', '[MASK]', 'cut', 'F', 'G', '1', 'D', 'Very', '[NUMERIC_EMBEDDING]', 'IF', 'I', 'depth', 'H', 'x', '[UNK]', 'Fair', 'color', 'VS', 'VVS', 'E', 'J', 'z', 'Ideal', 'clarity', 'y', 'table', 'Good', 'Premium'], reservoir_encoded=tensor([[    0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1031, 16371, 25531,  1035,  7308,  1033,     0,     0],\n",
       "        [  103,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  100,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1031, 16371, 25531,  1035,  7861,  8270,  4667,  1033],\n",
       "        [14418,  2102,     0,     0,     0,     0,     0,     0],\n",
       "        [ 5995,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 2795,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1060,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1061,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1062,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1045,  2487,     0,     0,     0,     0,     0,     0],\n",
       "        [ 9033,  2475,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1042,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1043,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 5443,  2487,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1040,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 2065,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1045,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1044,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 2200,  2204,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1058, 15088,  2487,     0,     0,     0,     0,     0],\n",
       "        [ 4189,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1041,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1046,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 7812,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 5443,  2475,     0,     0,     0,     0,     0,     0],\n",
       "        [ 9033,  2487,     0,     0,     0,     0,     0,     0],\n",
       "        [12882,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 2204,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1058, 15088,  2475,     0,     0,     0,     0,     0],\n",
       "        [ 3013,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 3609,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [15563,     0,     0,     0,     0,     0,     0,     0]]), tokenizer=BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, vocab_size=30522, n_columns=10, target='target')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_row_config = sr.SingleRowConfig.generate(df, \"target\")\n",
    "single_row_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'target', 'x',\n",
      "       'y', 'z'],\n",
      "      dtype='object')\n",
      "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'target', 'x',\n",
      "       'y', 'z'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "dataset = sr.TabularDS(df, single_row_config)\n",
    "model = sr.TabularRegressor(single_row_config, d_model=64, n_heads=4)\n",
    "res = model.forward(dataset[0])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "# train_df, test_df = train_test_split(df.copy(), test_size=0.2, random_state=42)\n",
    "train_df, test_df = train_test_split(df.copy(), test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = sr.TabularDS(train_df, single_row_config)\n",
    "test_dataset = sr.TabularDS(test_df, single_row_config)\n",
    "model.forward(train_dataset[0])\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    collate_fn=sr.training.tabular_collate_fn,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    collate_fn=sr.training.tabular_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = sr.TabularRegressor(single_row_config, d_model=64, n_heads=4)\n",
    "out = model.forward(dataset[5])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.forward(dataset[0:3])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat         0.29\n",
       "cut        Premium\n",
       "color            I\n",
       "clarity        VS2\n",
       "depth         62.4\n",
       "table         58.0\n",
       "target         334\n",
       "x              4.2\n",
       "y             4.23\n",
       "z             2.63\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader) * 20 - 43152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43152"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53940"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch type: <class 'hephaestus.single_row_models.model_data_classes.InputsTarget'>\n"
     ]
    }
   ],
   "source": [
    "# Get a batch from the training dataloader\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Print the batch information\n",
    "print(f\"Sample batch type: {type(sample_batch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 6]), torch.Size([20, 3]), torch.Size([20, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    sample_batch.inputs.numeric.shape,\n",
    "    sample_batch.inputs.categorical.shape,\n",
    "    sample_batch.target.shape,\n",
    ")  # (torch.Size([20, 6]), torch.Size([20, 3]), torch.Size([20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch.target.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 6])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0:20].inputs.numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat.shape=torch.Size([20, 1]), y.shape=torch.Size([20]), y_hat=tensor([[-0.7224],\n",
      "        [-0.7166],\n",
      "        [-0.7674],\n",
      "        [-0.5791],\n",
      "        [-0.7364],\n",
      "        [-0.8030],\n",
      "        [-0.7878],\n",
      "        [-0.7357],\n",
      "        [-0.7957],\n",
      "        [-0.5834],\n",
      "        [-0.8361],\n",
      "        [-0.7527],\n",
      "        [-0.7450],\n",
      "        [-0.7577],\n",
      "        [-0.6195],\n",
      "        [-0.8393],\n",
      "        [-0.8241],\n",
      "        [-0.7139],\n",
      "        [-0.8273],\n",
      "        [-0.7331]], grad_fn=<AddmmBackward0>), y=tensor([  907.,  4688.,  9139.,   622., 10396.,   729.,  1656.,  8849.,  2964.,\n",
      "        16688.,   666.,   945.,  1196.,  2723., 10536.,  9789.,  8455.,  1035.,\n",
      "         8758.,  2401.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kailukowiak/Hephaestus/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kailukowiak/Hephaestus/.venv/lib/python3.13/site-packages/pytorch_lightning/core/module.py:441: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    }
   ],
   "source": [
    "x = model.training_step(sample_batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47791540., grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                    | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | model   | TabularEncoderRegressor | 229 K  | train\n",
      "1 | loss_fn | MSELoss                 | 0      | train\n",
      "------------------------------------------------------------\n",
      "229 K     Trainable params\n",
      "0         Non-trainable params\n",
      "229 K     Total params\n",
      "0.916     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850d0736bfe04451b4329c6fe85890eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kailukowiak/Hephaestus/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kailukowiak/Hephaestus/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cd341250564456bd12dcf15b408184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[-0.8191]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(16231., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[1.2027]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4540., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[2.6923]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5729., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[3.9626]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6300., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[5.0616]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(12968., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[6.2724]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2167., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[7.1961]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1041., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[8.1231]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1607., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[8.7644]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5008., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[9.8838]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3197., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[10.6420]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1060., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[11.6645]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4044., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[12.6774]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5260., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[13.7657]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6129., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[14.9768]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1079., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[16.1660]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1664., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[17.3345]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(13464., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[18.7592]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(12336., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[20.2281]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(722., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[21.6934]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3059., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[22.9271]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(438., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[24.1808]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1400., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[25.3667]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3669., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[26.6441]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3494., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[28.0089]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1867., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[29.3407]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1439., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[30.6590]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(8758., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[32.2645]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(13499., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[34.1753]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1053., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[35.9484]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(596., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[37.5519]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1886., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[39.0777]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(628., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[40.5789]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3103., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[42.0550]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(18342., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[44.0812]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4193., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[46.0472]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6622., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[48.0967]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(926., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[49.9900]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(544., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[51.7301]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4126., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[53.5735]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1084., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[55.2994]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(872., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[56.9526]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(9346., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[59.0225]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2051., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[60.9701]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1084., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[62.7932]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1207., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[64.5238]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4039., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[66.3430]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2782., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[68.2186]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(614., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[69.9865]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4998., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[71.9791]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1643., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[73.8952]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3160., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[75.8998]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(8637., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[78.2474]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1927., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[80.5322]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(872., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[82.6846]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(713., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[84.6563]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(536., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[86.5877]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3171., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[88.5411]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3492., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[90.7793]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(11175., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[93.5390]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6740., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[96.5143]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6377., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[99.6849]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4704., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[102.9323]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6640., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[106.2964]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(8564., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[110.2235]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(936., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[113.7961]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(11079., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[117.7667]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(625., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[121.4371]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1709., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[125.0175]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2346., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[128.4396]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1402., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[131.7859]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4186., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[135.3798]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5131., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[139.1750]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1424., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[142.7798]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1125., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[146.1981]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1125., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[149.4591]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2274., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[152.7033]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(998., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[155.7503]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(16064., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[159.9892]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2109., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[164.0011]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3311., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[167.9489]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5259., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[172.1647]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1163., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[176.2293]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(7836., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[180.9048]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1609., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[185.3440]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(541., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[189.4298]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(805., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[193.2678]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(957., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[196.8532]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1343., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[200.3140]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2693., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[203.9175]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(895., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[207.2444]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2691., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[210.8134]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(720., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[214.0835]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1279., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[217.3181]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(594., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[220.3176]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(732., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[223.1246]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(12576., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[227.3282]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(15688., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[233.0482]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(842., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[238.2276]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3053., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[243.2983]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1602., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[248.2463]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2913., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[253.3353]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(827., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[258.1256]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(734., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[262.5746]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(7972., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[268.0547]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2147., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[273.2753]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5631., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[278.8669]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(707., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[283.9313]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3774., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[289.3092]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(789., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[294.3153]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2801., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[299.4927]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(17182., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[306.8053]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1028., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[313.2076]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(540., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[318.8304]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(616., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[323.7750]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(11649., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[331.2132]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1243., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[338.0797]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(7500., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[345.5977]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2496., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[352.6898]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(965., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[359.0636]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(734., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[364.8486]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6712., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[371.7483]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5939., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[379.4118]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6098., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[387.6708]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1187., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[395.2005]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(6363., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[403.2935]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(780., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[410.6482]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(8528., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[419.3510]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1150., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[427.4732]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2030., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[435.3141]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1151., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[442.6461]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5028., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[450.5938]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3248., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[458.5876]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2042., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[466.3362]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2889., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[474.0651]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(625., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[481.1367]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(571., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[487.5714]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(3403., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[494.4139]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1778., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[501.0594]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5123., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[508.5814]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5754., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[517.0405]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(819., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[524.8049]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2174., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[532.4029]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(12121., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[542.5292]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(487., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[551.7392]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1151., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[560.3284]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1112., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[568.3458]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1787., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[576.0911]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(558., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[583.1525]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(9576., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[592.5499]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1133., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[601.2305]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4067., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[610.3313]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1155., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[618.8281]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(851., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[626.5521]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(362., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[633.5770]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(702., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[639.9023]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(9419., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[649.2734]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5597., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[659.3786]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5228., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[670.0322]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1415., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[679.9243]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(2303., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[689.6828]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1872., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[699.1953]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(5814., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[710.4427]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(10011., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[723.9296]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(803., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[735.4255]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(4740., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[747.6616]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(1270., device='mps:0')\n",
      "y_hat.shape=torch.Size([1, 1]), y.shape=torch.Size([]), y_hat=tensor([[758.9805]], device='mps:0', grad_fn=<LinearBackward0>), y=tensor(730., device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"runs\", name=f\"{dt.now()}_tabular_encoder_regressor\")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "trainer = L.Trainer(max_epochs=6, logger=logger, callbacks=[early_stopping])\n",
    "trainer.fit(model, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 0  # Stop here to avoid running the rest of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hlskdafjsdal\" + \"SDFSDFSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sr.TabTransformer(dataset, n_heads=8).to(dataset.device)\n",
    "\n",
    "batch_size = 3\n",
    "test_num = dataset.X_train_numeric[0:batch_size, :]\n",
    "test_num_mask = sr.mask_tensor(test_num, model)\n",
    "test_cat = dataset.X_test_categorical[0:batch_size, :]\n",
    "test_cat_mask = sr.mask_tensor(test_cat, model)\n",
    "with torch.no_grad():\n",
    "    x = model(\n",
    "        test_num_mask,\n",
    "        test_cat_mask,\n",
    "        task=\"mlm\",\n",
    "    )\n",
    "x[0].shape, x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr.show_mask_pred(0, model, dataset, probability=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked Tabular Modeling\n",
    "base_model_name = \"is_model_global2\"\n",
    "\n",
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = f\"{base_model_name}_{model_time}\"\n",
    "\n",
    "model_save_path = \"./checkpoints/mtm_models_small.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = os.listdir(\"./checkpoints\")\n",
    "if model_save_path.split(\"/\")[-1] in model_list:\n",
    "    print(\"Model already exists\")\n",
    "    model_exists = True\n",
    "else:\n",
    "    print(\"Model does not exist\")\n",
    "    model_exists = False\n",
    "\n",
    "if model_exists:\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "else:\n",
    "    sr.mtm(model, dataset, model_name, epochs=100, batch_size=1000, lr=0.001)\n",
    "    torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regression_performance = sr.fine_tune_model(\n",
    "#     model, dataset, model_name=\"FT100\", n_rows=100, epochs=100\n",
    "# )\n",
    "# regression_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_rows = [\n",
    "    # 10,\n",
    "    100,\n",
    "    1_000,\n",
    "    2_000,\n",
    "    5_000,\n",
    "    10_000,\n",
    "    15_000,\n",
    "    30_000,\n",
    "    # 40_000,\n",
    "    dataset.X_train.shape[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_sizes(pt_model_path, dataset, n_train_rows, n_epochs=100):\n",
    "    model = sr.TabTransformer(dataset, n_heads=8).to(dataset.device)\n",
    "    if pt_model_path is not None:\n",
    "        model.load_state_dict(torch.load(pt_model_path))\n",
    "\n",
    "    regression_performance = sr.fine_tune_model(\n",
    "        model,\n",
    "        dataset,\n",
    "        model_name=f\"ft_{n_train_rows}\",\n",
    "        n_rows=n_train_rows,\n",
    "        epochs=n_epochs,\n",
    "    )\n",
    "\n",
    "    return regression_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hephaestus_results_no_pre_train = []\n",
    "pbar = tqdm(n_train_rows)\n",
    "for i in pbar:\n",
    "    pbar.set_description(f\"n_rows: {i}\")\n",
    "    loss = train_multiple_sizes(None, dataset, i, n_epochs=250)\n",
    "    hephaestus_results_no_pre_train.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pt_df = pd.DataFrame(hephaestus_results_no_pre_train)\n",
    "no_pt_df[\"model\"] = \"Hephaestus No Fine Tune\"\n",
    "no_pt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hephaestus_results = []\n",
    "pbar = tqdm(n_train_rows)\n",
    "for i in pbar:\n",
    "    pbar.set_description(f\"n_rows: {i}\")\n",
    "    loss = train_multiple_sizes(model_save_path, dataset, i, n_epochs=250)\n",
    "    hephaestus_results.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hephaestus_df = pd.DataFrame(hephaestus_results)\n",
    "hephaestus_df[\"model\"] = \"Hephaestus\"\n",
    "hephaestus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hephaestus_df.loc[hephaestus_df.n_rows == 1000, \"test_loss\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data = pd.read_csv(\"./data/diamonds.csv\")\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "label_encoders = {}\n",
    "categorical_features = [\"cut\", \"color\", \"clarity\"]\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    diamonds_data[feature] = le.fit_transform(diamonds_data[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = diamonds_data.drop(\"price\", axis=1)\n",
    "y = diamonds_data[\"price\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train the XGBoost regressor\n",
    "xgb_regressor = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_regressor.fit(\n",
    "    X_train[0:batch_size],\n",
    "    y_train[0:batch_size],\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:,.2f}\")\n",
    "\n",
    "# You can also access feature importance scores\n",
    "# feature_importances = xgb_regressor.feature_importances_\n",
    "# print(\"Feature Importance:\")\n",
    "# for feature, importance in zip(X.columns, feature_importances):\n",
    "#     print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_tester(train_set_size):\n",
    "    xgb_regressor = XGBRegressor(n_estimators=120, learning_rate=0.1, random_state=42)\n",
    "    xgb_regressor.fit(\n",
    "        X_train[0:train_set_size],\n",
    "        y_train[0:train_set_size],\n",
    "    )\n",
    "\n",
    "    y_pred = xgb_regressor.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return {\"n_rows\": train_set_size, \"test_loss\": mse}\n",
    "\n",
    "\n",
    "xgb_losses = []\n",
    "for i in tqdm(n_train_rows):\n",
    "    mse = xgb_tester(i)\n",
    "    xgb_losses.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df = pd.DataFrame(xgb_losses)\n",
    "xgb_df[\"model\"] = \"XGBoost\"\n",
    "\n",
    "xgb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.concat([hephaestus_df, xgb_df, no_pt_df])  # , no_pt_df\n",
    "loss_df = loss_df.loc[loss_df[\"n_rows\"] != 10]\n",
    "loss_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colors for each model\n",
    "# colors = {\"Hephaestus\": \"blue\", \"XGBoost\": \"red\"}\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Loop through each model and plot the test loss as a line\n",
    "for model, group in loss_df.groupby(\"model\"):\n",
    "    ax.plot(group[\"n_rows\"], group[\"test_loss\"], label=model)\n",
    "\n",
    "# Set the axis labels and legend\n",
    "ax.set_xlabel(\"Number of Rows\")\n",
    "ax.set_ylabel(\"Test Loss\")\n",
    "ax.legend()\n",
    "# set x axis to log scale\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colors for each model\n",
    "# colors = {\"Hephaestus\": \"blue\", \"XGBoost\": \"red\"}\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Loop through each model and plot the test loss as a line\n",
    "for model, group in loss_df.loc[loss_df[\"model\"] != \"Hephaestus No Fine Tune\"].groupby(\n",
    "    \"model\"\n",
    "):\n",
    "    ax.plot(group[\"n_rows\"], group[\"test_loss\"], label=model)\n",
    "\n",
    "# Set the axis labels and legend\n",
    "ax.set_xlabel(\"Number of Rows\")\n",
    "ax.set_ylabel(\"Test Loss\")\n",
    "ax.legend()\n",
    "# set x axis to log scale\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spread the data to have columns for the loss of each model\n",
    "# loss_df =\n",
    "loss_percent_df = loss_df.pivot(\n",
    "    index=\"n_rows\", columns=\"model\", values=\"test_loss\"\n",
    ").reset_index()\n",
    "loss_percent_df[\"percent_improvement\"] = (\n",
    "    loss_percent_df[\"XGBoost\"] - loss_percent_df[\"Hephaestus\"]\n",
    ") / loss_percent_df[\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=loss_percent_df, x=\"n_rows\", y=\"percent_improvement\")\n",
    "plt.axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "ax.set_yticks(loss_percent_df[\"percent_improvement\"].round(2))\n",
    "ax.set_xticks(loss_percent_df[\"n_rows\"])\n",
    "# ax.set_xscale(\"log\")\n",
    "# X lables at 45 degree angle\n",
    "plt.xticks(rotation=45)\n",
    "# plt.xlabel"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "lcc_arn": "arn:aws:sagemaker:us-west-2:385115691352:studio-lifecycle-config/base-installs-widgets",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
