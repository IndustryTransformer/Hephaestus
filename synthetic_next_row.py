# %% [markdown]
# # Synthetic Data Next Row Prediction
#
# This script performs next row predictions on the dataset generated by
# big_synthetic_generator.py
#

# %%
import os
from datetime import datetime as dt

import icecream
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pytorch_lightning as L
import torch
from icecream import ic
from pytorch_lightning.callbacks import EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.utils.data import DataLoader

import hephaestus as hp
from hephaestus.timeseries_models import tabular_collate_fn

# %%
torch.set_default_dtype(torch.float32)
torch.set_float32_matmul_precision("medium")

# %%
icecream.install()
ic_disable = True  # Global variable to disable ic
if ic_disable:
    ic.disable()
ic.configureOutput(includeContext=True, contextAbsPath=True)
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# %%
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")  # type: ignore
    print(f"GPU device: {torch.cuda.get_device_name(0)}")
elif torch.backends.mps.is_available():
    print("MPS available")
else:
    print("CUDA not available. Checking why...")
    import os

    print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}")

# %% [markdown]
# ## Load or Generate Synthetic Data
#

# %%
# Check if dataset exists, otherwise generate it
data_file = "data/big_synthetic_dataset_10000groups.parquet"
if not os.path.exists(data_file):
    print("Dataset not found. Generating...")
    from big_synthetic_generator import BigSyntheticDataset

    generator = BigSyntheticDataset(
        n_groups=10000,
        group_size=128,
        random_seed=42,
    )
    df = generator.generate_dataset()
    generator.save_dataset(df)
else:
    print(f"Loading existing dataset from {data_file}")
    df = pd.read_parquet(data_file)

print(f"Dataset shape: {df.shape}")
print("Columns:", df.columns.tolist())

# %%
df.head()

# %%
df.describe()

# %%
# Check categorical columns
categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()
print(f"Categorical columns: {categorical_cols}")
for col in categorical_cols:
    print(f"{col}: {df[col].unique()}")

# %%
# Filter to only use specified feature columns
feature_columns = [
    "idx",  # Keep idx for grouping
    "row_in_group",
    "sin_wave",
    "cos_wave",
    "fizzbuzz",
    "random_int",
    "lagged_mult",
]

df = df[feature_columns].copy()
print("Filtered to feature columns:", feature_columns)

# Scale numeric columns (excluding lagged_mult to preserve deterministic relationship)
numeric_columns = ["sin_wave", "cos_wave", "random_int"]  # Removed lagged_mult

for col in numeric_columns:
    if col in df.columns:
        # Use robust scaling to handle outliers and NaN values
        non_nan_values = df[col].dropna()
        if len(non_nan_values) > 0:
            median = non_nan_values.median()
            mad = (non_nan_values - median).abs().median()
            if mad > 0:
                df[col] = (df[col] - median) / mad
            else:
                # Fallback to standard scaling if MAD is 0
                mean = non_nan_values.mean()
                std = non_nan_values.std()
                if std > 0:
                    df[col] = (df[col] - mean) / std

# Scale lagged_mult separately to preserve its relationship with random_int
if "lagged_mult" in df.columns:
    # Simple min-max scaling to keep the 2.5x relationship visible
    non_nan_values = df["lagged_mult"].dropna()
    if len(non_nan_values) > 0:
        min_val = non_nan_values.min()
        max_val = non_nan_values.max()
        if max_val > min_val:
            df["lagged_mult"] = (df["lagged_mult"] - min_val) / (max_val - min_val)

print("Numeric columns scaled (lagged_mult uses min-max to preserve patterns)")

# %%
# Get train test split at 80/20 by idx
time_series_config = hp.TimeSeriesConfig.generate(df=df)
train_idx = int(df.idx.max() * 0.8)
train_df = df.loc[df.idx < train_idx].copy()
test_df = df.loc[df.idx >= train_idx].copy()

train_ds = hp.TimeSeriesDS(train_df, time_series_config)
test_ds = hp.TimeSeriesDS(test_df, time_series_config)
print(f"Train size: {len(train_ds)}, Test size: {len(test_ds)}")

# %%
# Configure model with custom learning rate
N_HEADS = 8 * 4

class CustomTabularDecoder(hp.TabularDecoder):
    def __init__(self, *args, learning_rate=1e-4, **kwargs):
        super().__init__(*args, **kwargs)
        self.learning_rate = learning_rate
    
    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer

tabular_decoder = CustomTabularDecoder(
    time_series_config,
    d_model=1024,  # Increased from 512 for better capacity
    n_heads=N_HEADS,
    attention_type="flash",  # Use flash attention for efficiency
    learning_rate=1e-4,  # Lower learning rate for better convergence
)

# %%
# Set up training
logger = TensorBoardLogger("runs", name=f"{dt.now()}_synthetic_next_row")
early_stopping = EarlyStopping(monitor="val_loss", patience=3, mode="min")
trainer = L.Trainer(max_epochs=10, logger=logger, callbacks=[early_stopping])

train_dl = DataLoader(
    train_ds,
    batch_size=32,
    shuffle=True,
    collate_fn=tabular_collate_fn,
    num_workers=1,
    persistent_workers=True,
)
test_dl = DataLoader(
    test_ds,
    batch_size=32,
    shuffle=False,
    collate_fn=tabular_collate_fn,
    num_workers=1,
    persistent_workers=True,
)

# Train the model
trainer.fit(tabular_decoder, train_dl, test_dl)

# %%
# Extract and display training metrics
print("\nTraining and Validation Loss Summary:")
print("=" * 80)

# Get metrics from trainer
metrics = trainer.logged_metrics
logger_metrics = trainer.logger.experiment

# Try to get metrics from different sources
try:
    # Method 1: From trainer callback metrics
    if hasattr(trainer, 'callback_metrics'):
        callback_metrics = trainer.callback_metrics
        print("Available callback metrics:", list(callback_metrics.keys()))
    
    # Method 2: From logger
    if hasattr(trainer.logger, 'experiment'):
        print(f"Logger type: {type(trainer.logger)}")
        
    # Method 3: From logged metrics
    if trainer.logged_metrics:
        print("Last logged metrics:", trainer.logged_metrics)
        
    # Method 4: Try to access TensorBoard logs directly
    if hasattr(trainer.logger, 'log_dir'):
        log_dir = trainer.logger.log_dir
        print(f"TensorBoard logs saved to: {log_dir}")
        
        # Try to read scalar summaries
        try:
            from tensorboard.backend.event_processing.event_accumulator import EventAccumulator
            
            event_acc = EventAccumulator(log_dir)
            event_acc.Reload()
            
            # Get available scalar tags
            scalar_tags = event_acc.Tags()['scalars']
            print(f"Available scalar metrics: {scalar_tags}")
            
            # Create summary table
            if scalar_tags:
                print("\nEpoch | Train Loss | Val Loss | Train Num Loss | Train Cat Loss | Val Num Loss | Val Cat Loss")
                print("-" * 95)
                
                # Get training and validation losses
                train_loss = []
                val_loss = []
                train_numeric_loss = []
                train_categorical_loss = []
                val_numeric_loss = []
                val_categorical_loss = []
                
                # Extract losses by epoch
                for tag in scalar_tags:
                    scalars = event_acc.Scalars(tag)
                    values = [s.value for s in scalars]
                    
                    if 'train_loss' in tag or 'train/loss' in tag:
                        train_loss = values
                    elif 'val_loss' in tag or 'val/loss' in tag:
                        val_loss = values
                    elif 'train_numeric_loss' in tag or 'train/numeric_loss' in tag:
                        train_numeric_loss = values
                    elif 'train_categorical_loss' in tag or 'train/categorical_loss' in tag:
                        train_categorical_loss = values
                    elif 'val_numeric_loss' in tag or 'val/numeric_loss' in tag:
                        val_numeric_loss = values
                    elif 'val_categorical_loss' in tag or 'val/categorical_loss' in tag:
                        val_categorical_loss = values
                
                # Print epoch by epoch summary
                max_epochs = max(len(train_loss), len(val_loss))
                for epoch in range(max_epochs):
                    t_loss = train_loss[epoch] if epoch < len(train_loss) else "N/A"
                    v_loss = val_loss[epoch] if epoch < len(val_loss) else "N/A"
                    t_num = train_numeric_loss[epoch] if epoch < len(train_numeric_loss) else "N/A"
                    t_cat = train_categorical_loss[epoch] if epoch < len(train_categorical_loss) else "N/A"
                    v_num = val_numeric_loss[epoch] if epoch < len(val_numeric_loss) else "N/A"
                    v_cat = val_categorical_loss[epoch] if epoch < len(val_categorical_loss) else "N/A"
                    
                    print(f"{epoch+1:5d} | {t_loss:10.4f} | {v_loss:8.4f} | {t_num:12.4f} | {t_cat:12.4f} | {v_num:10.4f} | {v_cat:10.4f}")
        
        except ImportError:
            print("TensorBoard not available for reading logs directly")
        except Exception as e:
            print(f"Error reading TensorBoard logs: {e}")
            
except Exception as e:
    print(f"Error accessing training metrics: {e}")

# Manual metrics extraction from model if available
try:
    if hasattr(tabular_decoder, 'training_step_outputs'):
        print("Model has training step outputs")
    if hasattr(tabular_decoder, 'validation_step_outputs'):
        print("Model has validation step outputs")
        
    # Check if model stores losses
    if hasattr(tabular_decoder, 'train_losses'):
        print(f"Training losses: {tabular_decoder.train_losses}")
    if hasattr(tabular_decoder, 'val_losses'):
        print(f"Validation losses: {tabular_decoder.val_losses}")
        
except Exception as e:
    print(f"Error checking model attributes: {e}")
    
print(f"\nTraining completed. Final epoch: {trainer.current_epoch}")
print(f"Global step: {trainer.global_step}")

# Simple loss trend analysis
if trainer.logged_metrics:
    print("\nFinal metrics:")
    for key, value in trainer.logged_metrics.items():
        if 'loss' in key.lower():
            print(f"  {key}: {value:.4f}")

print("\nModel training analysis:")
print("- If losses are decreasing, the model is learning")
print("- If losses plateau early, the model may need more capacity or different hyperparameters")
print("- If validation loss increases while training loss decreases, there's overfitting")
print("- If both losses remain high, the model may need architecture changes")

# %%
# Show results on training data
df_comp = hp.show_results_df(
    model=tabular_decoder,
    time_series_config=time_series_config,
    dataset=train_ds,
    idx=0,
)

# %%
# Plot error for sin wave
hp.plot_col_error(df_comp, "sin_wave")

# %%
# Plot comparison for sin wave
hp.plot_col_comparison(df_comp, "sin_wave")

# %%
# Plot error for cos wave
hp.plot_col_error(df_comp, "cos_wave")

# %%
# Plot comparison for cos wave
hp.plot_col_comparison(df_comp, "cos_wave")

# %% [markdown]
# ## Next Row Predictions
#

# %%
# Create initial inputs from the test dataset for next row prediction
test_idx = 5  # Choose a test sample
stop_idx = 64  # Start predictions after this timestep (halfway through sequence)
inputs = hp.AutoRegressiveResults.from_ds(test_ds, test_idx, stop_idx=stop_idx)

# Generate predictions for multiple steps
num_prediction_steps = 32  # Predict the remaining half of the sequence
for _ in range(num_prediction_steps):
    inputs = hp.auto_regressive_predictions(tabular_decoder, inputs)

# Process the results into DataFrames for analysis
actual_inputs = test_ds[test_idx]
actual_df = hp.create_test_inputs_df(
    hp.AutoRegressiveResults(actual_inputs.numeric, actual_inputs.categorical),
    time_series_config,
)
predicted_df = hp.create_test_inputs_df(inputs, time_series_config)

# %%
# Plot comparisons for key columns
plt.figure(figsize=(16, 12))
columns_to_plot = ["sin_wave", "cos_wave", "random_int", "lagged_mult"]

for i, col in enumerate(columns_to_plot):
    plt.subplot(2, 2, i + 1)

    ax = plt.gca()
    ax.plot(
        predicted_df["row_in_group"],
        predicted_df[col],
        "r-",
        label="Predicted",
    )
    ax.plot(
        actual_df["row_in_group"],
        actual_df[col],
        "b--",
        label="Actual",
    )

    # Add vertical line to mark prediction start
    ax.axvline(
        x=stop_idx, color="gray", linestyle="--", alpha=0.7, label="Prediction Start"
    )

    # Add annotations
    ax.set_title(f"{col} Next Row Predictions")
    ax.set_xlabel("Row in Group")
    ax.set_ylabel("Value")
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.suptitle("Next Row Predictions vs Actual Values", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# %%
# Analyze prediction accuracy for different types of columns
print("Prediction Analysis:")
print("=" * 50)

# Calculate errors for numeric columns
numeric_cols = ["sin_wave", "cos_wave", "random_int", "lagged_mult"]

for col in numeric_cols:
    if col in predicted_df.columns and col in actual_df.columns:
        # Get the overlapping portion for comparison
        min_len = min(len(predicted_df), len(actual_df))
        max_start = min(stop_idx, min_len - num_prediction_steps)

        # Only evaluate predictions (from stop_idx onward)
        end_idx = max_start + num_prediction_steps
        pred_values = predicted_df[col][max_start:end_idx].values
        actual_values = actual_df[col][max_start:end_idx].values

        # Ensure arrays are same length
        min_pred_len = min(len(pred_values), len(actual_values))
        pred_values = pred_values[:min_pred_len]
        actual_values = actual_values[:min_pred_len]

        # Remove NaN values for lagged_mult
        if len(pred_values) > 0 and len(actual_values) > 0:
            mask = ~(np.isnan(pred_values) | np.isnan(actual_values))
            if mask.any():
                pred_clean = pred_values[mask]
                actual_clean = actual_values[mask]

                if len(pred_clean) > 0:
                    mse = np.mean((pred_clean - actual_clean) ** 2)
                    mae = np.mean(np.abs(pred_clean - actual_clean))

                    print(f"{col}:")
                    print(f"  MSE: {mse:.4f}")
                    print(f"  MAE: {mae:.4f}")
                    print(f"  Data points: {len(pred_clean)}")

# Check categorical predictions
if "fizzbuzz" in predicted_df.columns and "fizzbuzz" in actual_df.columns:
    min_len = min(len(predicted_df), len(actual_df))
    max_start = min(stop_idx, min_len - num_prediction_steps)

    end_idx = max_start + num_prediction_steps
    pred_cat = predicted_df["fizzbuzz"][max_start:end_idx].values
    actual_cat = actual_df["fizzbuzz"][max_start:end_idx].values

    # Ensure arrays are same length
    min_pred_len = min(len(pred_cat), len(actual_cat))
    pred_cat = pred_cat[:min_pred_len]
    actual_cat = actual_cat[:min_pred_len]

    if len(pred_cat) > 0:
        accuracy = np.mean(pred_cat == actual_cat)
        print("fizzbuzz:")
        print(f"  Accuracy: {accuracy:.4f}")
        print(f"  Data points: {len(pred_cat)}")

# %% [markdown]
# ## Short-term Prediction Test (5 steps)
# Test next row prediction with only 5 steps to better evaluate performance
# on patterns vs random data

# %%
# Short-term prediction test with 5 steps
test_idx_short = 10  # Different test sample
stop_idx_short = 100  # Start later in sequence
inputs_short = hp.AutoRegressiveResults.from_ds(
    test_ds, test_idx_short, stop_idx=stop_idx_short
)

# Generate predictions for only 5 steps
num_prediction_steps_short = 5
for _ in range(num_prediction_steps_short):
    inputs_short = hp.auto_regressive_predictions(tabular_decoder, inputs_short)

# Process results for short-term predictions
actual_inputs_short = test_ds[test_idx_short]
actual_df_short = hp.create_test_inputs_df(
    hp.AutoRegressiveResults(
        actual_inputs_short.numeric, actual_inputs_short.categorical
    ),
    time_series_config,
)
predicted_df_short = hp.create_test_inputs_df(inputs_short, time_series_config)

# %%
# Plot short-term predictions
plt.figure(figsize=(16, 8))
columns_to_plot = ["sin_wave", "cos_wave", "random_int", "lagged_mult"]

for i, col in enumerate(columns_to_plot):
    plt.subplot(2, 2, i + 1)

    ax = plt.gca()

    # Plot larger context window around prediction
    context_window = 20
    start_plot = max(0, stop_idx_short - context_window)
    end_plot = min(len(actual_df_short), stop_idx_short + num_prediction_steps_short)

    # Plot actual values
    actual_plot = actual_df_short[col][start_plot:end_plot]
    row_plot = actual_df_short["row_in_group"][start_plot:end_plot]
    ax.plot(row_plot, actual_plot, "b-", label="Actual", linewidth=2)

    # Plot predicted values (only the 5 predicted steps)
    pred_start_idx = stop_idx_short
    pred_end_idx = stop_idx_short + num_prediction_steps_short
    if pred_end_idx <= len(predicted_df_short):
        pred_plot = predicted_df_short[col][pred_start_idx:pred_end_idx]
        row_pred = predicted_df_short["row_in_group"][pred_start_idx:pred_end_idx]
        ax.plot(
            row_pred,
            pred_plot,
            "r-",
            label="Predicted",
            linewidth=3,
            marker="o",
            markersize=4,
        )

    # Add vertical line to mark prediction start
    ax.axvline(
        x=stop_idx_short,
        color="gray",
        linestyle="--",
        alpha=0.7,
        label="Prediction Start",
    )

    # Styling
    ax.set_title(f"{col} - 5 Step Prediction")
    ax.set_xlabel("Row in Group")
    ax.set_ylabel("Value")
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.suptitle("Short-term Next Row Predictions (5 Steps)", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# %%
# Analyze short-term prediction accuracy
print("\nShort-term Prediction Analysis (5 steps):")
print("=" * 50)

for col in numeric_cols:
    if col in predicted_df_short.columns and col in actual_df_short.columns:
        # Compare only the 5 predicted steps
        pred_values = predicted_df_short[col][
            stop_idx_short : stop_idx_short + num_prediction_steps_short
        ].values
        actual_values = actual_df_short[col][
            stop_idx_short : stop_idx_short + num_prediction_steps_short
        ].values

        # Ensure arrays are same length
        min_pred_len = min(len(pred_values), len(actual_values))
        pred_values = pred_values[:min_pred_len]
        actual_values = actual_values[:min_pred_len]

        # Remove NaN values
        if len(pred_values) > 0 and len(actual_values) > 0:
            mask = ~(np.isnan(pred_values) | np.isnan(actual_values))
            if mask.any():
                pred_clean = pred_values[mask]
                actual_clean = actual_values[mask]

                if len(pred_clean) > 0:
                    mse = np.mean((pred_clean - actual_clean) ** 2)
                    mae = np.mean(np.abs(pred_clean - actual_clean))

                    print(f"{col}:")
                    print(f"  MSE: {mse:.4f}")
                    print(f"  MAE: {mae:.4f}")
                    print(f"  Data points: {len(pred_clean)}")

# Check categorical predictions for short-term
if "fizzbuzz" in predicted_df_short.columns and "fizzbuzz" in actual_df_short.columns:
    pred_cat = predicted_df_short["fizzbuzz"][
        stop_idx_short : stop_idx_short + num_prediction_steps_short
    ].values
    actual_cat = actual_df_short["fizzbuzz"][
        stop_idx_short : stop_idx_short + num_prediction_steps_short
    ].values

    min_pred_len = min(len(pred_cat), len(actual_cat))
    pred_cat = pred_cat[:min_pred_len]
    actual_cat = actual_cat[:min_pred_len]

    if len(pred_cat) > 0:
        accuracy = np.mean(pred_cat == actual_cat)
        print("fizzbuzz:")
        print(f"  Accuracy: {accuracy:.4f}")
        print(f"  Data points: {len(pred_cat)}")

# %% [markdown]
# ## Detailed Analysis of Random Variables and Lagged Multiplication
# Focus on random_int and lagged_mult to understand prediction quality

# %%
# Create a detailed plot focusing on random variables
plt.figure(figsize=(18, 10))

# Use a larger context window to see more patterns
context_window = 40
start_plot = max(0, stop_idx_short - context_window)
end_plot = min(len(actual_df_short), stop_idx_short + num_prediction_steps_short + 10)

# Subplot 1: Random integers
plt.subplot(2, 2, 1)
ax1 = plt.gca()

# Plot historical random_int values
hist_range = slice(start_plot, stop_idx_short)
ax1.plot(
    actual_df_short["row_in_group"][hist_range],
    actual_df_short["random_int"][hist_range],
    "b-", label="Historical Random Int", linewidth=2, marker=".", markersize=3
)

# Plot actual future random_int values
future_range = slice(stop_idx_short, stop_idx_short + num_prediction_steps_short)
ax1.plot(
    actual_df_short["row_in_group"][future_range],
    actual_df_short["random_int"][future_range],
    "g-", label="Actual Future Random Int", linewidth=3, marker="o", markersize=6
)

# Plot predicted random_int values
if stop_idx_short + num_prediction_steps_short <= len(predicted_df_short):
    ax1.plot(
        predicted_df_short["row_in_group"][future_range],
        predicted_df_short["random_int"][future_range],
        "r-", label="Predicted Random Int", linewidth=3, marker="x", markersize=8
    )

ax1.axvline(x=stop_idx_short, color="gray", linestyle="--", alpha=0.7)
ax1.set_title("Random Integer Predictions")
ax1.set_xlabel("Row in Group")
ax1.set_ylabel("Random Int (Scaled)")
ax1.legend()
ax1.grid(True, alpha=0.3)

# Subplot 2: Lagged multiplication
plt.subplot(2, 2, 2)
ax2 = plt.gca()

# Plot historical lagged_mult values
ax2.plot(
    actual_df_short["row_in_group"][hist_range],
    actual_df_short["lagged_mult"][hist_range],
    "b-", label="Historical Lagged Mult", linewidth=2, marker=".", markersize=3
)

# Plot actual future lagged_mult values
ax2.plot(
    actual_df_short["row_in_group"][future_range],
    actual_df_short["lagged_mult"][future_range],
    "g-", label="Actual Future Lagged Mult", linewidth=3, marker="o", markersize=6
)

# Plot predicted lagged_mult values
if stop_idx_short + num_prediction_steps_short <= len(predicted_df_short):
    ax2.plot(
        predicted_df_short["row_in_group"][future_range],
        predicted_df_short["lagged_mult"][future_range],
        "r-", label="Predicted Lagged Mult", linewidth=3, marker="x", markersize=8
    )

ax2.axvline(x=stop_idx_short, color="gray", linestyle="--", alpha=0.7)
ax2.set_title("Lagged Multiplication Predictions")
ax2.set_xlabel("Row in Group")
ax2.set_ylabel("Lagged Mult (Scaled)")
ax2.legend()
ax2.grid(True, alpha=0.3)

# Subplot 3: Both variables together (scatter plot)
plt.subplot(2, 2, 3)
ax3 = plt.gca()

# Historical data
ax3.scatter(
    actual_df_short["random_int"][hist_range],
    actual_df_short["lagged_mult"][hist_range],
    c="blue", alpha=0.6, s=20, label="Historical"
)

# Actual future values
ax3.scatter(
    actual_df_short["random_int"][future_range],
    actual_df_short["lagged_mult"][future_range],
    c="green", s=80, marker="o", label="Actual Future", edgecolor="black"
)

# Predicted future values
if stop_idx_short + num_prediction_steps_short <= len(predicted_df_short):
    ax3.scatter(
        predicted_df_short["random_int"][future_range],
        predicted_df_short["lagged_mult"][future_range],
        c="red", s=80, marker="x", label="Predicted Future", linewidths=3
    )

ax3.set_title("Random Int vs Lagged Mult Relationship")
ax3.set_xlabel("Random Int (Scaled)")
ax3.set_ylabel("Lagged Mult (Scaled)")
ax3.legend()
ax3.grid(True, alpha=0.3)

# Subplot 4: Prediction errors over time
plt.subplot(2, 2, 4)
ax4 = plt.gca()

if stop_idx_short + num_prediction_steps_short <= len(predicted_df_short):
    # Calculate absolute errors for each step
    random_int_errors = np.abs(
        predicted_df_short["random_int"][future_range].values - 
        actual_df_short["random_int"][future_range].values
    )
    lagged_mult_errors = np.abs(
        predicted_df_short["lagged_mult"][future_range].values - 
        actual_df_short["lagged_mult"][future_range].values
    )
    
    steps = np.arange(1, num_prediction_steps_short + 1)
    
    ax4.plot(steps, random_int_errors, "r-o", label="Random Int Error", linewidth=2)
    ax4.plot(steps, lagged_mult_errors, "b-s", label="Lagged Mult Error", linewidth=2)
    
    ax4.set_title("Prediction Error by Step")
    ax4.set_xlabel("Prediction Step")
    ax4.set_ylabel("Absolute Error")
    ax4.legend()
    ax4.grid(True, alpha=0.3)

plt.suptitle(f"Random Variables Analysis (Test Sample {test_idx_short})", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# %%
# Print detailed numerical analysis
print("\nDetailed Random Variables Analysis:")
print("=" * 60)

if stop_idx_short + num_prediction_steps_short <= len(predicted_df_short):
    print(f"Test sample: {test_idx_short}")
    print(f"Prediction start: row {stop_idx_short}")
    print(f"Prediction steps: {num_prediction_steps_short}")
    
    # Get the actual values for comparison
    actual_random = actual_df_short["random_int"][future_range].values
    pred_random = predicted_df_short["random_int"][future_range].values
    actual_lagged = actual_df_short["lagged_mult"][future_range].values
    pred_lagged = predicted_df_short["lagged_mult"][future_range].values
    
    print("\nStep-by-step comparison:")
    print("Step | Actual Random | Pred Random | Actual Lagged | Pred Lagged")
    print("-" * 65)
    
    for i in range(num_prediction_steps_short):
        step = i + 1
        print(f"{step:4d} | {actual_random[i]:11.3f} | {pred_random[i]:9.3f} | "
              f"{actual_lagged[i]:11.3f} | {pred_lagged[i]:9.3f}")
    
    # Calculate correlation between random_int and lagged_mult
    # Look back 5 steps to see if model understands the lagged relationship
    back_start = max(0, stop_idx_short - 10)
    back_random = actual_df_short["random_int"][back_start:stop_idx_short].values
    current_lagged = actual_df_short["lagged_mult"][
        stop_idx_short:stop_idx_short + 5
    ].values
    
    print("\nLagged relationship analysis:")
    print(f"Random ints 5-10 steps back: {back_random[-5:]}")
    print(f"Current lagged values: {current_lagged}")
    
    # Check if the model should be able to predict lagged_mult from past random_int
    if len(back_random) >= 5 and len(current_lagged) >= 5:
        expected_lagged = back_random[-5:] * 2.5  # 5 steps back * 2.5
        print(f"Expected lagged values (random*2.5): {expected_lagged}")
        actual_vs_expected_error = np.abs(current_lagged - expected_lagged)
        print(f"Actual vs Expected lagged error: {actual_vs_expected_error}")

# %%
# Model Performance Analysis and Recommendations
print("\n" + "=" * 80)
print("MODEL PERFORMANCE ANALYSIS & IMPROVEMENT RECOMMENDATIONS")
print("=" * 80)

# Analyze the results we just saw
analysis_results = []

# Check if model learned lagged relationship
if stop_idx_short + num_prediction_steps_short <= len(predicted_df_short):
    actual_random = actual_df_short["random_int"][future_range].values
    pred_random = predicted_df_short["random_int"][future_range].values
    actual_lagged = actual_df_short["lagged_mult"][future_range].values
    pred_lagged = predicted_df_short["lagged_mult"][future_range].values
    
    # Random prediction error
    random_mse = np.mean((pred_random - actual_random) ** 2)
    lagged_mse = np.mean((pred_lagged - actual_lagged) ** 2)
    
    # Check if model understands the lagged relationship
    back_start = max(0, stop_idx_short - 10)
    back_random = actual_df_short["random_int"][back_start:stop_idx_short].values
    if len(back_random) >= 5:
        expected_lagged = back_random[-5:] * 2.5
        actual_lagged_subset = actual_lagged[:len(expected_lagged)]
        pred_lagged_subset = pred_lagged[:len(expected_lagged)]
        
        expected_vs_actual_error = np.mean(np.abs(actual_lagged_subset - expected_lagged))
        predicted_vs_expected_error = np.mean(np.abs(pred_lagged_subset - expected_lagged))
        
        print(f"Random Integer MSE: {random_mse:.4f}")
        print(f"Lagged Multiplication MSE: {lagged_mse:.4f}")
        print(f"Expected vs Actual Lagged Error: {expected_vs_actual_error:.4f}")
        print(f"Predicted vs Expected Lagged Error: {predicted_vs_expected_error:.4f}")
        
        # Analysis
        print("\nANALYSIS:")
        
        if random_mse > 0.5:
            print("âŒ Random number prediction is poor (expected - these are random!)")
            analysis_results.append("random_poor")
        else:
            print("âš ï¸  Random number prediction is surprisingly good (concerning)")
            analysis_results.append("random_good")
            
        if lagged_mse > 0.5:
            print("âŒ Lagged multiplication prediction is poor")
            analysis_results.append("lagged_poor")
        else:
            print("âœ… Lagged multiplication prediction is reasonable")
            analysis_results.append("lagged_good")
            
        if predicted_vs_expected_error > expected_vs_actual_error * 2:
            print("âŒ Model doesn't understand the lagged relationship")
            analysis_results.append("no_pattern_learning")
        else:
            print("âœ… Model somewhat understands the lagged relationship")
            analysis_results.append("pattern_learning")

print("\nRECOMMENDATIONS:")

# Provide specific recommendations
recommendations = []

if "random_good" in analysis_results:
    recommendations.append("ðŸ” INVESTIGATE: Model predicting random numbers too well - check data leakage")

if "lagged_poor" in analysis_results:
    recommendations.append("ðŸ“ˆ INCREASE model capacity: More layers or larger d_model")
    recommendations.append("â° LONGER training: More epochs or lower learning rate")
    recommendations.append("ðŸŽ¯ FOCUS on sequence modeling: The model needs to learn temporal dependencies")

if "no_pattern_learning" in analysis_results:
    recommendations.append("ðŸ§  ARCHITECTURE CHANGE: Model isn't learning patterns in the data")
    recommendations.append("ðŸ“Š CHECK attention: Make sure attention can look back 5+ steps")
    recommendations.append("ðŸ”§ PREPROCESSING: Consider not scaling the lagged_mult column")

# General recommendations based on the synthetic dataset
recommendations.extend([
    "ðŸ“ SCALING ISSUE: Try training without scaling, or use different scaling methods",
    "ðŸŽ¯ LOSS WEIGHTING: Weight the numeric loss higher for deterministic patterns",
    "ðŸ“ SEQUENCE LENGTH: Ensure model sees enough history (>5 steps) to learn patterns",
    "ðŸ”„ LEARNING RATE: Try lower learning rate for better convergence",
    "ðŸ—ï¸  MODEL SIZE: Increase d_model from 512 to 1024+ for better capacity"
])

for i, rec in enumerate(recommendations[:8], 1):  # Show top 8 recommendations
    print(f"{i}. {rec}")

print("\nNEXT STEPS:")
print("1. Run this script and examine the training loss table")
print("2. If losses plateau early, increase model capacity or lower learning rate")
print("3. If validation loss >> training loss, reduce model size or add regularization")
print("4. If both losses remain high, try architectural changes")
print("5. For this dataset, focus on whether model learns sin/cos patterns vs random data")

# %%
