{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diamonds dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\"\n",
    ")\n",
    "df = df.sample(1_000, random_state=42)\n",
    "# Use all columns except for 'price' as features\n",
    "features = df.drop(\"price\", axis=1)\n",
    "labels = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388          0.24 Ideal G VVS1 62.1 56.0 3.97 4.0 2.47\n",
       "50052    0.58 Very Good F VVS2 60.0 57.0 5.44 5.42 3.26\n",
       "41645         0.4 Ideal E VVS2 62.1 55.0 4.76 4.74 2.95\n",
       "42377      0.43 Premium E VVS2 60.8 57.0 4.92 4.89 2.98\n",
       "17244         1.55 Ideal E SI2 62.3 55.0 7.44 7.37 4.61\n",
       "                              ...                      \n",
       "35207          0.33 Ideal I IF 61.6 55.0 4.47 4.46 2.75\n",
       "15806          1.0 Ideal E SI1 62.4 55.0 6.34 6.42 3.98\n",
       "45884          0.58 Ideal G VS2 61.1 56.0 5.4 5.43 3.31\n",
       "22681         0.38 Ideal J VVS2 62.0 55.0 4.67 4.69 2.9\n",
       "21429       1.18 Premium G VVS2 59.7 58.0 6.94 6.9 4.13\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to string and concatenate\n",
    "features_str = features.applymap(str).apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize features\n",
    "tokens = tokenizer(\n",
    "    features_str.tolist(), padding=True, truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Standardize labels (price)\n",
    "scaler = StandardScaler()\n",
    "labels_scaled = scaler.fit_transform(labels.values.reshape(-1, 1))\n",
    "\n",
    "# Convert labels to tensor\n",
    "labels_tensor = torch.tensor(labels_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertRegressor, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooler_output = outputs.pooler_output\n",
    "        return self.regressor(pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDataset\n",
    "dataset = TensorDataset(tokens.input_ids, tokens.attention_mask, labels_tensor)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad052dcf3a3849c59506ceb057438fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567aeaa8165b4b22afe2249b629f99c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af05fb8f1c471ab44a8490838f8b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model = BertRegressor()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):\n",
    "    print(epoch)  # Number of epochs can be adjusted\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids, attention_mask, y = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).squeeze()\n",
    "        # loss = criterion(outputs, y.squeeze())\n",
    "        # outputs = model(input_ids, attention_mask).squeeze()\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3075, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.997130391336721\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, y = batch\n",
    "        outputs = model(input_ids, attention_mask).squeeze()\n",
    "        all_preds.extend(outputs.tolist())\n",
    "        all_labels.extend(y.tolist())\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(all_labels, all_preds, squared=False)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0906, 0.0755, 0.0768, 0.0922, 0.0760, 0.0631, 0.0727, 0.0883])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8692],\n",
       "        [-0.8181],\n",
       "        [-0.8596],\n",
       "        [ 2.0640],\n",
       "        [-0.6108],\n",
       "        [-0.5678],\n",
       "        [-0.5316],\n",
       "        [-0.7376]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0906, 0.0755, 0.0768, 0.0922, 0.0760, 0.0631, 0.0727, 0.0883])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
