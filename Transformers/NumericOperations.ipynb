{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diamond Transformer\n",
    "\n",
    "This notebook investigates the use of a transformer to predict the price of diamonds. The dataset is from Kaggle and can be found [here](https://www.kaggle.com/shivam2503/diamonds).\n",
    "\n",
    "While many traditional ML and DL techniques work on the dataset, our approach uses far less labeled data while achieving similar results. This is done by using a transformer.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import hephaestus as hp\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diamonds dataset: df = pl.read_csv(\"../data/diamonds.csv\") df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>684.0</td><td>93.428636</td><td>&quot;multiply&quot;</td><td>63905.187075</td></tr><tr><td>440.382552</td><td>30.0</td><td>&quot;multiply&quot;</td><td>13211.476564</td></tr><tr><td>645.0</td><td>169.406437</td><td>&quot;add&quot;</td><td>814.406437</td></tr><tr><td>589.0</td><td>595.671255</td><td>&quot;add&quot;</td><td>1184.671255</td></tr><tr><td>945.0</td><td>542.315009</td><td>&quot;subtract&quot;</td><td>402.684991</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────┬────────────┬───────────┬──────────────┐\n",
       "│ num1       ┆ num2       ┆ operation ┆ result       │\n",
       "│ ---        ┆ ---        ┆ ---       ┆ ---          │\n",
       "│ f64        ┆ f64        ┆ str       ┆ f64          │\n",
       "╞════════════╪════════════╪═══════════╪══════════════╡\n",
       "│ 684.0      ┆ 93.428636  ┆ multiply  ┆ 63905.187075 │\n",
       "│ 440.382552 ┆ 30.0       ┆ multiply  ┆ 13211.476564 │\n",
       "│ 645.0      ┆ 169.406437 ┆ add       ┆ 814.406437   │\n",
       "│ 589.0      ┆ 595.671255 ┆ add       ┆ 1184.671255  │\n",
       "│ 945.0      ┆ 542.315009 ┆ subtract  ┆ 402.684991   │\n",
       "└────────────┴────────────┴───────────┴──────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to generate a random number, either integer or float\n",
    "def generate_random_number():\n",
    "    return random.randint(1, 10) if random.random() < 0.5 else random.uniform(1, 10)\n",
    "\n",
    "\n",
    "# Number of rows in the DataFrame\n",
    "n_rows = 100_000\n",
    "\n",
    "# Generate random values for num1 and num2 (both integers and floats)\n",
    "num1 = [generate_random_number() for _ in range(n_rows)]\n",
    "num2 = [generate_random_number() for _ in range(n_rows)]\n",
    "\n",
    "# Randomly choose an operation for each row\n",
    "operations = [\n",
    "    random.choice([\"multiply\", \"divide\", \"add\", \"subtract\"]) for _ in range(n_rows)\n",
    "]\n",
    "\n",
    "# Create a DataFrame with the columns num1, num2, and operation\n",
    "df = pl.DataFrame({\"num1\": num1, \"num2\": num2, \"operation\": operations})\n",
    "\n",
    "# Apply the operation to each row to create the result column\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"operation\") == \"multiply\")\n",
    "    .then(pl.col(\"num1\") * pl.col(\"num2\"))\n",
    "    .when(pl.col(\"operation\") == \"divide\")\n",
    "    .then(pl.col(\"num1\") / pl.col(\"num2\"))\n",
    "    .when(pl.col(\"operation\") == \"add\")\n",
    "    .then(pl.col(\"num1\") + pl.col(\"num2\"))\n",
    "    .when(pl.col(\"operation\") == \"subtract\")\n",
    "    .then(pl.col(\"num1\") - pl.col(\"num2\"))\n",
    "    .otherwise(None)\n",
    "    .alias(\"result\")\n",
    ")\n",
    "\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>10000.0</td><td>10000.0</td><td>&quot;10000&quot;</td><td>10000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>503.037639</td><td>501.664594</td><td>null</td><td>62970.758504</td></tr><tr><td>&quot;std&quot;</td><td>288.368825</td><td>286.497977</td><td>null</td><td>153451.869404</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>&quot;add&quot;</td><td>-980.694696</td></tr><tr><td>&quot;max&quot;</td><td>1000.0</td><td>1000.0</td><td>&quot;subtract&quot;</td><td>984850.571308</td></tr><tr><td>&quot;median&quot;</td><td>501.379767</td><td>503.984314</td><td>null</td><td>504.571328</td></tr><tr><td>&quot;25%&quot;</td><td>256.793421</td><td>257.780895</td><td>null</td><td>0.991464</td></tr><tr><td>&quot;75%&quot;</td><td>754.058153</td><td>749.0</td><td>null</td><td>1871.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 5)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────────┐\n",
       "│ describe   ┆ num1       ┆ num2       ┆ operation ┆ result        │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---       ┆ ---           │\n",
       "│ str        ┆ f64        ┆ f64        ┆ str       ┆ f64           │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════════╡\n",
       "│ count      ┆ 10000.0    ┆ 10000.0    ┆ 10000     ┆ 10000.0       │\n",
       "│ null_count ┆ 0.0        ┆ 0.0        ┆ 0         ┆ 0.0           │\n",
       "│ mean       ┆ 503.037639 ┆ 501.664594 ┆ null      ┆ 62970.758504  │\n",
       "│ std        ┆ 288.368825 ┆ 286.497977 ┆ null      ┆ 153451.869404 │\n",
       "│ min        ┆ 1.0        ┆ 1.0        ┆ add       ┆ -980.694696   │\n",
       "│ max        ┆ 1000.0     ┆ 1000.0     ┆ subtract  ┆ 984850.571308 │\n",
       "│ median     ┆ 501.379767 ┆ 503.984314 ┆ null      ┆ 504.571328    │\n",
       "│ 25%        ┆ 256.793421 ┆ 257.780895 ┆ null      ┆ 0.991464      │\n",
       "│ 75%        ┆ 754.058153 ┆ 749.0      ┆ null      ┆ 1871.0        │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.627538</td><td>-1.424917</td><td>&quot;multiply&quot;</td><td>0.006089</td></tr><tr><td>-0.217274</td><td>-1.64631</td><td>&quot;multiply&quot;</td><td>-0.324266</td></tr><tr><td>0.492294</td><td>-1.159723</td><td>&quot;add&quot;</td><td>-0.405054</td></tr><tr><td>0.298099</td><td>0.328123</td><td>&quot;add&quot;</td><td>-0.402641</td></tr><tr><td>1.532629</td><td>0.141887</td><td>&quot;subtract&quot;</td><td>-0.407737</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.627538  ┆ -1.424917 ┆ multiply  ┆ 0.006089  │\n",
       "│ -0.217274 ┆ -1.64631  ┆ multiply  ┆ -0.324266 │\n",
       "│ 0.492294  ┆ -1.159723 ┆ add       ┆ -0.405054 │\n",
       "│ 0.298099  ┆ 0.328123  ┆ add       ┆ -0.402641 │\n",
       "│ 1.532629  ┆ 0.141887  ┆ subtract  ┆ -0.407737 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hp.scale_numeric(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hp.make_lower_remove_special_chars(df)\n",
    "val_tokens = hp.get_unique_utf8_values(df)\n",
    "col_tokens = hp.get_col_tokens(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.627538</td><td>-1.424917</td><td>&quot;multiply&quot;</td><td>0.006089</td></tr><tr><td>-0.217274</td><td>-1.64631</td><td>&quot;multiply&quot;</td><td>-0.324266</td></tr><tr><td>0.492294</td><td>-1.159723</td><td>&quot;add&quot;</td><td>-0.405054</td></tr><tr><td>0.298099</td><td>0.328123</td><td>&quot;add&quot;</td><td>-0.402641</td></tr><tr><td>1.532629</td><td>0.141887</td><td>&quot;subtract&quot;</td><td>-0.407737</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.627538  ┆ -1.424917 ┆ multiply  ┆ 0.006089  │\n",
       "│ -0.217274 ┆ -1.64631  ┆ multiply  ┆ -0.324266 │\n",
       "│ 0.492294  ┆ -1.159723 ┆ add       ┆ -0.405054 │\n",
       "│ 0.298099  ┆ 0.328123  ┆ add       ┆ -0.402641 │\n",
       "│ 1.532629  ┆ 0.141887  ┆ subtract  ┆ -0.407737 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = np.array(\n",
    "    [\n",
    "        \"missing\",\n",
    "        \"<mask>\",\n",
    "        \"<numeric_mask>\",\n",
    "        \"<pad>\",\n",
    "        \"<unk>\",\n",
    "        \":\",\n",
    "        \",\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', ':', '<mask>', '<numeric>', '<numeric_mask>', '<pad>',\n",
       "       '<row-end>', '<row-start>', '<unk>', 'add', 'divide', 'missing',\n",
       "       'multiply', 'num1', 'num2', 'operation', 'result', 'subtract'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = np.unique(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            val_tokens,\n",
    "            col_tokens,\n",
    "            special_tokens,\n",
    "            [\n",
    "                \"<numeric>\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "To show the actual model performance out of sample we split the data into a training and test set. The training set will be used to train the model and the test set will be used to evaluate the model performance. We will use 80% of the data for training and 20% for testing.\n",
    "\n",
    "We also remove the price column from the training and test sets and will only use a tiny subset of the data to simulate an industrial process with lots of input data but expensive and limited labeled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.627538</td><td>-1.424917</td><td>&quot;multiply&quot;</td><td>0.006089</td></tr><tr><td>-0.217274</td><td>-1.64631</td><td>&quot;multiply&quot;</td><td>-0.324266</td></tr><tr><td>0.492294</td><td>-1.159723</td><td>&quot;add&quot;</td><td>-0.405054</td></tr><tr><td>0.298099</td><td>0.328123</td><td>&quot;add&quot;</td><td>-0.402641</td></tr><tr><td>1.532629</td><td>0.141887</td><td>&quot;subtract&quot;</td><td>-0.407737</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.627538  ┆ -1.424917 ┆ multiply  ┆ 0.006089  │\n",
       "│ -0.217274 ┆ -1.64631  ┆ multiply  ┆ -0.324266 │\n",
       "│ 0.492294  ┆ -1.159723 ┆ add       ┆ -0.405054 │\n",
       "│ 0.298099  ┆ 0.328123  ┆ add       ┆ -0.402641 │\n",
       "│ 1.532629  ┆ 0.141887  ┆ subtract  ┆ -0.407737 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle for randomness\n",
    "df = df.sample(fraction=1.0, seed=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "n_train = int(train_fraction * len(df))\n",
    "train_test_df = df.select(pl.all())\n",
    "\n",
    "train, test = train_test_df.head(n_train), train_test_df.tail(\n",
    "    len(train_test_df) - n_train\n",
    ")\n",
    "\n",
    "labeled_train, labeled_test = df.head(n_train), df.tail(len(df) - n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(shape: (5, 4)\n",
       " ┌───────────┬───────────┬───────────┬───────────┐\n",
       " │ num1      ┆ num2      ┆ operation ┆ result    │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       " │ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       " │ 0.627538  ┆ -1.424917 ┆ multiply  ┆ 0.006089  │\n",
       " │ -0.217274 ┆ -1.64631  ┆ multiply  ┆ -0.324266 │\n",
       " │ 0.492294  ┆ -1.159723 ┆ add       ┆ -0.405054 │\n",
       " │ 0.298099  ┆ 0.328123  ┆ add       ┆ -0.402641 │\n",
       " │ 1.532629  ┆ 0.141887  ┆ subtract  ┆ -0.407737 │\n",
       " └───────────┴───────────┴───────────┴───────────┘,\n",
       " (8000, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(), train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.627538</td><td>-1.424917</td><td>&quot;multiply&quot;</td><td>0.006089</td></tr><tr><td>-0.217274</td><td>-1.64631</td><td>&quot;multiply&quot;</td><td>-0.324266</td></tr><tr><td>0.492294</td><td>-1.159723</td><td>&quot;add&quot;</td><td>-0.405054</td></tr><tr><td>0.298099</td><td>0.328123</td><td>&quot;add&quot;</td><td>-0.402641</td></tr><tr><td>1.532629</td><td>0.141887</td><td>&quot;subtract&quot;</td><td>-0.407737</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.627538  ┆ -1.424917 ┆ multiply  ┆ 0.006089  │\n",
       "│ -0.217274 ┆ -1.64631  ┆ multiply  ┆ -0.324266 │\n",
       "│ 0.492294  ┆ -1.159723 ┆ add       ┆ -0.405054 │\n",
       "│ 0.298099  ┆ 0.328123  ┆ add       ┆ -0.402641 │\n",
       "│ 1.532629  ┆ 0.141887  ┆ subtract  ┆ -0.407737 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "ds = hp.TabularDataset(\n",
    "    train,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=False,\n",
    "    max_row_length=19,\n",
    ")\n",
    "\n",
    "print(len(ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<row-start>', 'num1', ':', 0.627537880086947, ',', 'num2', ':', -1.4249174175476262, ',', 'operation', ':', 'multiply', ',', 'result', ':', 0.006089391901095394, ',', '<row-end>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print([i.value for i in ds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    device_name = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:218: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because  self.layers[0].self_attn.batch_first was not True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "n_token = len(ds.vocab)  # size of vocabulary\n",
    "d_model = 96  # embedding dimension\n",
    "d_hid = 1_000  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "n_layers = 12  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "n_head = 12  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = hp.TransformerModel(\n",
    "    n_token, d_model, n_head, d_hid, n_layers, device, dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model out:\n",
    "data, targets = hp.batch_data(ds, 1, n_row=1)\n",
    "class_out, numeric_out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = d[\"pre_num_scal_embed\"] / d[\"post_num_scal_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d[\"pre_num_scal_embed\"] * torch.eye(d[\"pre_num_scal_embed\"].shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "lr = 0.001  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size =100, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.8,\n",
    "    patience=5,\n",
    "    threshold=0.001,\n",
    "    threshold_mode=\"rel\",\n",
    "    cooldown=0,\n",
    "    min_lr=0.01,\n",
    "    eps=1e-08,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "def train(model: nn.Module, epochs=1, model_name=\"\") -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 1000\n",
    "    lr_eval_interval = 25\n",
    "    n_row = 100  # one because it's not time series\n",
    "    start_time = time.time()\n",
    "    for epoch in trange(1, epochs + 1, leave=True, desc=\"Epoch\"):\n",
    "        pbar = trange(0, len(ds) - 1, n_row, desc=f\"Batch for {epoch}/{epochs}\")\n",
    "        writer = SummaryWriter(\"runs/\" + model_name + \"_run_\" + str(epoch))\n",
    "        for batch, i in enumerate(pbar):\n",
    "            data, targets = hp.batch_data(ds, i, n_row=n_row)\n",
    "            class_output, numeric_output = model(data)\n",
    "            loss, loss_dict = hp.hephaestus_loss(\n",
    "                class_output, numeric_output, targets, tokens, special_tokens, device\n",
    "            )\n",
    "            num_loss = loss_dict[\"reg_loss\"].item()\n",
    "            class_loss = loss_dict[\"class_loss\"].item()\n",
    "            writer.add_scalar(\"Loss/total_loss\", loss, batch)\n",
    "            writer.add_scalar(\"Loss/numeric_loss\", num_loss, batch)\n",
    "            writer.add_scalar(\"Loss/class_loss\", class_loss, batch)\n",
    "            writer.add_scalar(\n",
    "                \"Metrics/learning_rate\", optimizer.param_groups[0][\"lr\"], batch\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    \"tl\": f\"{loss:.2f}\",\n",
    "                    \"cl\": f\"{class_loss:.2f}\",\n",
    "                    \"nl\": f\"{num_loss:.2f}\",\n",
    "                    \"tr\": f\"{optimizer.param_groups[0]['lr']:.2f}\",\n",
    "                },\n",
    "                refresh=True,\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            if batch % lr_eval_interval == 0:\n",
    "                # pbar.set_p(\n",
    "                #     f\"tl: {}, nl: {num_loss:.2f}, cl: {class_loss:.2f}, tr: {optimizer.param_groups[0]['lr']:.2f}\"\n",
    "                # )\n",
    "\n",
    "                scheduler.step(loss)\n",
    "\n",
    "                # if batch % log_interval == 0:\n",
    "                #     # lr = scheduler.get_last_lr()[0]\n",
    "                #     lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "                #     ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "                #     cur_loss = total_loss / log_interval\n",
    "                #     ppl = math.exp(cur_loss)\n",
    "                #     print(  # f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                #         f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \",\n",
    "                #         f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\",\n",
    "                #         f\"num_loss {num_loss:5.2f} | class_loss {class_loss:5.2f}\",\n",
    "                #     )\n",
    "                #     total_loss = 0\n",
    "                start_time = time.time()\n",
    "                # scheduler.step(loss)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496002b4f1e8493dbee0c5556c32a0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9056d9ac2dee41f3b4786edd6b876517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch for 1/3:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372d68b9eca34cfc921a4aa150934f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch for 2/3:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94763607aa6146be914c033f714d3707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch for 3/3:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "exp_name = \"numeric_scaling6\"\n",
    "\n",
    "model_name = model_time + \"_\" + exp_name\n",
    "epochs = 3\n",
    "train(model=model, epochs=epochs, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 2,776,946\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# model = CustomNumericAttention(d_model=512, n_head=8) # Replace with your model\n",
    "param_count = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {param_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "save_model = True\n",
    "if save_model:\n",
    "    MODEL_PATH = \"models/\" + model_name + \".pth\"\n",
    "    torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = hp.TabularDataset(\n",
    "    test,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=False,\n",
    "    max_row_length=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, ds, idx) -> None:\n",
    "    model.eval()  # turn on train mode\n",
    "    n_row = 1  # one because it's not time series\n",
    "    with torch.no_grad():\n",
    "        data, targets = hp.batch_data(ds, idx, n_row=n_row)\n",
    "        class_output, numeric_output = model(data)\n",
    "        loss, loss_dict = hp.hephaestus_loss(\n",
    "            class_output, numeric_output, targets, tokens, special_tokens, device\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss.item(),\n",
    "            \"loss_dict\": loss_dict,\n",
    "            \"data\": data,\n",
    "            \"targets\": targets,\n",
    "            \"class_output\": class_output,\n",
    "            \"numeric_output\": numeric_output,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_000, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>-0.222069</td><td>-0.093071</td><td>&quot;divide&quot;</td><td>-0.410356</td></tr><tr><td>-0.760505</td><td>1.052537</td><td>&quot;multiply&quot;</td><td>1.074778</td></tr><tr><td>-0.596589</td><td>0.714712</td><td>&quot;add&quot;</td><td>-0.403601</td></tr><tr><td>1.45287</td><td>0.309759</td><td>&quot;divide&quot;</td><td>-0.410351</td></tr><tr><td>0.846681</td><td>-0.99011</td><td>&quot;subtract&quot;</td><td>-0.406913</td></tr><tr><td>0.336244</td><td>0.043056</td><td>&quot;divide&quot;</td><td>-0.410354</td></tr><tr><td>1.622331</td><td>-0.777194</td><td>&quot;multiply&quot;</td><td>1.35483</td></tr><tr><td>-1.0474</td><td>-0.145427</td><td>&quot;multiply&quot;</td><td>0.192173</td></tr><tr><td>0.55095</td><td>-0.853984</td><td>&quot;subtract&quot;</td><td>-0.407723</td></tr><tr><td>1.709486</td><td>0.4846</td><td>&quot;multiply&quot;</td><td>3.7469</td></tr><tr><td>0.714232</td><td>-1.164632</td><td>&quot;divide&quot;</td><td>-0.410334</td></tr><tr><td>-0.093761</td><td>-1.0669</td><td>&quot;multiply&quot;</td><td>0.197621</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1.366175</td><td>1.505544</td><td>&quot;divide&quot;</td><td>-0.410355</td></tr><tr><td>1.600914</td><td>-0.882463</td><td>&quot;subtract&quot;</td><td>-0.405697</td></tr><tr><td>-0.959116</td><td>1.317061</td><td>&quot;divide&quot;</td><td>-0.41036</td></tr><tr><td>-0.59361</td><td>-1.65782</td><td>&quot;subtract&quot;</td><td>-0.408373</td></tr><tr><td>-0.502959</td><td>1.456678</td><td>&quot;add&quot;</td><td>-0.40204</td></tr><tr><td>1.210125</td><td>0.130316</td><td>&quot;add&quot;</td><td>-0.401297</td></tr><tr><td>0.398664</td><td>-0.034867</td><td>&quot;add&quot;</td><td>-0.40313</td></tr><tr><td>0.710765</td><td>1.529977</td><td>&quot;subtract&quot;</td><td>-0.411873</td></tr><tr><td>0.013741</td><td>1.486612</td><td>&quot;subtract&quot;</td><td>-0.413102</td></tr><tr><td>-1.539825</td><td>0.591053</td><td>&quot;divide&quot;</td><td>-0.410361</td></tr><tr><td>-0.721429</td><td>-1.011053</td><td>&quot;add&quot;</td><td>-0.407058</td></tr><tr><td>-1.403492</td><td>-0.707386</td><td>&quot;subtract&quot;</td><td>-0.411669</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_000, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ -0.222069 ┆ -0.093071 ┆ divide    ┆ -0.410356 │\n",
       "│ -0.760505 ┆ 1.052537  ┆ multiply  ┆ 1.074778  │\n",
       "│ -0.596589 ┆ 0.714712  ┆ add       ┆ -0.403601 │\n",
       "│ 1.45287   ┆ 0.309759  ┆ divide    ┆ -0.410351 │\n",
       "│ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 0.013741  ┆ 1.486612  ┆ subtract  ┆ -0.413102 │\n",
       "│ -1.539825 ┆ 0.591053  ┆ divide    ┆ -0.410361 │\n",
       "│ -0.721429 ┆ -1.011053 ┆ add       ┆ -0.407058 │\n",
       "│ -1.403492 ┆ -0.707386 ┆ subtract  ┆ -0.411669 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = hp.TabularDataset(\n",
    "    test,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=False,\n",
    "    max_row_length=18,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(res):\n",
    "\n",
    "    def replacer(x):\n",
    "        x = x.replace(\"  \", \":\")\n",
    "        x = x.replace(\" ,\", \",\")\n",
    "        return x\n",
    "\n",
    "    actuals = [str(i.value) for i in res[\"targets\"]]\n",
    "    actuals_ = \" \".join(actuals)\n",
    "    actual_str = actuals_.split(\"<row-end>\")[0]\n",
    "    actual_str = replacer(actual_str)\n",
    "    masked_str = [str(i.value) for i in res[\"data\"]]\n",
    "    masked_str = \" \".join(masked_str)\n",
    "    masked_str = masked_str.split(\"<row-end>\")[0]\n",
    "    masked_str = replacer(masked_str)\n",
    "    lsm = nn.Softmax(dim=0)\n",
    "    softmax_cats = lsm(res[\"class_output\"])\n",
    "    softmax_cats = torch.argmax(softmax_cats, dim=1)\n",
    "    gen_tokens = []\n",
    "    for idx, pred in enumerate(softmax_cats):\n",
    "        token = tokens[pred - 1]\n",
    "        if token == \"<numeric>\":\n",
    "            gen_tokens.append(str(res[\"numeric_output\"][idx].item()))\n",
    "        else:\n",
    "            gen_tokens.append(token)\n",
    "    preds = \" \".join(gen_tokens)\n",
    "    preds = replacer(preds)\n",
    "    \n",
    "    s = (\n",
    "        f\"Targets   : {actual_str}\\n\"\n",
    "        + f\"Masked    : {masked_str}\\n\"\n",
    "        + f\"Predicted : {preds.split('<row-end>')[0]}\"\n",
    "    )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0\n",
      "Targets   : <row-start> num1 : 0.627537880086947, num2 : -1.4249174175476262, operation : multiply, result : 0.006089391901095394, \n",
      "Masked    : <row-start> num1 : 0.627537880086947, num2 : -1.4249174175476262, operation : multiply, result : 0.006089391901095394, \n",
      "Predicted : <row-start> num1 : 0.746845006942749, num2 : subtract, operation : multiply, result : -0.0796755775809288, \n",
      "\n",
      "Row 1\n",
      "Targets   : <row-start> num1 : -0.21727413399197865, num2 : -1.6463103806205621, operation : multiply, result : -0.3242663783358256, \n",
      "Masked    : <row-start> num1 : -0.21727413399197865, num2 : -1.6463103806205621, operation : multiply, result : -0.3242663783358256, \n",
      "Predicted : <row-start> num1 : -0.2761440575122833, num2 : subtract, operation : multiply, result : -0.31431835889816284, \n",
      "\n",
      "Row 2\n",
      "Targets   : <row-start> num1 : 0.4922944119488227, num2 : -1.1597225240082345, operation : add, result : -0.4050543816063307, \n",
      "Masked    : <row-start> num1 : 0.4922944119488227, num2 : -1.1597225240082345, operation : add, <mask> : -0.4050543816063307, \n",
      "Predicted : <row-start> num1 : 0.597592830657959, num2 : subtract, operation : add, result : -0.4656722843647003, \n",
      "\n",
      "Row 3\n",
      "Targets   : <row-start> num1 : 0.2980986628274134, num2 : 0.3281232982046361, operation : add, result : -0.4026414763754813, \n",
      "Masked    : <row-start> <mask> : 0.2980986628274134, num2 : <numeric_mask>, operation : add, <mask> : -0.4026414763754813, \n",
      "Predicted : <row-start> result : 0.4876459836959839, num2 : -0.18969981372356415, operation : <pad>, result : -0.554686427116394, \n",
      "\n",
      "Row 4\n",
      "Targets   : <row-start> num1 : 1.5326287822420868, num2 : 0.1418872688472103, operation : subtract, result : -0.4077374472967699, \n",
      "Masked    : <row-start> num1 : 1.5326287822420868, num2 : 0.1418872688472103, operation : subtract, result : -0.4077374472967699, \n",
      "Predicted : <row-start> num1 : subtract, num2 : 0.2131994068622589, operation : subtract, result : -0.5440848469734192, \n",
      "\n",
      "Row 5\n",
      "Targets   : <row-start> num1 : -0.719697155884671, num2 : -0.3862665799710027, operation : add, result : -0.40588791345890773, \n",
      "Masked    : <row-start> num1 : <numeric_mask>, num2 : -0.3862665799710027, operation : add, result : -0.40588791345890773, \n",
      "Predicted : <row-start> num1 : -0.10331123322248459, num2 : -0.5987114906311035, operation : add, result : -0.5253350734710693, \n",
      "\n",
      "Row 6\n",
      "Targets   : <row-start> num1 : 1.6768448410186372, num2 : -1.126236900574068, operation : add, result : -0.40276584005801164, \n",
      "Masked    : <row-start> num1 : <numeric_mask>, num2 : -1.126236900574068, <mask> : add, result : -0.40276584005801164, \n",
      "Predicted : <row-start> num1 : -0.06223365291953087, num2 : -1.0088807344436646, operation : add, result : -0.43729862570762634, \n",
      "\n",
      "Row 7\n",
      "Targets   : <row-start> num1 : 1.0679460968444288, num2 : 0.32578033230741865, operation : divide, result : -0.4103527426792386, \n",
      "Masked    : <row-start> <mask> : 1.0679460968444288, num2 : 0.32578033230741865, operation : divide, <mask> : -0.4103527426792386, \n",
      "Predicted : <row-start> result : 1.504229187965393, num2 : 0.5459406971931458, operation : divide, result : -0.5973004698753357, \n",
      "\n",
      "Row 8\n",
      "Targets   : <row-start> num1 : 0.8344886380314569, num2 : -0.16986016545501192, operation : subtract, result : -0.40846736244358517, \n",
      "Masked    : <row-start> <mask> : 0.8344886380314569, num2 : -0.16986016545501192, operation : subtract, result : -0.40846736244358517, \n",
      "Predicted : <row-start> result : num1, num2 : -0.31731298565864563, operation : subtract, result : -0.5374314188957214, \n",
      "\n",
      "Row 9\n",
      "Targets   : <row-start> num1 : 0.48972924482543834, num2 : 1.0901836351945475, operation : multiply, result : 3.0071781849695562, \n",
      "Masked    : <row-start> <mask> : <numeric_mask>, num2 : 1.0901836351945475, operation : multiply, result : 3.0071781849695562, \n",
      "Predicted : <row-start> result : -0.15376323461532593, num2 : 1.4277478456497192, operation : divide, result : num1, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = evaluate(model, ds, i)\n",
    "    print(f\"Row {i}\")\n",
    "    print(show_results(res))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, ds, idx) -> None:\n",
    "    model.eval()  # turn on train mode\n",
    "    n_row = 1  # one because it's not time series\n",
    "    with torch.no_grad():\n",
    "        data, targets = hp.batch_data(ds, idx, n_row=n_row)\n",
    "        class_output, numeric_output = model(data)\n",
    "        loss, loss_dict = hp.hephaestus_loss(\n",
    "            class_output, numeric_output, targets, tokens, special_tokens, device\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss.item(),\n",
    "            \"loss_dict\": loss_dict,\n",
    "            \"data\": data,\n",
    "            \"targets\": targets,\n",
    "            \"class_output\": class_output,\n",
    "            \"numeric_output\": numeric_output,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(model, ds_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StringNumeric' object has no attribute 'numeric_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     pred_str \u001b[39m=\u001b[39m prediction_str(d[\u001b[39m\"\u001b[39m\u001b[39mclass_output\u001b[39m\u001b[39m\"\u001b[39m], d[\u001b[39m\"\u001b[39m\u001b[39mnumeric_output\u001b[39m\u001b[39m\"\u001b[39m], tokens)\n\u001b[1;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData  : \u001b[39m\u001b[39m{\u001b[39;00mdata_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mTarget: \u001b[39m\u001b[39m{\u001b[39;00mtarget_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mPredict: \u001b[39m\u001b[39m{\u001b[39;00mpred_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m print_results(res)\n",
      "Cell \u001b[0;32mIn[34], line 28\u001b[0m, in \u001b[0;36mprint_results\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_results\u001b[39m(d: \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m     data_str \u001b[39m=\u001b[39m make_str(d[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     29\u001b[0m     target_str \u001b[39m=\u001b[39m make_str(d[\u001b[39m\"\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m     pred_str \u001b[39m=\u001b[39m prediction_str(d[\u001b[39m\"\u001b[39m\u001b[39mclass_output\u001b[39m\u001b[39m\"\u001b[39m], d[\u001b[39m\"\u001b[39m\u001b[39mnumeric_output\u001b[39m\u001b[39m\"\u001b[39m], tokens)\n",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m, in \u001b[0;36mmake_str\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m l:\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m i\u001b[39m.\u001b[39mis_numeric:\n\u001b[0;32m----> 5\u001b[0m         result_list\u001b[39m.\u001b[39mappend(i\u001b[39m.\u001b[39;49mnumeric_value)\n\u001b[1;32m      6\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         result_list\u001b[39m.\u001b[39mappend(i\u001b[39m.\u001b[39mvalue)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StringNumeric' object has no attribute 'numeric_value'"
     ]
    }
   ],
   "source": [
    "def make_str(l: list):\n",
    "    result_list = []\n",
    "    for i in l:\n",
    "        if i.is_numeric:\n",
    "            result_list.append(i.numeric_value)\n",
    "        else:\n",
    "            result_list.append(i.value)\n",
    "    result_list = [str(i) for i in result_list]\n",
    "    return \" \".join(result_list).split(\"<row-end>\")[0]\n",
    "\n",
    "\n",
    "def prediction_str(class_output, numeric_output, tokens):\n",
    "    lsm = nn.Softmax(dim=0)\n",
    "    softmax_cats = lsm(class_output)\n",
    "    softmax_cats = torch.argmax(softmax_cats, dim=1)\n",
    "    gen_tokens = []\n",
    "    for idx, pred in enumerate(softmax_cats):\n",
    "        token = tokens[pred]\n",
    "        if token == \"<numeric>\":\n",
    "            gen_tokens.append(str(numeric_output[idx].item()))\n",
    "        else:\n",
    "            gen_tokens.append(token)\n",
    "    preds = \" \".join(gen_tokens).split(\"<row-end>\")[0]\n",
    "    return preds\n",
    "\n",
    "\n",
    "def print_results(d: dict):\n",
    "    data_str = make_str(d[\"data\"])\n",
    "    target_str = make_str(d[\"targets\"])\n",
    "    pred_str = prediction_str(d[\"class_output\"], d[\"numeric_output\"], tokens)\n",
    "    print(f\"Data  : {data_str}\\nTarget: {target_str}\\nPredict: {pred_str}\")\n",
    "\n",
    "\n",
    "print_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 41])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"class_output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"numeric_output\"][:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((res[\"numeric_output\"][None, :], res[\"class_output\"].T)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_str(class_output, numeric_output, tokens):\n",
    "    lsm = nn.Softmax(dim=0)\n",
    "    softmax_cats = lsm(class_output)\n",
    "    softmax_cats = torch.argmax(softmax_cats, dim=1)\n",
    "    gen_tokens = []\n",
    "    for idx, pred in enumerate(softmax_cats):\n",
    "        token = tokens[pred]\n",
    "        if token == \"<numeric>\":\n",
    "            gen_tokens.append(str(numeric_output[idx].item()))\n",
    "        else:\n",
    "            gen_tokens.append(token)\n",
    "    preds = \" \".join(gen_tokens).split(\"<row-end>\")[0]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_data(N):\n",
    "    x = torch.randint(1, 100, (N, 2), dtype=torch.float32)\n",
    "    y_mul = x[:, 0] * x[:, 1]\n",
    "    y_div = x[:, 0] / x[:, 1]\n",
    "    y = torch.stack((y_mul, y_div), dim=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MathNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MathNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5478397.5\n",
      "Epoch 100, Loss: 1675928.875\n",
      "Epoch 200, Loss: 784210.25\n",
      "Epoch 300, Loss: 779894.25\n",
      "Epoch 400, Loss: 775376.625\n",
      "Epoch 500, Loss: 770643.8125\n",
      "Epoch 600, Loss: 765713.625\n",
      "Epoch 700, Loss: 760585.8125\n",
      "Epoch 800, Loss: 755247.5\n",
      "Epoch 900, Loss: 749672.125\n"
     ]
    }
   ],
   "source": [
    "N = 1000000\n",
    "data_x, data_y = generate_data(N)\n",
    "\n",
    "# Split into training and testing\n",
    "train_x, test_x = data_x[:8000], data_x[8000:]\n",
    "train_y, test_y = data_y[:8000], data_y[8000:]\n",
    "\n",
    "model = MathNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    outputs = model(train_x)\n",
    "    loss = criterion(outputs, train_y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 737482.3125\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs = model(test_x)\n",
    "    test_loss = criterion(test_outputs, test_y)\n",
    "    print(f\"Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992000, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3350e+03, 5.9333e+00],\n",
       "        [7.4000e+01, 1.8500e+01],\n",
       "        [2.7600e+02, 1.7250e+01],\n",
       "        ...,\n",
       "        [9.8600e+02, 8.5294e-01],\n",
       "        [9.0000e+02, 1.1111e-01],\n",
       "        [2.5550e+03, 2.0857e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.5403e+03, -6.8926e-01],\n",
       "        [ 5.4591e+03, -7.7647e-01],\n",
       "        [ 1.7531e+03,  9.1369e+00],\n",
       "        ...,\n",
       "        [ 8.5710e+02,  8.9137e-01],\n",
       "        [ 6.9791e+03, -1.7934e+00],\n",
       "        [ 5.2343e+01,  1.2579e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N):\n",
    "    x = torch.randint(1, 1000, (N, 2), dtype=torch.float32)\n",
    "    y_mul = x[:, 0] * x[:, 1]\n",
    "    y_div = x[:, 0] / x[:, 1]\n",
    "    y = torch.stack((y_mul, y_div), dim=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        N = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.nn.Softmax(dim=3)(energy)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 256), nn.ReLU(), nn.Linear(256, embed_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally feed forward\n",
    "        x = self.norm1(attention + query)\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.norm2(forward + x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MathNet(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MathNet, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.fc1 = nn.Linear(2, embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads)\n",
    "        self.fc2 = nn.Linear(embed_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.repeat(1, 3, 1)  # Repeat x three times to form keys, values, queries\n",
    "        x = self.transformer_block(x, x, x, mask=None)\n",
    "        x = self.fc2(x[:, 0, :])  # We only need the first result from the sequence\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8000, 2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5377728.5\n",
      "Epoch 100, Loss: 4712922.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    483\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    484\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[0;32m--> 491\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    492\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    493\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/autograd/__init__.py:204\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    201\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    206\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MathNet(embed_size=64, heads=4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    outputs = model(train_x)\n",
    "    loss = criterion(outputs, train_y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
