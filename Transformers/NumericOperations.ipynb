{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diamond Transformer\n",
    "\n",
    "This notebook investigates the use of a transformer to predict the price of diamonds. The dataset is from Kaggle and can be found [here](https://www.kaggle.com/shivam2503/diamonds).\n",
    "\n",
    "While many traditional ML and DL techniques work on the dataset, our approach uses far less labeled data while achieving similar results. This is done by using a transformer.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import hephaestus as hp\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diamonds dataset: df = pl.read_csv(\"../data/diamonds.csv\") df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>7.0</td><td>9.0</td><td>&quot;multiply&quot;</td><td>63.0</td></tr><tr><td>1.627391</td><td>3.0</td><td>&quot;multiply&quot;</td><td>4.882173</td></tr><tr><td>6.0</td><td>3.0</td><td>&quot;subtract&quot;</td><td>3.0</td></tr><tr><td>8.0</td><td>7.0</td><td>&quot;add&quot;</td><td>15.0</td></tr><tr><td>2.0</td><td>8.610289</td><td>&quot;add&quot;</td><td>10.610289</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────┬──────────┬───────────┬───────────┐\n",
       "│ num1     ┆ num2     ┆ operation ┆ result    │\n",
       "│ ---      ┆ ---      ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64      ┆ str       ┆ f64       │\n",
       "╞══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ 7.0      ┆ 9.0      ┆ multiply  ┆ 63.0      │\n",
       "│ 1.627391 ┆ 3.0      ┆ multiply  ┆ 4.882173  │\n",
       "│ 6.0      ┆ 3.0      ┆ subtract  ┆ 3.0       │\n",
       "│ 8.0      ┆ 7.0      ┆ add       ┆ 15.0      │\n",
       "│ 2.0      ┆ 8.610289 ┆ add       ┆ 10.610289 │\n",
       "└──────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to generate a random number, either integer or float\n",
    "def generate_random_number():\n",
    "    return random.randint(1, 10) if random.random() < 0.5 else random.uniform(1, 10)\n",
    "\n",
    "\n",
    "# Number of rows in the DataFrame\n",
    "n_rows = 100_000\n",
    "\n",
    "# Generate random values for num1 and num2 (both integers and floats)\n",
    "num1 = [generate_random_number() for _ in range(n_rows)]\n",
    "num2 = [generate_random_number() for _ in range(n_rows)]\n",
    "\n",
    "# Randomly choose an operation for each row\n",
    "operations = [\n",
    "    random.choice([\"multiply\", \"divide\", \"add\", \"subtract\"]) for _ in range(n_rows)\n",
    "]\n",
    "\n",
    "# Create a DataFrame with the columns num1, num2, and operation\n",
    "df = pl.DataFrame({\"num1\": num1, \"num2\": num2, \"operation\": operations})\n",
    "\n",
    "# Apply the operation to each row to create the result column\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"operation\") == \"multiply\")\n",
    "    .then(pl.col(\"num1\") * pl.col(\"num2\"))\n",
    "    .when(pl.col(\"operation\") == \"divide\")\n",
    "    .then(pl.col(\"num1\") / pl.col(\"num2\"))\n",
    "    .when(pl.col(\"operation\") == \"add\")\n",
    "    .then(pl.col(\"num1\") + pl.col(\"num2\"))\n",
    "    .when(pl.col(\"operation\") == \"subtract\")\n",
    "    .then(pl.col(\"num1\") - pl.col(\"num2\"))\n",
    "    .otherwise(None)\n",
    "    .alias(\"result\")\n",
    ")\n",
    "\n",
    "\n",
    "# Print the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>100000.0</td><td>100000.0</td><td>&quot;100000&quot;</td><td>100000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>5.496155</td><td>5.499495</td><td>null</td><td>10.658448</td></tr><tr><td>&quot;std&quot;</td><td>2.741764</td><td>2.741762</td><td>null</td><td>16.747226</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>&quot;add&quot;</td><td>-9.0</td></tr><tr><td>&quot;max&quot;</td><td>10.0</td><td>10.0</td><td>&quot;subtract&quot;</td><td>100.0</td></tr><tr><td>&quot;median&quot;</td><td>5.498269</td><td>5.485602</td><td>null</td><td>5.022965</td></tr><tr><td>&quot;25%&quot;</td><td>3.0</td><td>3.0</td><td>null</td><td>0.866335</td></tr><tr><td>&quot;75%&quot;</td><td>8.0</td><td>8.0</td><td>null</td><td>13.218557</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 5)\n",
       "┌────────────┬──────────┬──────────┬───────────┬───────────┐\n",
       "│ describe   ┆ num1     ┆ num2     ┆ operation ┆ result    │\n",
       "│ ---        ┆ ---      ┆ ---      ┆ ---       ┆ ---       │\n",
       "│ str        ┆ f64      ┆ f64      ┆ str       ┆ f64       │\n",
       "╞════════════╪══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 100000.0 ┆ 100000.0 ┆ 100000    ┆ 100000.0  │\n",
       "│ null_count ┆ 0.0      ┆ 0.0      ┆ 0         ┆ 0.0       │\n",
       "│ mean       ┆ 5.496155 ┆ 5.499495 ┆ null      ┆ 10.658448 │\n",
       "│ std        ┆ 2.741764 ┆ 2.741762 ┆ null      ┆ 16.747226 │\n",
       "│ min        ┆ 1.0      ┆ 1.0      ┆ add       ┆ -9.0      │\n",
       "│ max        ┆ 10.0     ┆ 10.0     ┆ subtract  ┆ 100.0     │\n",
       "│ median     ┆ 5.498269 ┆ 5.485602 ┆ null      ┆ 5.022965  │\n",
       "│ 25%        ┆ 3.0      ┆ 3.0      ┆ null      ┆ 0.866335  │\n",
       "│ 75%        ┆ 8.0      ┆ 8.0      ┆ null      ┆ 13.218557 │\n",
       "└────────────┴──────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.548495</td><td>1.276735</td><td>&quot;multiply&quot;</td><td>3.125386</td></tr><tr><td>-1.411049</td><td>-0.911638</td><td>&quot;multiply&quot;</td><td>-0.344909</td></tr><tr><td>0.183767</td><td>-0.911638</td><td>&quot;subtract&quot;</td><td>-0.457297</td></tr><tr><td>0.913224</td><td>0.547277</td><td>&quot;add&quot;</td><td>0.25924</td></tr><tr><td>-1.275148</td><td>1.134596</td><td>&quot;add&quot;</td><td>-0.002876</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.548495  ┆ 1.276735  ┆ multiply  ┆ 3.125386  │\n",
       "│ -1.411049 ┆ -0.911638 ┆ multiply  ┆ -0.344909 │\n",
       "│ 0.183767  ┆ -0.911638 ┆ subtract  ┆ -0.457297 │\n",
       "│ 0.913224  ┆ 0.547277  ┆ add       ┆ 0.25924   │\n",
       "│ -1.275148 ┆ 1.134596  ┆ add       ┆ -0.002876 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hp.scale_numeric(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hp.make_lower_remove_special_chars(df)\n",
    "val_tokens = hp.get_unique_utf8_values(df)\n",
    "col_tokens = hp.get_col_tokens(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.548495</td><td>1.276735</td><td>&quot;multiply&quot;</td><td>3.125386</td></tr><tr><td>-1.411049</td><td>-0.911638</td><td>&quot;multiply&quot;</td><td>-0.344909</td></tr><tr><td>0.183767</td><td>-0.911638</td><td>&quot;subtract&quot;</td><td>-0.457297</td></tr><tr><td>0.913224</td><td>0.547277</td><td>&quot;add&quot;</td><td>0.25924</td></tr><tr><td>-1.275148</td><td>1.134596</td><td>&quot;add&quot;</td><td>-0.002876</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.548495  ┆ 1.276735  ┆ multiply  ┆ 3.125386  │\n",
       "│ -1.411049 ┆ -0.911638 ┆ multiply  ┆ -0.344909 │\n",
       "│ 0.183767  ┆ -0.911638 ┆ subtract  ┆ -0.457297 │\n",
       "│ 0.913224  ┆ 0.547277  ┆ add       ┆ 0.25924   │\n",
       "│ -1.275148 ┆ 1.134596  ┆ add       ┆ -0.002876 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = np.array(\n",
    "    [\n",
    "        \"missing\",\n",
    "        \"<mask>\",\n",
    "        \"<numeric_mask>\",\n",
    "        \"<pad>\",\n",
    "        \"<unk>\",\n",
    "        \":\",\n",
    "        \",\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', ':', '<mask>', '<numeric>', '<numeric_mask>', '<pad>',\n",
       "       '<row-end>', '<row-start>', '<unk>', 'add', 'divide', 'missing',\n",
       "       'multiply', 'num1', 'num2', 'operation', 'result', 'subtract'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = np.unique(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            val_tokens,\n",
    "            col_tokens,\n",
    "            special_tokens,\n",
    "            [\n",
    "                \"<numeric>\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "To show the actual model performance out of sample we split the data into a training and test set. The training set will be used to train the model and the test set will be used to evaluate the model performance. We will use 80% of the data for training and 20% for testing.\n",
    "\n",
    "We also remove the price column from the training and test sets and will only use a tiny subset of the data to simulate an industrial process with lots of input data but expensive and limited labeled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.548495</td><td>1.276735</td><td>&quot;multiply&quot;</td><td>3.125386</td></tr><tr><td>-1.411049</td><td>-0.911638</td><td>&quot;multiply&quot;</td><td>-0.344909</td></tr><tr><td>0.183767</td><td>-0.911638</td><td>&quot;subtract&quot;</td><td>-0.457297</td></tr><tr><td>0.913224</td><td>0.547277</td><td>&quot;add&quot;</td><td>0.25924</td></tr><tr><td>-1.275148</td><td>1.134596</td><td>&quot;add&quot;</td><td>-0.002876</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.548495  ┆ 1.276735  ┆ multiply  ┆ 3.125386  │\n",
       "│ -1.411049 ┆ -0.911638 ┆ multiply  ┆ -0.344909 │\n",
       "│ 0.183767  ┆ -0.911638 ┆ subtract  ┆ -0.457297 │\n",
       "│ 0.913224  ┆ 0.547277  ┆ add       ┆ 0.25924   │\n",
       "│ -1.275148 ┆ 1.134596  ┆ add       ┆ -0.002876 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle for randomness\n",
    "df = df.sample(fraction=1.0, seed=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "n_train = int(train_fraction * len(df))\n",
    "train_test_df = df.select(pl.all())\n",
    "\n",
    "train, test = train_test_df.head(n_train), train_test_df.tail(\n",
    "    len(train_test_df) - n_train\n",
    ")\n",
    "\n",
    "labeled_train, labeled_test = df.head(n_train), df.tail(len(df) - n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(shape: (5, 4)\n",
       " ┌───────────┬───────────┬───────────┬───────────┐\n",
       " │ num1      ┆ num2      ┆ operation ┆ result    │\n",
       " │ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       " │ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       " ╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       " │ 0.548495  ┆ 1.276735  ┆ multiply  ┆ 3.125386  │\n",
       " │ -1.411049 ┆ -0.911638 ┆ multiply  ┆ -0.344909 │\n",
       " │ 0.183767  ┆ -0.911638 ┆ subtract  ┆ -0.457297 │\n",
       " │ 0.913224  ┆ 0.547277  ┆ add       ┆ 0.25924   │\n",
       " │ -1.275148 ┆ 1.134596  ┆ add       ┆ -0.002876 │\n",
       " └───────────┴───────────┴───────────┴───────────┘,\n",
       " (80000, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(), train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num1</th><th>num2</th><th>operation</th><th>result</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0.548495</td><td>1.276735</td><td>&quot;multiply&quot;</td><td>3.125386</td></tr><tr><td>-1.411049</td><td>-0.911638</td><td>&quot;multiply&quot;</td><td>-0.344909</td></tr><tr><td>0.183767</td><td>-0.911638</td><td>&quot;subtract&quot;</td><td>-0.457297</td></tr><tr><td>0.913224</td><td>0.547277</td><td>&quot;add&quot;</td><td>0.25924</td></tr><tr><td>-1.275148</td><td>1.134596</td><td>&quot;add&quot;</td><td>-0.002876</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────┬───────────┬───────────┬───────────┐\n",
       "│ num1      ┆ num2      ┆ operation ┆ result    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       ┆ str       ┆ f64       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0.548495  ┆ 1.276735  ┆ multiply  ┆ 3.125386  │\n",
       "│ -1.411049 ┆ -0.911638 ┆ multiply  ┆ -0.344909 │\n",
       "│ 0.183767  ┆ -0.911638 ┆ subtract  ┆ -0.457297 │\n",
       "│ 0.913224  ┆ 0.547277  ┆ add       ┆ 0.25924   │\n",
       "│ -1.275148 ┆ 1.134596  ┆ add       ┆ -0.002876 │\n",
       "└───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "ds = hp.TabularDataset(\n",
    "    train,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=False,\n",
    "    max_row_length=19,\n",
    ")\n",
    "\n",
    "print(len(ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<row-start>', 'num1', ':', 0.5484952344853055, ',', 'num2', ':', 1.2767353074563859, ',', 'operation', ':', 'multiply', ',', 'result', ':', 3.1253863503051096, ',', '<row-end>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print([i.value for i in ds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    device_name = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:218: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because  self.layers[0].self_attn.batch_first was not True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "n_token = len(ds.vocab)  # size of vocabulary\n",
    "d_model = 96  # embedding dimension\n",
    "d_hid = 1_000  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "n_layers = 12  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "n_head = 12  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = hp.TransformerModel(\n",
    "    n_token, d_model, n_head, d_hid, n_layers, device, dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StringNumericEmbedding(nn.Module):\n",
    "#     def __init__(self, n_token: int, d_model: int, device: torch.device):\n",
    "#         super().__init__()\n",
    "#         self.device = device\n",
    "#         self.embedding = nn.Embedding(n_token + 1, d_model).to(device)  # padding_idx=0\n",
    "#         self.numeric_embedding = nn.Linear(1, d_model).to(device)\n",
    "\n",
    "#     def forward(self, input: hp.StringNumeric):\n",
    "#         embedding_tensor = torch.zeros(\n",
    "#             (len(input), self.embedding.embedding_dim), dtype=torch.float32\n",
    "#         ).to(self.device)\n",
    "#         for idx, val in enumerate(input):\n",
    "#             if val.is_numeric:\n",
    "#                 print(\"numeric\")\n",
    "#                 val = torch.Tensor([val.value]).float().to(self.device)\n",
    "#                 embedding_tensor[idx] = self.numeric_embedding(val)\n",
    "#             else:\n",
    "#                 print(\"non-numeric\")\n",
    "#                 embed_idx = torch.Tensor([val.embedding_idx]).long().to(self.device)\n",
    "#                 embedding_tensor[idx] = self.embedding(embed_idx)\n",
    "\n",
    "#         embedding = torch.Tensor(embedding_list).to(self.device)\n",
    "\n",
    "\n",
    "# x = hp.StringNumericEmbedding(d_model=32, n_token=tokens.shape[0], device=device)\n",
    "# data, targets = hp.batch_data(ds, 1, n_row=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model out:\n",
    "with torch.no_grad():\n",
    "    data, targets = hp.batch_data(ds, 1, n_row=1)\n",
    "    class_out, numeric_out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "lr = 0.9  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size =100, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.8,\n",
    "    patience=5,\n",
    "    threshold=0.001,\n",
    "    threshold_mode=\"rel\",\n",
    "    cooldown=0,\n",
    "    min_lr=0.01,\n",
    "    eps=1e-08,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "def train(model: nn.Module, epochs=1, model_name=\"\") -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 1000\n",
    "    lr_eval_interval = 25\n",
    "    n_row = 100  # one because it's not time series\n",
    "    start_time = time.time()\n",
    "    for epoch in trange(1, epochs + 1, leave=True, desc=\"Epoch\"):\n",
    "        pbar = trange(0, len(ds) - 1, n_row, desc=f\"Batch for {epoch}/{epochs}\")\n",
    "        writer = SummaryWriter(\"runs/\" + model_name + \"_run_\" + str(epoch))\n",
    "        for batch, i in enumerate(pbar):\n",
    "            data, targets = hp.batch_data(ds, i, n_row=n_row)\n",
    "            class_output, numeric_output = model(data)\n",
    "            loss, loss_dict = hp.hephaestus_loss(\n",
    "                class_output, numeric_output, targets, tokens, special_tokens, device\n",
    "            )\n",
    "            num_loss = loss_dict[\"reg_loss\"].item()\n",
    "            class_loss = loss_dict[\"class_loss\"].item()\n",
    "            writer.add_scalar(\"Loss/total_loss\", loss, batch)\n",
    "            writer.add_scalar(\"Loss/numeric_loss\", num_loss, batch)\n",
    "            writer.add_scalar(\"Loss/class_loss\", class_loss, batch)\n",
    "            writer.add_scalar(\n",
    "                \"Metrics/learning_rate\", optimizer.param_groups[0][\"lr\"], batch\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    \"tl\": f\"{loss:.2f}\",\n",
    "                    \"cl\": f\"{class_loss:.2f}\",\n",
    "                    \"nl\": f\"{num_loss:.2f}\",\n",
    "                    \"tr\": f\"{optimizer.param_groups[0]['lr']:.2f}\",\n",
    "                },\n",
    "                refresh=True,\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            if batch % lr_eval_interval == 0:\n",
    "                # pbar.set_p(\n",
    "                #     f\"tl: {}, nl: {num_loss:.2f}, cl: {class_loss:.2f}, tr: {optimizer.param_groups[0]['lr']:.2f}\"\n",
    "                # )\n",
    "\n",
    "                scheduler.step(loss)\n",
    "\n",
    "                # if batch % log_interval == 0:\n",
    "                #     # lr = scheduler.get_last_lr()[0]\n",
    "                #     lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "                #     ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "                #     cur_loss = total_loss / log_interval\n",
    "                #     ppl = math.exp(cur_loss)\n",
    "                #     print(  # f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                #         f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \",\n",
    "                #         f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\",\n",
    "                #         f\"num_loss {num_loss:5.2f} | class_loss {class_loss:5.2f}\",\n",
    "                #     )\n",
    "                #     total_loss = 0\n",
    "                start_time = time.time()\n",
    "                # scheduler.step(loss)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e196cd8289c141e09c9d3555b1d8bffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8f1cd9018c48e69a25dc222de46429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch for 1/3:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bba3e0938fb406a8a01d264f156de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch for 2/3:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a7a058b60f4ea281800e160ef51504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch for 3/3:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "exp_name = \"shorter_positional_encoding\"\n",
    "\n",
    "model_name = model_time + \"_\" + exp_name\n",
    "epochs = 3\n",
    "train(model=model, epochs=epochs, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 2,791,698\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# model = CustomNumericAttention(d_model=512, n_head=8) # Replace with your model\n",
    "param_count = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {param_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "save_model = True\n",
    "if save_model:\n",
    "    MODEL_PATH = \"models/\" + model_name + \".pth\"\n",
    "    torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = hp.TabularDataset(\n",
    "    test,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=False,\n",
    "    max_row_length=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, ds, idx) -> None:\n",
    "    model.eval()  # turn on train mode\n",
    "    n_row = 1  # one because it's not time series\n",
    "    with torch.no_grad():\n",
    "        data, targets = hp.batch_data(ds, idx, n_row=n_row)\n",
    "        class_output, numeric_output = model(data)\n",
    "        loss, loss_dict = hp.hephaestus_loss(\n",
    "            class_output, numeric_output, targets, tokens, special_tokens, device\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss.item(),\n",
    "            \"loss_dict\": loss_dict,\n",
    "            \"data\": data,\n",
    "            \"targets\": targets,\n",
    "            \"class_output\": class_output,\n",
    "            \"numeric_output\": numeric_output,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = hp.TabularDataset(\n",
    "    test,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=False,\n",
    "    max_row_length=18,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(res):\n",
    "    def replacer(x):\n",
    "        x = x.replace(\"  \", \":\")\n",
    "        x = x.replace(\" ,\", \",\")\n",
    "        return x\n",
    "\n",
    "    actuals = [str(i.value) for i in res[\"targets\"]]\n",
    "    actuals_ = \" \".join(actuals)\n",
    "    actual_str = actuals_.split(\"<row-end>\")[0]\n",
    "    actual_str = replacer(actual_str)\n",
    "    masked_str = [str(i.value) for i in res[\"data\"]]\n",
    "    masked_str = \" \".join(masked_str)\n",
    "    masked_str = masked_str.split(\"<row-end>\")[0]\n",
    "    masked_str = replacer(masked_str)\n",
    "    lsm = nn.Softmax(dim=0)\n",
    "    softmax_cats = lsm(res[\"class_output\"])\n",
    "    softmax_cats = torch.argmax(softmax_cats, dim=1)\n",
    "    gen_tokens = []\n",
    "    for idx, pred in enumerate(softmax_cats):\n",
    "        token = tokens[pred - 1]\n",
    "        if token == \"<numeric>\":\n",
    "            gen_tokens.append(str(res[\"numeric_output\"][idx].item()))\n",
    "        else:\n",
    "            gen_tokens.append(token)\n",
    "    preds = \" \".join(gen_tokens)\n",
    "    preds = replacer(preds)\n",
    "\n",
    "    s = (\n",
    "        f\"Targets   : {actual_str}\\n\"\n",
    "        + f\"Masked    : {masked_str}\\n\"\n",
    "        + f\"Predicted : {preds.split('<row-end>')[0]}\"\n",
    "    )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0\n",
      "Targets   : <row-start> num1 : 0.5484952344853055, num2 : 1.2767353074563859, operation : multiply, result : 3.1253863503051096, \n",
      "Masked    : <row-start> num1 : 0.5484952344853055, num2 : 1.2767353074563859, operation : multiply, result : 3.1253863503051096, \n",
      "Predicted : <row-start> num1 : 0.5693233609199524, num2 : 1.2691832780838013, operation : multiply, result : 3.2241780757904053, \n",
      "\n",
      "Row 1\n",
      "Targets   : <row-start> num1 : -1.4110493787569127, num2 : -0.9116383370904074, operation : multiply, result : -0.3449093638567237, \n",
      "Masked    : <row-start> num1 : <numeric_mask>, <mask> : -0.9116383370904074, <mask> : multiply, result : -0.3449093638567237, \n",
      "Predicted : <row-start> num1 : 0.010482162237167358, operation : -0.9196162223815918, num2 : multiply, result : divide, \n",
      "\n",
      "Row 2\n",
      "Targets   : <row-start> num1 : 0.18376654919364793, num2 : -0.9116383370904074, operation : subtract, result : -0.4572965150581714, \n",
      "Masked    : <row-start> num1 : 0.18376654919364793, num2 : -0.9116383370904074, <mask> : subtract, result : -0.4572965150581714, \n",
      "Predicted : <row-start> num1 : add, num2 : -0.9245350956916809, operation : subtract, result : divide, \n",
      "\n",
      "Row 3\n",
      "Targets   : <row-start> num1 : 0.913223919776963, num2 : 0.5472774259407881, operation : add, result : 0.25924005801448474, \n",
      "Masked    : <row-start> num1 : 0.913223919776963, num2 : 0.5472774259407881, operation : add, result : 0.25924005801448474, \n",
      "Predicted : <row-start> num1 : 1.0130380392074585, num2 : 0.6783446669578552, operation : add, result : 0.2156810760498047, \n",
      "\n",
      "Row 4\n",
      "Targets   : <row-start> num1 : -1.2751481919729823, num2 : 1.134596387097069, operation : add, result : -0.002875654948268834, \n",
      "Masked    : <row-start> num1 : -1.2751481919729823, num2 : 1.134596387097069, operation : add, result : -0.002875654948268834, \n",
      "Predicted : <row-start> num1 : <numeric_mask>, num2 : 1.1556254625320435, operation : add, result : -0.09012992680072784, \n",
      "\n",
      "Row 5\n",
      "Targets   : <row-start> num1 : 1.3141151780537716, num2 : 0.4447587180807888, operation : add, result : 0.3080879881902912, \n",
      "Masked    : <row-start> <mask> : 1.3141151780537716, num2 : <numeric_mask>, operation : add, result : 0.3080879881902912, \n",
      "Predicted : <row-start> num1 : 1.2691832780838013, num2 : 0.009577766060829163, operation : add, result : 0.29767587780952454, \n",
      "\n",
      "Row 6\n",
      "Targets   : <row-start> num1 : 0.5579427481475897, num2 : 0.912006366698587, operation : divide, result : -0.5839898629793608, \n",
      "Masked    : <row-start> num1 : 0.5579427481475897, num2 : 0.912006366698587, operation : divide, result : -0.5839898629793608, \n",
      "Predicted : <row-start> num1 : 0.6228762865066528, num2 : 0.9902698993682861, operation : divide, result : -0.5957240462303162, \n",
      "\n",
      "Row 7\n",
      "Targets   : <row-start> num1 : 1.5628195909533116, num2 : -0.5469093963326086, operation : multiply, result : 1.699726506594667, \n",
      "Masked    : <row-start> num1 : 1.5628195909533116, num2 : -0.5469093963326086, operation : multiply, result : 1.699726506594667, \n",
      "Predicted : <row-start> num1 : 1.352624773979187, num2 : -0.5172480344772339, operation : multiply, result : 1.6113431453704834, \n",
      "\n",
      "Row 8\n",
      "Targets   : <row-start> num1 : 1.642681290360278, num2 : 0.030956919919941032, operation : add, result : 0.29413371637380403, \n",
      "Masked    : <row-start> num1 : 1.642681290360278, num2 : 0.030956919919941032, operation : add, result : <numeric_mask>, \n",
      "Predicted : <row-start> num1 subtract missing, num2 : -0.06429797410964966, operation : add, result : 0.007145345211029053, \n",
      "\n",
      "Row 9\n",
      "Targets   : <row-start> num1 : 0.913223919776963, num2 : 1.2767353074563859, operation : add, result : 0.37866282019326075, \n",
      "Masked    : <row-start> <mask> : 0.913223919776963, num2 : 1.2767353074563859, operation : add, result : 0.37866282019326075, \n",
      "Predicted : <row-start> num1 : 0.9260894060134888, num2 : 1.2691832780838013, operation : add, result : 0.36150479316711426, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = evaluate(model, ds, i)\n",
    "    print(f\"Row {i}\")\n",
    "    print(show_results(res))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, ds, idx) -> None:\n",
    "    model.eval()  # turn on train mode\n",
    "    n_row = 1  # one because it's not time series\n",
    "    with torch.no_grad():\n",
    "        data, targets = hp.batch_data(ds, idx, n_row=n_row)\n",
    "        class_output, numeric_output = model(data)\n",
    "        loss, loss_dict = hp.hephaestus_loss(\n",
    "            class_output, numeric_output, targets, tokens, special_tokens, device\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss.item(),\n",
    "            \"loss_dict\": loss_dict,\n",
    "            \"data\": data,\n",
    "            \"targets\": targets,\n",
    "            \"class_output\": class_output,\n",
    "            \"numeric_output\": numeric_output,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(model, ds_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StringNumeric' object has no attribute 'numeric_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     pred_str \u001b[39m=\u001b[39m prediction_str(d[\u001b[39m\"\u001b[39m\u001b[39mclass_output\u001b[39m\u001b[39m\"\u001b[39m], d[\u001b[39m\"\u001b[39m\u001b[39mnumeric_output\u001b[39m\u001b[39m\"\u001b[39m], tokens)\n\u001b[1;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData  : \u001b[39m\u001b[39m{\u001b[39;00mdata_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mTarget: \u001b[39m\u001b[39m{\u001b[39;00mtarget_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mPredict: \u001b[39m\u001b[39m{\u001b[39;00mpred_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m print_results(res)\n",
      "Cell \u001b[0;32mIn[30], line 28\u001b[0m, in \u001b[0;36mprint_results\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_results\u001b[39m(d: \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m     data_str \u001b[39m=\u001b[39m make_str(d[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     29\u001b[0m     target_str \u001b[39m=\u001b[39m make_str(d[\u001b[39m\"\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m     pred_str \u001b[39m=\u001b[39m prediction_str(d[\u001b[39m\"\u001b[39m\u001b[39mclass_output\u001b[39m\u001b[39m\"\u001b[39m], d[\u001b[39m\"\u001b[39m\u001b[39mnumeric_output\u001b[39m\u001b[39m\"\u001b[39m], tokens)\n",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m, in \u001b[0;36mmake_str\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m l:\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m i\u001b[39m.\u001b[39mis_numeric:\n\u001b[0;32m----> 5\u001b[0m         result_list\u001b[39m.\u001b[39mappend(i\u001b[39m.\u001b[39;49mnumeric_value)\n\u001b[1;32m      6\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         result_list\u001b[39m.\u001b[39mappend(i\u001b[39m.\u001b[39mvalue)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StringNumeric' object has no attribute 'numeric_value'"
     ]
    }
   ],
   "source": [
    "def make_str(l: list):\n",
    "    result_list = []\n",
    "    for i in l:\n",
    "        if i.is_numeric:\n",
    "            result_list.append(i.numeric_value)\n",
    "        else:\n",
    "            result_list.append(i.value)\n",
    "    result_list = [str(i) for i in result_list]\n",
    "    return \" \".join(result_list).split(\"<row-end>\")[0]\n",
    "\n",
    "\n",
    "def prediction_str(class_output, numeric_output, tokens):\n",
    "    lsm = nn.Softmax(dim=0)\n",
    "    softmax_cats = lsm(class_output)\n",
    "    softmax_cats = torch.argmax(softmax_cats, dim=1)\n",
    "    gen_tokens = []\n",
    "    for idx, pred in enumerate(softmax_cats):\n",
    "        token = tokens[pred]\n",
    "        if token == \"<numeric>\":\n",
    "            gen_tokens.append(str(numeric_output[idx].item()))\n",
    "        else:\n",
    "            gen_tokens.append(token)\n",
    "    preds = \" \".join(gen_tokens).split(\"<row-end>\")[0]\n",
    "    return preds\n",
    "\n",
    "\n",
    "def print_results(d: dict):\n",
    "    data_str = make_str(d[\"data\"])\n",
    "    target_str = make_str(d[\"targets\"])\n",
    "    pred_str = prediction_str(d[\"class_output\"], d[\"numeric_output\"], tokens)\n",
    "    print(f\"Data  : {data_str}\\nTarget: {target_str}\\nPredict: {pred_str}\")\n",
    "\n",
    "\n",
    "print_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=96, out_features=1000, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1000, out_features=96, bias=True)\n",
      "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): StringNumericEmbedding(\n",
      "    (embedding): Embedding(20, 96)\n",
      "    (numeric_embedding): Linear(in_features=1, out_features=96, bias=True)\n",
      "  )\n",
      "  (decoder): Linear(in_features=96, out_features=19, bias=True)\n",
      "  (numeric_ingester): Linear(in_features=96, out_features=38, bias=True)\n",
      "  (numeric_hidden): Linear(in_features=38, out_features=19, bias=True)\n",
      "  (numeric_flattener): Linear(in_features=19, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "--------------------\n",
      "transformer_encoder.layers.0.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.0.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.0.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.0.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.0.linear1.weight: 96000\n",
      "transformer_encoder.layers.0.linear1.bias: 1000\n",
      "transformer_encoder.layers.0.linear2.weight: 96000\n",
      "transformer_encoder.layers.0.linear2.bias: 96\n",
      "transformer_encoder.layers.0.norm1.weight: 96\n",
      "transformer_encoder.layers.0.norm1.bias: 96\n",
      "transformer_encoder.layers.0.norm2.weight: 96\n",
      "transformer_encoder.layers.0.norm2.bias: 96\n",
      "transformer_encoder.layers.1.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.1.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.1.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.1.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.1.linear1.weight: 96000\n",
      "transformer_encoder.layers.1.linear1.bias: 1000\n",
      "transformer_encoder.layers.1.linear2.weight: 96000\n",
      "transformer_encoder.layers.1.linear2.bias: 96\n",
      "transformer_encoder.layers.1.norm1.weight: 96\n",
      "transformer_encoder.layers.1.norm1.bias: 96\n",
      "transformer_encoder.layers.1.norm2.weight: 96\n",
      "transformer_encoder.layers.1.norm2.bias: 96\n",
      "transformer_encoder.layers.2.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.2.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.2.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.2.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.2.linear1.weight: 96000\n",
      "transformer_encoder.layers.2.linear1.bias: 1000\n",
      "transformer_encoder.layers.2.linear2.weight: 96000\n",
      "transformer_encoder.layers.2.linear2.bias: 96\n",
      "transformer_encoder.layers.2.norm1.weight: 96\n",
      "transformer_encoder.layers.2.norm1.bias: 96\n",
      "transformer_encoder.layers.2.norm2.weight: 96\n",
      "transformer_encoder.layers.2.norm2.bias: 96\n",
      "transformer_encoder.layers.3.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.3.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.3.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.3.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.3.linear1.weight: 96000\n",
      "transformer_encoder.layers.3.linear1.bias: 1000\n",
      "transformer_encoder.layers.3.linear2.weight: 96000\n",
      "transformer_encoder.layers.3.linear2.bias: 96\n",
      "transformer_encoder.layers.3.norm1.weight: 96\n",
      "transformer_encoder.layers.3.norm1.bias: 96\n",
      "transformer_encoder.layers.3.norm2.weight: 96\n",
      "transformer_encoder.layers.3.norm2.bias: 96\n",
      "transformer_encoder.layers.4.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.4.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.4.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.4.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.4.linear1.weight: 96000\n",
      "transformer_encoder.layers.4.linear1.bias: 1000\n",
      "transformer_encoder.layers.4.linear2.weight: 96000\n",
      "transformer_encoder.layers.4.linear2.bias: 96\n",
      "transformer_encoder.layers.4.norm1.weight: 96\n",
      "transformer_encoder.layers.4.norm1.bias: 96\n",
      "transformer_encoder.layers.4.norm2.weight: 96\n",
      "transformer_encoder.layers.4.norm2.bias: 96\n",
      "transformer_encoder.layers.5.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.5.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.5.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.5.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.5.linear1.weight: 96000\n",
      "transformer_encoder.layers.5.linear1.bias: 1000\n",
      "transformer_encoder.layers.5.linear2.weight: 96000\n",
      "transformer_encoder.layers.5.linear2.bias: 96\n",
      "transformer_encoder.layers.5.norm1.weight: 96\n",
      "transformer_encoder.layers.5.norm1.bias: 96\n",
      "transformer_encoder.layers.5.norm2.weight: 96\n",
      "transformer_encoder.layers.5.norm2.bias: 96\n",
      "transformer_encoder.layers.6.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.6.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.6.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.6.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.6.linear1.weight: 96000\n",
      "transformer_encoder.layers.6.linear1.bias: 1000\n",
      "transformer_encoder.layers.6.linear2.weight: 96000\n",
      "transformer_encoder.layers.6.linear2.bias: 96\n",
      "transformer_encoder.layers.6.norm1.weight: 96\n",
      "transformer_encoder.layers.6.norm1.bias: 96\n",
      "transformer_encoder.layers.6.norm2.weight: 96\n",
      "transformer_encoder.layers.6.norm2.bias: 96\n",
      "transformer_encoder.layers.7.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.7.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.7.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.7.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.7.linear1.weight: 96000\n",
      "transformer_encoder.layers.7.linear1.bias: 1000\n",
      "transformer_encoder.layers.7.linear2.weight: 96000\n",
      "transformer_encoder.layers.7.linear2.bias: 96\n",
      "transformer_encoder.layers.7.norm1.weight: 96\n",
      "transformer_encoder.layers.7.norm1.bias: 96\n",
      "transformer_encoder.layers.7.norm2.weight: 96\n",
      "transformer_encoder.layers.7.norm2.bias: 96\n",
      "transformer_encoder.layers.8.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.8.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.8.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.8.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.8.linear1.weight: 96000\n",
      "transformer_encoder.layers.8.linear1.bias: 1000\n",
      "transformer_encoder.layers.8.linear2.weight: 96000\n",
      "transformer_encoder.layers.8.linear2.bias: 96\n",
      "transformer_encoder.layers.8.norm1.weight: 96\n",
      "transformer_encoder.layers.8.norm1.bias: 96\n",
      "transformer_encoder.layers.8.norm2.weight: 96\n",
      "transformer_encoder.layers.8.norm2.bias: 96\n",
      "transformer_encoder.layers.9.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.9.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.9.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.9.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.9.linear1.weight: 96000\n",
      "transformer_encoder.layers.9.linear1.bias: 1000\n",
      "transformer_encoder.layers.9.linear2.weight: 96000\n",
      "transformer_encoder.layers.9.linear2.bias: 96\n",
      "transformer_encoder.layers.9.norm1.weight: 96\n",
      "transformer_encoder.layers.9.norm1.bias: 96\n",
      "transformer_encoder.layers.9.norm2.weight: 96\n",
      "transformer_encoder.layers.9.norm2.bias: 96\n",
      "transformer_encoder.layers.10.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.10.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.10.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.10.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.10.linear1.weight: 96000\n",
      "transformer_encoder.layers.10.linear1.bias: 1000\n",
      "transformer_encoder.layers.10.linear2.weight: 96000\n",
      "transformer_encoder.layers.10.linear2.bias: 96\n",
      "transformer_encoder.layers.10.norm1.weight: 96\n",
      "transformer_encoder.layers.10.norm1.bias: 96\n",
      "transformer_encoder.layers.10.norm2.weight: 96\n",
      "transformer_encoder.layers.10.norm2.bias: 96\n",
      "transformer_encoder.layers.11.self_attn.in_proj_weight: 27648\n",
      "transformer_encoder.layers.11.self_attn.in_proj_bias: 288\n",
      "transformer_encoder.layers.11.self_attn.out_proj.weight: 9216\n",
      "transformer_encoder.layers.11.self_attn.out_proj.bias: 96\n",
      "transformer_encoder.layers.11.linear1.weight: 96000\n",
      "transformer_encoder.layers.11.linear1.bias: 1000\n",
      "transformer_encoder.layers.11.linear2.weight: 96000\n",
      "transformer_encoder.layers.11.linear2.bias: 96\n",
      "transformer_encoder.layers.11.norm1.weight: 96\n",
      "transformer_encoder.layers.11.norm1.bias: 96\n",
      "transformer_encoder.layers.11.norm2.weight: 96\n",
      "transformer_encoder.layers.11.norm2.bias: 96\n",
      "encoder.embedding.weight: 1920\n",
      "encoder.numeric_embedding.weight: 96\n",
      "encoder.numeric_embedding.bias: 96\n",
      "decoder.weight: 1824\n",
      "decoder.bias: 19\n",
      "numeric_ingester.weight: 3648\n",
      "numeric_ingester.bias: 38\n",
      "numeric_hidden.weight: 722\n",
      "numeric_hidden.bias: 19\n",
      "numeric_flattener.weight: 19\n",
      "numeric_flattener.bias: 1\n",
      "--------------------\n",
      "Total Parameters: 2777138\n"
     ]
    }
   ],
   "source": [
    "def model_summary(model):\n",
    "    print(\"Model Summary\")\n",
    "    print(\"--------------------\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        total_params += num_params\n",
    "        print(f\"{name}: {num_params}\")\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "# Usage\n",
    "model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 41])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"class_output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"numeric_output\"][:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((res[\"numeric_output\"][None, :], res[\"class_output\"].T)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_str(class_output, numeric_output, tokens):\n",
    "    lsm = nn.Softmax(dim=0)\n",
    "    softmax_cats = lsm(class_output)\n",
    "    softmax_cats = torch.argmax(softmax_cats, dim=1)\n",
    "    gen_tokens = []\n",
    "    for idx, pred in enumerate(softmax_cats):\n",
    "        token = tokens[pred]\n",
    "        if token == \"<numeric>\":\n",
    "            gen_tokens.append(str(numeric_output[idx].item()))\n",
    "        else:\n",
    "            gen_tokens.append(token)\n",
    "    preds = \" \".join(gen_tokens).split(\"<row-end>\")[0]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_data(N):\n",
    "    x = torch.randint(1, 100, (N, 2), dtype=torch.float32)\n",
    "    y_mul = x[:, 0] * x[:, 1]\n",
    "    y_div = x[:, 0] / x[:, 1]\n",
    "    y = torch.stack((y_mul, y_div), dim=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MathNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MathNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5478397.5\n",
      "Epoch 100, Loss: 1675928.875\n",
      "Epoch 200, Loss: 784210.25\n",
      "Epoch 300, Loss: 779894.25\n",
      "Epoch 400, Loss: 775376.625\n",
      "Epoch 500, Loss: 770643.8125\n",
      "Epoch 600, Loss: 765713.625\n",
      "Epoch 700, Loss: 760585.8125\n",
      "Epoch 800, Loss: 755247.5\n",
      "Epoch 900, Loss: 749672.125\n"
     ]
    }
   ],
   "source": [
    "N = 1000000\n",
    "data_x, data_y = generate_data(N)\n",
    "\n",
    "# Split into training and testing\n",
    "train_x, test_x = data_x[:8000], data_x[8000:]\n",
    "train_y, test_y = data_y[:8000], data_y[8000:]\n",
    "\n",
    "model = MathNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    outputs = model(train_x)\n",
    "    loss = criterion(outputs, train_y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 737482.3125\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs = model(test_x)\n",
    "    test_loss = criterion(test_outputs, test_y)\n",
    "    print(f\"Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992000, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3350e+03, 5.9333e+00],\n",
       "        [7.4000e+01, 1.8500e+01],\n",
       "        [2.7600e+02, 1.7250e+01],\n",
       "        ...,\n",
       "        [9.8600e+02, 8.5294e-01],\n",
       "        [9.0000e+02, 1.1111e-01],\n",
       "        [2.5550e+03, 2.0857e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.5403e+03, -6.8926e-01],\n",
       "        [ 5.4591e+03, -7.7647e-01],\n",
       "        [ 1.7531e+03,  9.1369e+00],\n",
       "        ...,\n",
       "        [ 8.5710e+02,  8.9137e-01],\n",
       "        [ 6.9791e+03, -1.7934e+00],\n",
       "        [ 5.2343e+01,  1.2579e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N):\n",
    "    x = torch.randint(1, 1000, (N, 2), dtype=torch.float32)\n",
    "    y_mul = x[:, 0] * x[:, 1]\n",
    "    y_div = x[:, 0] / x[:, 1]\n",
    "    y = torch.stack((y_mul, y_div), dim=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        N = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.nn.Softmax(dim=3)(energy)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 256), nn.ReLU(), nn.Linear(256, embed_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally feed forward\n",
    "        x = self.norm1(attention + query)\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.norm2(forward + x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MathNet(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MathNet, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.fc1 = nn.Linear(2, embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads)\n",
    "        self.fc2 = nn.Linear(embed_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.repeat(1, 3, 1)  # Repeat x three times to form keys, values, queries\n",
    "        x = self.transformer_block(x, x, x, mask=None)\n",
    "        x = self.fc2(x[:, 0, :])  # We only need the first result from the sequence\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8000, 2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5377728.5\n",
      "Epoch 100, Loss: 4712922.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    483\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    484\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[0;32m--> 491\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    492\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    493\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/autograd/__init__.py:204\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    201\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    206\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MathNet(embed_size=64, heads=4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    outputs = model(train_x)\n",
    "    loss = criterion(outputs, train_y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NumberEmbedding(nn.Module):\n",
    "    def __init__(self, embed_size=512):\n",
    "        super(NumberEmbedding, self).__init__()\n",
    "        self.linear = nn.Linear(1, embed_size)\n",
    "\n",
    "    def forward(self, numbers):\n",
    "        # Assuming numbers is a tensor containing the numerical values\n",
    "        return self.linear(numbers.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = NumberEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "n = torch.Tensor([1.01, 1, 2, 3])\n",
    "nn = n.unsqueeze(-1)\n",
    "\n",
    "print(n.shape, nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0100],\n",
       "        [1.0000],\n",
       "        [2.0000],\n",
       "        [3.0000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0800, -0.2637,  0.9156,  ...,  0.5839, -0.1389,  0.9257],\n",
       "        [ 0.0831, -0.2657,  0.9104,  ...,  0.5853, -0.1418,  0.9182],\n",
       "        [-0.2212, -0.0711,  1.4304,  ...,  0.4433,  0.1406,  1.6661],\n",
       "        [-0.5256,  0.1235,  1.9504,  ...,  0.3013,  0.4230,  2.4140]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ne(n)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
