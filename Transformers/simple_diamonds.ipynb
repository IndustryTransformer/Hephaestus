{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load and preprocess the dataset (assuming you have a CSV file)\n",
    "data = pd.read_csv(\"../data/diamonds.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>datetime</th>\n",
       "      <th>timezone</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>...</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>uvIndexTime</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>temperatureMinTime</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMaxTime</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>apparentTemperatureMinTime</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMaxTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424553bb-7174-41ea-aeb4-fe06d4f4b9d7</td>\n",
       "      <td>1.544953e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-16 09:30:07</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>1544979600</td>\n",
       "      <td>39.89</td>\n",
       "      <td>1545012000</td>\n",
       "      <td>43.68</td>\n",
       "      <td>1544968800</td>\n",
       "      <td>33.73</td>\n",
       "      <td>1545012000</td>\n",
       "      <td>38.07</td>\n",
       "      <td>1544958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bd23055-6827-41c6-b23b-3c491f24e74d</td>\n",
       "      <td>1.543284e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-27 02:00:23</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>1543251600</td>\n",
       "      <td>40.49</td>\n",
       "      <td>1543233600</td>\n",
       "      <td>47.30</td>\n",
       "      <td>1543251600</td>\n",
       "      <td>36.20</td>\n",
       "      <td>1543291200</td>\n",
       "      <td>43.92</td>\n",
       "      <td>1543251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>981a3613-77af-4620-a42a-0c0866077d1e</td>\n",
       "      <td>1.543367e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-28 01:00:22</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>1543338000</td>\n",
       "      <td>35.36</td>\n",
       "      <td>1543377600</td>\n",
       "      <td>47.55</td>\n",
       "      <td>1543320000</td>\n",
       "      <td>31.04</td>\n",
       "      <td>1543377600</td>\n",
       "      <td>44.12</td>\n",
       "      <td>1543320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c2d88af2-d278-4bfd-a8d0-29ca77cc5512</td>\n",
       "      <td>1.543554e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-30 04:53:02</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1543507200</td>\n",
       "      <td>34.67</td>\n",
       "      <td>1543550400</td>\n",
       "      <td>45.03</td>\n",
       "      <td>1543510800</td>\n",
       "      <td>30.30</td>\n",
       "      <td>1543550400</td>\n",
       "      <td>38.53</td>\n",
       "      <td>1543510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e0126e1f-8ca9-4f2e-82b3-50505a09db9a</td>\n",
       "      <td>1.543463e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-29 03:49:20</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1543420800</td>\n",
       "      <td>33.10</td>\n",
       "      <td>1543402800</td>\n",
       "      <td>42.18</td>\n",
       "      <td>1543420800</td>\n",
       "      <td>29.11</td>\n",
       "      <td>1543392000</td>\n",
       "      <td>35.75</td>\n",
       "      <td>1543420800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id     timestamp  hour  day  month  \\\n",
       "0  424553bb-7174-41ea-aeb4-fe06d4f4b9d7  1.544953e+09     9   16     12   \n",
       "1  4bd23055-6827-41c6-b23b-3c491f24e74d  1.543284e+09     2   27     11   \n",
       "2  981a3613-77af-4620-a42a-0c0866077d1e  1.543367e+09     1   28     11   \n",
       "3  c2d88af2-d278-4bfd-a8d0-29ca77cc5512  1.543554e+09     4   30     11   \n",
       "4  e0126e1f-8ca9-4f2e-82b3-50505a09db9a  1.543463e+09     3   29     11   \n",
       "\n",
       "              datetime          timezone            source    destination  \\\n",
       "0  2018-12-16 09:30:07  America/New_York  Haymarket Square  North Station   \n",
       "1  2018-11-27 02:00:23  America/New_York  Haymarket Square  North Station   \n",
       "2  2018-11-28 01:00:22  America/New_York  Haymarket Square  North Station   \n",
       "3  2018-11-30 04:53:02  America/New_York  Haymarket Square  North Station   \n",
       "4  2018-11-29 03:49:20  America/New_York  Haymarket Square  North Station   \n",
       "\n",
       "  cab_type  ... precipIntensityMax uvIndexTime  temperatureMin  \\\n",
       "0     Lyft  ...             0.1276  1544979600           39.89   \n",
       "1     Lyft  ...             0.1300  1543251600           40.49   \n",
       "2     Lyft  ...             0.1064  1543338000           35.36   \n",
       "3     Lyft  ...             0.0000  1543507200           34.67   \n",
       "4     Lyft  ...             0.0001  1543420800           33.10   \n",
       "\n",
       "   temperatureMinTime  temperatureMax  temperatureMaxTime  \\\n",
       "0          1545012000           43.68          1544968800   \n",
       "1          1543233600           47.30          1543251600   \n",
       "2          1543377600           47.55          1543320000   \n",
       "3          1543550400           45.03          1543510800   \n",
       "4          1543402800           42.18          1543420800   \n",
       "\n",
       "   apparentTemperatureMin  apparentTemperatureMinTime  apparentTemperatureMax  \\\n",
       "0                   33.73                  1545012000                   38.07   \n",
       "1                   36.20                  1543291200                   43.92   \n",
       "2                   31.04                  1543377600                   44.12   \n",
       "3                   30.30                  1543550400                   38.53   \n",
       "4                   29.11                  1543392000                   35.75   \n",
       "\n",
       "  apparentTemperatureMaxTime  \n",
       "0                 1544958000  \n",
       "1                 1543251600  \n",
       "2                 1543320000  \n",
       "3                 1543510800  \n",
       "4                 1543420800  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"~/Downloads/rideshare_kaggle.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>datetime</th>\n",
       "      <th>timezone</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>...</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>uvIndexTime</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>temperatureMinTime</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMaxTime</th>\n",
       "      <th>apparentTemperatureMin</th>\n",
       "      <th>apparentTemperatureMinTime</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "      <th>apparentTemperatureMaxTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276564</td>\n",
       "      <td>90e22612-d1c7-47c2-af54-2a2240109889</td>\n",
       "      <td>1.543204e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-26 03:40:46</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>North End</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>1543161600</td>\n",
       "      <td>40.61</td>\n",
       "      <td>1543122000</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1543154400</td>\n",
       "      <td>38.23</td>\n",
       "      <td>1543136400</td>\n",
       "      <td>43.17</td>\n",
       "      <td>1543186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30792</td>\n",
       "      <td>ef4771c2-c88d-4730-aaf7-a95751e9d27e</td>\n",
       "      <td>1.543204e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-26 03:40:46</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>1543161600</td>\n",
       "      <td>40.61</td>\n",
       "      <td>1543122000</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1543154400</td>\n",
       "      <td>38.23</td>\n",
       "      <td>1543136400</td>\n",
       "      <td>43.17</td>\n",
       "      <td>1543186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261362</td>\n",
       "      <td>d9852684-4e38-494c-ad6d-d8090e857ba9</td>\n",
       "      <td>1.543204e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-26 03:40:46</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>1543161600</td>\n",
       "      <td>40.61</td>\n",
       "      <td>1543122000</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1543154400</td>\n",
       "      <td>38.23</td>\n",
       "      <td>1543136400</td>\n",
       "      <td>43.17</td>\n",
       "      <td>1543186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449958</td>\n",
       "      <td>68c01519-3da8-4f84-b113-48cf6d1441db</td>\n",
       "      <td>1.543204e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-26 03:40:46</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>South Station</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>1543161600</td>\n",
       "      <td>40.61</td>\n",
       "      <td>1543122000</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1543154400</td>\n",
       "      <td>38.23</td>\n",
       "      <td>1543136400</td>\n",
       "      <td>43.17</td>\n",
       "      <td>1543186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261363</td>\n",
       "      <td>f3f35cea-9a3f-4534-930d-da42e7610f77</td>\n",
       "      <td>1.543204e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-26 03:40:46</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>1543161600</td>\n",
       "      <td>40.61</td>\n",
       "      <td>1543122000</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1543154400</td>\n",
       "      <td>38.23</td>\n",
       "      <td>1543136400</td>\n",
       "      <td>43.17</td>\n",
       "      <td>1543186800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                    id     timestamp  hour  day  \\\n",
       "0  276564  90e22612-d1c7-47c2-af54-2a2240109889  1.543204e+09     3   26   \n",
       "1   30792  ef4771c2-c88d-4730-aaf7-a95751e9d27e  1.543204e+09     3   26   \n",
       "2  261362  d9852684-4e38-494c-ad6d-d8090e857ba9  1.543204e+09     3   26   \n",
       "3  449958  68c01519-3da8-4f84-b113-48cf6d1441db  1.543204e+09     3   26   \n",
       "4  261363  f3f35cea-9a3f-4534-930d-da42e7610f77  1.543204e+09     3   26   \n",
       "\n",
       "   month             datetime          timezone             source  \\\n",
       "0     11  2018-11-26 03:40:46  America/New_York        Beacon Hill   \n",
       "1     11  2018-11-26 03:40:46  America/New_York  Boston University   \n",
       "2     11  2018-11-26 03:40:46  America/New_York        Beacon Hill   \n",
       "3     11  2018-11-26 03:40:46  America/New_York      South Station   \n",
       "4     11  2018-11-26 03:40:46  America/New_York        Beacon Hill   \n",
       "\n",
       "         destination  ... precipIntensityMax uvIndexTime temperatureMin  \\\n",
       "0          North End  ...             0.1396  1543161600          40.61   \n",
       "1   Theatre District  ...             0.1396  1543161600          40.61   \n",
       "2  Boston University  ...             0.1396  1543161600          40.61   \n",
       "3        Beacon Hill  ...             0.1396  1543161600          40.61   \n",
       "4  Boston University  ...             0.1396  1543161600          40.61   \n",
       "\n",
       "   temperatureMinTime  temperatureMax  temperatureMaxTime  \\\n",
       "0          1543122000           46.15          1543154400   \n",
       "1          1543122000           46.15          1543154400   \n",
       "2          1543122000           46.15          1543154400   \n",
       "3          1543122000           46.15          1543154400   \n",
       "4          1543122000           46.15          1543154400   \n",
       "\n",
       "   apparentTemperatureMin  apparentTemperatureMinTime  apparentTemperatureMax  \\\n",
       "0                   38.23                  1543136400                   43.17   \n",
       "1                   38.23                  1543136400                   43.17   \n",
       "2                   38.23                  1543136400                   43.17   \n",
       "3                   38.23                  1543136400                   43.17   \n",
       "4                   38.23                  1543136400                   43.17   \n",
       "\n",
       "   apparentTemperatureMaxTime  \n",
       "0                  1543186800  \n",
       "1                  1543186800  \n",
       "2                  1543186800  \n",
       "3                  1543186800  \n",
       "4                  1543186800  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by=[\"timestamp\"]).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>name</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>distance</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>North End</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Black</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.83</td>\n",
       "      <td>1014.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.83</td>\n",
       "      <td>1014.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Shared</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.83</td>\n",
       "      <td>1014.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Station</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.83</td>\n",
       "      <td>1014.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Lux</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.83</td>\n",
       "      <td>1014.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Theatre District</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Shared</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.52</td>\n",
       "      <td>1014.06</td>\n",
       "      <td>0.90</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Lux</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.52</td>\n",
       "      <td>1014.06</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>South Station</td>\n",
       "      <td>Beacon Hill</td>\n",
       "      <td>Uber</td>\n",
       "      <td>UberPool</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.52</td>\n",
       "      <td>1014.06</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>West End</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.52</td>\n",
       "      <td>1014.06</td>\n",
       "      <td>0.90</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>South Station</td>\n",
       "      <td>Financial District</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.52</td>\n",
       "      <td>1014.06</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source              destination cab_type          name  hour  \\\n",
       "0          Beacon Hill                North End     Uber         Black     3   \n",
       "1    Boston University         Theatre District     Lyft  Lux Black XL     3   \n",
       "2          Beacon Hill        Boston University     Lyft        Shared     3   \n",
       "3        South Station              Beacon Hill     Uber          Taxi     3   \n",
       "4          Beacon Hill        Boston University     Lyft           Lux     3   \n",
       "..                 ...                      ...      ...           ...   ...   \n",
       "96    Theatre District        Boston University     Lyft        Shared     4   \n",
       "97    Haymarket Square            North Station     Lyft           Lux     4   \n",
       "98       South Station              Beacon Hill     Uber      UberPool     4   \n",
       "99            West End  Northeastern University     Lyft  Lux Black XL     4   \n",
       "100      South Station       Financial District     Lyft          Lyft     4   \n",
       "\n",
       "     day  month  distance  precipIntensity  temperature  pressure  humidity  \\\n",
       "0     26     11      2.19              0.0        41.83   1014.10      0.92   \n",
       "1     26     11      3.03              0.0        41.83   1014.10      0.92   \n",
       "2     26     11      2.30              0.0        41.83   1014.10      0.92   \n",
       "3     26     11      2.50              0.0        41.83   1014.10      0.92   \n",
       "4     26     11      2.30              0.0        41.83   1014.10      0.92   \n",
       "..   ...    ...       ...              ...          ...       ...       ...   \n",
       "96    26     11      4.73              0.0        41.52   1014.06      0.90   \n",
       "97    26     11      0.55              0.0        41.52   1014.06      0.90   \n",
       "98    26     11      2.58              0.0        41.52   1014.06      0.90   \n",
       "99    26     11      3.11              0.0        41.52   1014.06      0.90   \n",
       "100   26     11      0.66              0.0        41.52   1014.06      0.90   \n",
       "\n",
       "     price  \n",
       "0     17.5  \n",
       "1     34.0  \n",
       "2      3.5  \n",
       "3      NaN  \n",
       "4     16.5  \n",
       "..     ...  \n",
       "96    11.0  \n",
       "97    10.5  \n",
       "98     8.0  \n",
       "99    34.0  \n",
       "100    9.0  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    0:100,\n",
    "    [\n",
    "        \"source\",\n",
    "        \"destination\",\n",
    "        \"cab_type\",\n",
    "        \"name\",\n",
    "        \"hour\",\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"distance\",\n",
    "        \"precipIntensity\",\n",
    "        # \"surge_multiplier\",\n",
    "        \"temperature\",\n",
    "        \"pressure\",\n",
    "        \"humidity\",\n",
    "        \"price\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      17.5\n",
       "1      34.0\n",
       "2       3.5\n",
       "4      16.5\n",
       "5       7.0\n",
       "       ... \n",
       "102    36.0\n",
       "103    38.5\n",
       "104     3.5\n",
       "105    34.0\n",
       "106    22.0\n",
       "Name: price, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_4807/1676805110.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cat[col] = le.fit_transform(X_train_cat[col].copy())\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_4807/1676805110.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_cat[col] = le.transform(X_test_cat[col].copy())\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_4807/1676805110.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cat[col] = le.fit_transform(X_train_cat[col].copy())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'South Station'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m values])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnan_value\n\u001b[0;32m--> 159\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'South Station'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     le \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m     25\u001b[0m     X_train_cat[col] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mfit_transform(X_train_cat[col]\u001b[39m.\u001b[39mcopy())\n\u001b[0;32m---> 26\u001b[0m     X_test_cat[col] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39;49mtransform(X_test_cat[col]\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m     27\u001b[0m     label_encoders[col] \u001b[39m=\u001b[39m le\n\u001b[1;32m     29\u001b[0m \u001b[39m# Preprocess numeric features\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'South Station'"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "df2 = df.dropna()\n",
    "df2 = df2.head(100)\n",
    "X = df2.drop(\"price\", axis=1)\n",
    "y = df2[\"price\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess categorical features\n",
    "cat_columns = [\n",
    "    \"source\",\n",
    "    \"destination\",\n",
    "    \"cab_type\",\n",
    "    \"name\",\n",
    "]\n",
    "X_train_cat = X_train[cat_columns]\n",
    "X_test_cat = X_test[cat_columns]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_cat[col] = le.fit_transform(X_train_cat[col].copy())\n",
    "    X_test_cat[col] = le.transform(X_test_cat[col].copy())\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Preprocess numeric features\n",
    "num_columns = [\n",
    "    \"hour\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"distance\",\n",
    "    \"precipIntensity\",\n",
    "    # \"surge_multiplier\",\n",
    "    \"temperature\",\n",
    "    \"pressure\",\n",
    "    \"humidity\",\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[num_columns])\n",
    "X_test_num = scaler.transform(X_test[num_columns])\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(\n",
    "    X_train_cat.values, dtype=torch.int64\n",
    ")  # Use int64 dtype for categorical indices\n",
    "X_train_num_tensor = torch.tensor(X_train_num, dtype=torch.float32)\n",
    "X_test_cat_tensor = torch.tensor(\n",
    "    X_test_cat.values, dtype=torch.int64\n",
    ")  # Use int64 dtype for categorical indices\n",
    "X_test_num_tensor = torch.tensor(X_test_num, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "# Define the neural network model\n",
    "class DiamondPricePredictor(nn.Module):\n",
    "    def __init__(self, num_input_dim, cat_embedding_sizes, hidden_dim):\n",
    "        super(DiamondPricePredictor, self).__init__()\n",
    "\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [\n",
    "                nn.Embedding(num_classes, emb_size)\n",
    "                for num_classes, emb_size in cat_embedding_sizes\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        total_emb_dim = sum(emb_size for _, emb_size in cat_embedding_sizes)\n",
    "        self.fc1 = nn.Linear(num_input_dim + total_emb_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, num_inputs, cat_inputs):\n",
    "        embeddings = [\n",
    "            embedding(cat_inputs[:, i]) for i, embedding in enumerate(self.embeddings)\n",
    "        ]\n",
    "        cat_features = torch.cat(embeddings, dim=1)\n",
    "        x = torch.cat([num_inputs, cat_features], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "num_input_dim = X_train_num.shape[1]\n",
    "cat_embedding_sizes = [\n",
    "    (len(le.classes_), min(50, (len(le.classes_) + 1) // 2))\n",
    "    for le in label_encoders.values()\n",
    "]\n",
    "hidden_dim = 64\n",
    "model = DiamondPricePredictor(num_input_dim, cat_embedding_sizes, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6209],\n",
       "        [-0.1325],\n",
       "        [-0.2881],\n",
       "        [ 0.0968],\n",
       "        [-0.0953],\n",
       "        [-0.4319],\n",
       "        [-0.1174],\n",
       "        [-0.1601],\n",
       "        [-0.3293],\n",
       "        [ 0.3193],\n",
       "        [-0.2006],\n",
       "        [-0.0949],\n",
       "        [-0.3470],\n",
       "        [-0.4423],\n",
       "        [-0.0903],\n",
       "        [-0.0209],\n",
       "        [ 0.1232],\n",
       "        [-0.1612],\n",
       "        [-0.0320],\n",
       "        [-0.6046],\n",
       "        [-0.3500],\n",
       "        [-0.0740],\n",
       "        [-0.4677],\n",
       "        [-0.4586],\n",
       "        [ 0.0316],\n",
       "        [-0.0613],\n",
       "        [-0.1205],\n",
       "        [ 0.0625],\n",
       "        [-0.1287],\n",
       "        [-0.1334],\n",
       "        [-0.2792],\n",
       "        [-0.0185],\n",
       "        [-0.1273],\n",
       "        [-0.4536],\n",
       "        [-0.1592],\n",
       "        [ 0.3383],\n",
       "        [-0.3883],\n",
       "        [-0.0969],\n",
       "        [-0.6642],\n",
       "        [-0.1163],\n",
       "        [-0.1587],\n",
       "        [-0.1673],\n",
       "        [-0.6315],\n",
       "        [-0.0618],\n",
       "        [-0.3102],\n",
       "        [ 0.0627],\n",
       "        [-0.2514],\n",
       "        [-0.3541],\n",
       "        [-0.6075],\n",
       "        [-0.0817],\n",
       "        [ 0.0839],\n",
       "        [-0.6619],\n",
       "        [-0.0049],\n",
       "        [-0.2613],\n",
       "        [-0.1255],\n",
       "        [-0.0212],\n",
       "        [-0.1073],\n",
       "        [ 0.1768],\n",
       "        [-0.5153],\n",
       "        [-0.0374],\n",
       "        [-0.1442],\n",
       "        [-0.0083],\n",
       "        [-0.1582],\n",
       "        [-0.1490],\n",
       "        [ 0.0575],\n",
       "        [-0.1885],\n",
       "        [ 0.0900],\n",
       "        [-0.0396],\n",
       "        [ 0.1519],\n",
       "        [-0.2221],\n",
       "        [-0.6546],\n",
       "        [-0.0150],\n",
       "        [-0.1834],\n",
       "        [ 0.0645],\n",
       "        [-0.3634],\n",
       "        [ 0.0545],\n",
       "        [-0.4725],\n",
       "        [-0.1887],\n",
       "        [-0.4811],\n",
       "        [-0.3582]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(X_train_num_tensor, X_train_cat_tensor)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000],\n",
       "        [19.5000],\n",
       "        [26.0000],\n",
       "        [19.5000],\n",
       "        [10.5000],\n",
       "        [19.5000],\n",
       "        [10.5000],\n",
       "        [11.0000],\n",
       "        [13.0000],\n",
       "        [10.5000],\n",
       "        [ 9.0000],\n",
       "        [27.5000],\n",
       "        [10.5000],\n",
       "        [ 8.5000],\n",
       "        [10.5000],\n",
       "        [ 7.0000],\n",
       "        [14.0000],\n",
       "        [27.5000],\n",
       "        [34.0000],\n",
       "        [    nan],\n",
       "        [14.0000],\n",
       "        [16.5000],\n",
       "        [10.5000],\n",
       "        [10.0000],\n",
       "        [35.0000],\n",
       "        [47.5000],\n",
       "        [16.5000],\n",
       "        [34.0000],\n",
       "        [11.0000],\n",
       "        [62.5000],\n",
       "        [10.0000],\n",
       "        [    nan],\n",
       "        [10.5000],\n",
       "        [16.0000],\n",
       "        [18.5000],\n",
       "        [38.5000],\n",
       "        [ 7.0000],\n",
       "        [30.0000],\n",
       "        [27.5000],\n",
       "        [ 9.0000],\n",
       "        [10.5000],\n",
       "        [34.0000],\n",
       "        [ 9.5000],\n",
       "        [22.5000],\n",
       "        [16.0000],\n",
       "        [13.5000],\n",
       "        [ 7.0000],\n",
       "        [ 9.0000],\n",
       "        [    nan],\n",
       "        [10.5000],\n",
       "        [32.5000],\n",
       "        [26.0000],\n",
       "        [16.5000],\n",
       "        [ 9.5000],\n",
       "        [ 8.0000],\n",
       "        [26.0000],\n",
       "        [16.5000],\n",
       "        [22.5000],\n",
       "        [16.5000],\n",
       "        [ 5.0000],\n",
       "        [    nan],\n",
       "        [38.0000],\n",
       "        [16.5000],\n",
       "        [16.5000],\n",
       "        [34.0000],\n",
       "        [29.5000],\n",
       "        [ 8.5000],\n",
       "        [ 3.5000],\n",
       "        [21.5000],\n",
       "        [27.0000],\n",
       "        [18.5000],\n",
       "        [10.5000],\n",
       "        [11.0000],\n",
       "        [32.5000],\n",
       "        [ 8.0000],\n",
       "        [19.5000],\n",
       "        [    nan],\n",
       "        [    nan],\n",
       "        [26.0000],\n",
       "        [10.0000]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(outputs, y_train_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1,000.00, Loss: nan, lr: 0.01\n",
      "Epoch 101/1,000.00, Loss: nan, lr: 0.01\n",
      "Epoch 201/1,000.00, Loss: nan, lr: 0.01\n",
      "Epoch 301/1,000.00, Loss: nan, lr: 0.01\n",
      "Epoch 401/1,000.00, Loss: nan, lr: 0.01\n",
      "Epoch 501/1,000.00, Loss: nan, lr: 0.01\n",
      "Epoch 601/1,000.00, Loss: nan, lr: 0.00\n",
      "Epoch 701/1,000.00, Loss: nan, lr: 0.00\n",
      "Epoch 801/1,000.00, Loss: nan, lr: 0.00\n",
      "Epoch 901/1,000.00, Loss: nan, lr: 0.00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     41\u001b[0m     test_predictions \u001b[39m=\u001b[39m model(X_test_num_tensor, X_test_cat_tensor)\n\u001b[0;32m---> 42\u001b[0m     mse \u001b[39m=\u001b[39m mean_squared_error(y_test_tensor, test_predictions)\n\u001b[1;32m     43\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMean Squared Error on Test Data: \u001b[39m\u001b[39m{\u001b[39;00mmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    405\u001b[0m     {\n\u001b[1;32m    406\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    475\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    478\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/metrics/_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m    correct keyword.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 100\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    101\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer final:\n",
    "# 616,079.6875 ->\n",
    "# 261,726.6875\n",
    "# 988,246.6875\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.8,\n",
    "    patience=5,\n",
    "    threshold=0.001,\n",
    "    threshold_mode=\"rel\",\n",
    "    cooldown=0,\n",
    "    min_lr=0.0001,\n",
    "    eps=1e-08,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(\n",
    "        X_train_num_tensor, X_train_cat_tensor\n",
    "    )  # Pass numeric and categorical tensors separately\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs:,.2f}, Loss: {loss.item():,.2f},\"\n",
    "            + f\" lr: {optimizer.param_groups[0]['lr']:,.2f}\"\n",
    "        )\n",
    "    if epoch % 25 == 0:\n",
    "        scheduler.step(loss.item())\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_num_tensor, X_test_cat_tensor)\n",
    "    mse = mean_squared_error(y_test_tensor, test_predictions)\n",
    "    print(f\"Mean Squared Error on Test Data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 1, 3],\n",
       "        [3, 4, 5],\n",
       "        ...,\n",
       "        [4, 2, 1],\n",
       "        [3, 6, 2],\n",
       "        [3, 2, 2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5601, -2.5507,  2.9339,  2.2295,  2.1382,  1.7382],\n",
       "        [ 0.4474, -1.2204,  1.1396,  0.7475,  0.6567,  0.5377],\n",
       "        [ 0.6375,  0.5300,  0.2424,  0.7654,  0.7003,  0.7920],\n",
       "        ...,\n",
       "        [-0.9892, -1.0104,  0.2424, -1.1093, -1.1124, -1.1853],\n",
       "        [ 0.2150,  0.7400,  0.6910,  0.3548,  0.2558,  0.3965],\n",
       "        [ 0.7220, -0.9404,  0.2424,  0.9707,  0.9182,  0.8061]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 291539.15625\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_num_tensor, X_test_cat_tensor)\n",
    "    mse = mean_squared_error(y_test_tensor, test_predictions)\n",
    "    print(f\"Mean Squared Error on Test Data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 559.],\n",
       "        [2201.],\n",
       "        [1238.],\n",
       "        ...,\n",
       "        [ 761.],\n",
       "        [9836.],\n",
       "        [3742.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 650.0410],\n",
       "        [2434.5598],\n",
       "        [1229.5330],\n",
       "        ...,\n",
       "        [ 712.3433],\n",
       "        [9726.6943],\n",
       "        [3760.2744]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "embed_dim must be divisible by num_heads",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 74\u001b[0m\n\u001b[1;32m     69\u001b[0m cat_embedding_sizes \u001b[39m=\u001b[39m [\n\u001b[1;32m     70\u001b[0m     (\u001b[39mlen\u001b[39m(le\u001b[39m.\u001b[39mclasses_), \u001b[39mmin\u001b[39m(\u001b[39m50\u001b[39m, (\u001b[39mlen\u001b[39m(le\u001b[39m.\u001b[39mclasses_) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[1;32m     71\u001b[0m     \u001b[39mfor\u001b[39;00m le \u001b[39min\u001b[39;00m label_encoders\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m     72\u001b[0m ]\n\u001b[1;32m     73\u001b[0m hidden_dim \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[0;32m---> 74\u001b[0m model \u001b[39m=\u001b[39m DiamondPricePredictorWithTransformer(\n\u001b[1;32m     75\u001b[0m     num_input_dim, cat_embedding_sizes, hidden_dim\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[39m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m     79\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n",
      "Cell \u001b[0;32mIn[28], line 28\u001b[0m, in \u001b[0;36mDiamondPricePredictorWithTransformer.__init__\u001b[0;34m(self, num_input_dim, cat_embedding_sizes, hidden_dim)\u001b[0m\n\u001b[1;32m     25\u001b[0m total_emb_dim \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(emb_size \u001b[39mfor\u001b[39;00m _, emb_size \u001b[39min\u001b[39;00m cat_embedding_sizes)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Transformer Encoder Layer\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_layer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mTransformerEncoderLayer(\n\u001b[1;32m     29\u001b[0m     d_model\u001b[39m=\u001b[39;49mnum_input_dim \u001b[39m+\u001b[39;49m total_emb_dim,\n\u001b[1;32m     30\u001b[0m     nhead\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,  \u001b[39m# Number of attention heads\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m     dim_feedforward\u001b[39m=\u001b[39;49mhidden_dim,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mTransformerEncoder(\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_layer, num_layers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     36\u001b[0m )  \u001b[39m# Number of transformer layers\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(num_input_dim \u001b[39m+\u001b[39m total_emb_dim, hidden_dim)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:495\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.__init__\u001b[0;34m(self, d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, device, dtype)\u001b[0m\n\u001b[1;32m    493\u001b[0m factory_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: device, \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m: dtype}\n\u001b[1;32m    494\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn \u001b[39m=\u001b[39m MultiheadAttention(d_model, nhead, dropout\u001b[39m=\u001b[39;49mdropout, batch_first\u001b[39m=\u001b[39;49mbatch_first,\n\u001b[1;32m    496\u001b[0m                                     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n\u001b[1;32m    497\u001b[0m \u001b[39m# Implementation of Feedforward model\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1 \u001b[39m=\u001b[39m Linear(d_model, dim_feedforward, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/activation.py:988\u001b[0m, in \u001b[0;36mMultiheadAttention.__init__\u001b[0;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39m=\u001b[39m batch_first\n\u001b[1;32m    987\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim \u001b[39m=\u001b[39m embed_dim \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_heads\n\u001b[0;32m--> 988\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim \u001b[39m*\u001b[39m num_heads \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39m\"\u001b[39m\u001b[39membed_dim must be divisible by num_heads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    990\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qkv_same_embed_dim:\n\u001b[1;32m    991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((embed_dim, embed_dim), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mAssertionError\u001b[0m: embed_dim must be divisible by num_heads"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ... (Your data preprocessing code remains the same) ...\n",
    "\n",
    "\n",
    "# Define the neural network model with Transformer components\n",
    "class DiamondPricePredictorWithTransformer(nn.Module):\n",
    "    def __init__(self, num_input_dim, cat_embedding_sizes, hidden_dim):\n",
    "        super(DiamondPricePredictorWithTransformer, self).__init__()\n",
    "\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [\n",
    "                nn.Embedding(num_classes, emb_size)\n",
    "                for num_classes, emb_size in cat_embedding_sizes\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        total_emb_dim = sum(emb_size for _, emb_size in cat_embedding_sizes)\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=num_input_dim + total_emb_dim,\n",
    "            nhead=4,  # Number of attention heads\n",
    "            dim_feedforward=hidden_dim,\n",
    "        )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.transformer_layer, num_layers=2\n",
    "        )  # Number of transformer layers\n",
    "\n",
    "        self.fc1 = nn.Linear(num_input_dim + total_emb_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.embedding_dim = 9  # 16  # Embedding dimension for column names\n",
    "        self.column_name_embedding = nn.Embedding(\n",
    "            len(X_train.columns), self.embedding_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, num_inputs, cat_inputs, col_indices):\n",
    "        # Embed column indices\n",
    "        col_name_embeddings = self.column_name_embedding(col_indices)\n",
    "\n",
    "        # Embed categorical features\n",
    "        embeddings = [\n",
    "            embedding(cat_inputs[:, i]) for i, embedding in enumerate(self.embeddings)\n",
    "        ]\n",
    "        cat_features = torch.cat(embeddings, dim=1)\n",
    "\n",
    "        # Combine column embeddings with features\n",
    "        x = torch.cat([col_name_embeddings, num_inputs, cat_features], dim=1)\n",
    "\n",
    "        # Apply Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "num_input_dim = X_train_num.shape[1]\n",
    "cat_embedding_sizes = [\n",
    "    (len(le.classes_), min(50, (len(le.classes_) + 1) // 2))\n",
    "    for le in label_encoders.values()\n",
    "]\n",
    "hidden_dim = 64\n",
    "model = DiamondPricePredictorWithTransformer(\n",
    "    num_input_dim, cat_embedding_sizes, hidden_dim\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ... (Training loop and evaluation code remains the same) ...\n",
    "\n",
    "# During training loop and evaluation, make sure to provide the column indices as well\n",
    "# Column indices can be obtained using: col_indices = torch.arange(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 16, but got 33",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m    102\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 103\u001b[0m     outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m    104\u001b[0m         X_train_num_tensor, X_train_cat_tensor, col_indices\n\u001b[1;32m    105\u001b[0m     )  \u001b[39m# Pass numeric, categorical tensors, and column indices\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, y_train_tensor)\n\u001b[1;32m    107\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 71\u001b[0m, in \u001b[0;36mDiamondPricePredictorWithTransformer.forward\u001b[0;34m(self, num_inputs, cat_inputs, col_indices)\u001b[0m\n\u001b[1;32m     68\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[39m# Apply Transformer Encoder\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x)\n\u001b[1;32m     73\u001b[0m \u001b[39m# Permute dimensions back to original shape\u001b[39;00m\n\u001b[1;32m     74\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:334\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    331\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[1;32m    333\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 334\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    337\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:646\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    644\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    645\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 646\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    647\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    649\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:654\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    653\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 654\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    655\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    656\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    657\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/activation.py:1231\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1218\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1219\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1229\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1230\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1231\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1232\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1233\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1234\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1235\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1236\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1237\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1238\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1239\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1240\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1241\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:5271\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5265\u001b[0m     \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5266\u001b[0m         \u001b[39m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[1;32m   5267\u001b[0m         \u001b[39m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[1;32m   5268\u001b[0m         \u001b[39m# longer causal.\u001b[39;00m\n\u001b[1;32m   5269\u001b[0m         is_causal \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 5271\u001b[0m \u001b[39massert\u001b[39;00m embed_dim \u001b[39m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5272\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwas expecting embedding dimension of \u001b[39m\u001b[39m{\u001b[39;00membed_dim_to_check\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00membed_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(embed_dim, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m   5274\u001b[0m     \u001b[39m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5275\u001b[0m     head_dim \u001b[39m=\u001b[39m embed_dim\u001b[39m.\u001b[39mdiv(num_heads, rounding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrunc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 16, but got 33"
     ]
    }
   ],
   "source": [
    "# Define the neural network model with Transformer components\n",
    "class DiamondPricePredictorWithTransformer(nn.Module):\n",
    "    def __init__(self, num_input_dim, cat_embedding_sizes, hidden_dim, num_heads):\n",
    "        super(DiamondPricePredictorWithTransformer, self).__init__()\n",
    "\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [\n",
    "                nn.Embedding(num_classes, emb_size)\n",
    "                for num_classes, emb_size in cat_embedding_sizes\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        total_emb_dim = sum(emb_size for _, emb_size in cat_embedding_sizes)\n",
    "\n",
    "        # Calculate adjusted embedding dimension for compatibility with num_heads\n",
    "        adjusted_embed_dim = num_heads * ((num_input_dim + total_emb_dim) // num_heads)\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=adjusted_embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "        )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.transformer_layer, num_layers=2\n",
    "        )  # Number of transformer layers\n",
    "\n",
    "        self.fc1 = nn.Linear(adjusted_embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.embedding_dim = 16  # Embedding dimension for column names\n",
    "        self.column_name_embedding = nn.Embedding(\n",
    "            len(X_train.columns), self.embedding_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, num_inputs, cat_inputs, col_indices):\n",
    "        # Embed column indices\n",
    "        col_name_embeddings = self.column_name_embedding(col_indices)\n",
    "\n",
    "        # Embed categorical features\n",
    "        embeddings = [\n",
    "            embedding(cat_inputs[:, i]) for i, embedding in enumerate(self.embeddings)\n",
    "        ]\n",
    "        cat_features = torch.cat(embeddings, dim=1)\n",
    "\n",
    "        # Expand dimensions to make room for the col_name_embeddings\n",
    "        col_name_embeddings_expanded = col_name_embeddings.unsqueeze(0).expand(\n",
    "            num_inputs.size(0), -1, -1\n",
    "        )\n",
    "\n",
    "        # Expand dimensions for num_inputs and cat_features to match col_name_embeddings\n",
    "        num_inputs_expanded = num_inputs.unsqueeze(1).expand(\n",
    "            -1, col_name_embeddings_expanded.size(1), -1\n",
    "        )\n",
    "        cat_features_expanded = cat_features.unsqueeze(1).expand(\n",
    "            -1, col_name_embeddings_expanded.size(1), -1\n",
    "        )\n",
    "\n",
    "        # Concatenate the embeddings and features\n",
    "        x = torch.cat(\n",
    "            [col_name_embeddings_expanded, num_inputs_expanded, cat_features_expanded],\n",
    "            dim=2,\n",
    "        )\n",
    "\n",
    "        # Permute dimensions to match transformer's expected input shape\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Apply Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Permute dimensions back to original shape\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Flatten back the input dimensions\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "num_input_dim = X_train_num.shape[1]\n",
    "cat_embedding_sizes = [\n",
    "    (len(le.classes_), min(50, (len(le.classes_) + 1) // 2))\n",
    "    for le in label_encoders.values()\n",
    "]\n",
    "hidden_dim = 64\n",
    "num_heads = 4  # Choose a suitable number of attention heads\n",
    "model = DiamondPricePredictorWithTransformer(\n",
    "    num_input_dim, cat_embedding_sizes, hidden_dim, num_heads\n",
    ")\n",
    "\n",
    "epochs = 10000\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Training loop\n",
    "col_indices = torch.arange(len(X_train.columns))\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(\n",
    "        X_train_num_tensor, X_train_cat_tensor, col_indices\n",
    "    )  # Pass numeric, categorical tensors, and column indices\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(\n",
    "        X_test_num_tensor, X_test_cat_tensor, col_indices\n",
    "    )  # Pass numeric, categorical tensors, and column indices\n",
    "    mse = mean_squared_error(y_test_tensor, test_predictions)\n",
    "    print(f\"Mean Squared Error on Test Data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
