{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir='runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Load and preprocess the dataset (assuming you have a CSV file)\n",
    "df = pd.read_csv(\"../data/diamonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_columns = [\"cut\", \"color\", \"clarity\"]\n",
    "num_columns = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "cat_values = pd.unique(df[cat_columns].values.ravel(\"K\"))\n",
    "target_column = \"price\"\n",
    "tokens = list(\n",
    "    chain(\n",
    "        cat_values,\n",
    "        cat_columns,\n",
    "        num_columns,\n",
    "        [\"PAD\", \"[NUMERIC_MASK]\", \"[MASK]\"],\n",
    "        [target_column],\n",
    "    )\n",
    ")\n",
    "token_dict = {token: i for i, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess categorical features\n",
    "X_train_cat = X_train[cat_columns].copy()\n",
    "X_test_cat = X_test[cat_columns].copy()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_cat[col] = X_train_cat[col].map(token_dict)\n",
    "    X_test_cat[col] = X_test_cat[col].map(token_dict)\n",
    "    # label_encoders[col] = le\n",
    "\n",
    "# Preprocess numeric features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[num_columns].copy())\n",
    "X_test_num = scaler.transform(X_test[num_columns].copy())\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(\n",
    "    X_train_cat.values, dtype=torch.int64\n",
    ").to(device)  # Use int64 dtype for categorical indices\n",
    "X_train_num_tensor = torch.tensor(X_train_num, dtype=torch.float32).to(device)\n",
    "X_test_cat_tensor = torch.tensor(\n",
    "    X_test_cat.values, dtype=torch.int64\n",
    ").to(device)  # Use int64 dtype for categorical indices\n",
    "X_test_num_tensor = torch.tensor(X_test_num, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50052</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41645</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42377</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17244</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44081</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23713</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31375</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21772</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cut  color  clarity\n",
       "1388     0     10       17\n",
       "50052    3      9       16\n",
       "41645    0      5       16\n",
       "42377    1      5       16\n",
       "17244    0      5       12\n",
       "...    ...    ...      ...\n",
       "44081    3      5       14\n",
       "23713    3      9       16\n",
       "31375    2     10       17\n",
       "21772    0      9       14\n",
       "4998     2      7       12\n",
       "\n",
       "[10788 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_head = d_model // n_heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        q = (\n",
    "            self.q_linear(q)\n",
    "            .view(batch_size, -1, self.n_heads, self.d_head)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "        k = (\n",
    "            self.k_linear(k)\n",
    "            .view(batch_size, -1, self.n_heads, self.d_head)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "        v = (\n",
    "            self.v_linear(v)\n",
    "            .view(batch_size, -1, self.n_heads, self.d_head)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "\n",
    "        attn_output, _ = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        attn_output = (\n",
    "            attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        )\n",
    "        out = self.out_linear(attn_output)\n",
    "        return out\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask=None):\n",
    "        matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
    "        d_k = q.size(-1)\n",
    "        scaled_attention_logits = matmul_qk / (d_k**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += mask * -1e9\n",
    "\n",
    "        attention_weights = F.softmax(scaled_attention_logits, dim=-1)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * d_model, d_model),\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        attn_output = self.multi_head_attention(q, k, v, mask)\n",
    "        out1 = self.layernorm1(q + attn_output)\n",
    "\n",
    "        ff_output = self.feed_forward(out1)\n",
    "        out2 = self.layernorm2(out1 + ff_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "# d_model = 64  # Embedding dimension\n",
    "# n_heads = 4  # Number of attention heads\n",
    "# seq_len_q = 10  # Sequence length for the query tensor\n",
    "# seq_len_k = 20  # Sequence length for the key tensor\n",
    "# batch_size = 32  # Batch size\n",
    "\n",
    "# # Random data\n",
    "# q = torch.rand((batch_size, seq_len_q, d_model))\n",
    "# k = torch.rand((batch_size, seq_len_k, d_model))\n",
    "# v = k  # Usually, value and key are the same in many applications\n",
    "\n",
    "# # Model\n",
    "# encoder_layer = TransformerEncoderLayer(d_model, n_heads)\n",
    "\n",
    "# # Forward pass\n",
    "# output = encoder_layer(q, k, v)\n",
    "# print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_tensor(tensor, model, propability=0.8):\n",
    "    if tensor.dtype == torch.float32:\n",
    "        is_numeric = True\n",
    "    elif tensor.dtype == torch.int64:\n",
    "        is_numeric = False\n",
    "    else:\n",
    "        raise ValueError(f\"Task {tensor.dtype} not supported.\")\n",
    "\n",
    "    tensor = tensor.clone()\n",
    "    bit_mask = torch.rand(tensor.shape) > propability\n",
    "    if is_numeric:\n",
    "        tensor[bit_mask] =torch.tensor(float(\"-Inf\"))\n",
    "    else:\n",
    "        tensor[bit_mask] = model.cat_mask_token\n",
    "    return tensor.to(model.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 9, 64]), torch.Size([3, 6]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TabTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokens,\n",
    "        numeric_col_tokens,\n",
    "        cat_col_tokens,\n",
    "        token_dict,\n",
    "        d_model=64,\n",
    "        n_heads=2,\n",
    "        device=device\n",
    "    ):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.device = device\n",
    "        self.d_model = d_model\n",
    "        self.tokens = tokens\n",
    "        self.token_dict = token_dict\n",
    "        # Masks\n",
    "        self.cat_mask_token = torch.tensor(self.token_dict[\"[MASK]\"]).to(device)\n",
    "        self.numeric_mask_token = torch.tensor(self.token_dict[\"[NUMERIC_MASK]\"]).to(device)\n",
    "\n",
    "        self.col_tokens = cat_col_tokens + numeric_col_tokens\n",
    "        self.n_tokens = len(tokens)  # TODO Make this\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.Embedding(self.n_tokens, self.d_model).to(device)\n",
    "        self.n_numeric_cols = len(numeric_col_tokens)\n",
    "        self.n_cat_cols = len(cat_col_tokens)\n",
    "        self.n_columns = self.n_numeric_cols + self.n_cat_cols\n",
    "        # self.numeric_embeddings = NumericEmbedding(d_model=self.d_model)\n",
    "        self.col_indices = torch.tensor(\n",
    "            [self.tokens.index(col) for col in self.col_tokens], dtype=torch.long\n",
    "        ).to(device)\n",
    "        self.numeric_indices = torch.tensor(\n",
    "            [self.tokens.index(col) for col in numeric_col_tokens], dtype=torch.long\n",
    "        ).to(device)\n",
    "        self.transformer_encoder = TransformerEncoderLayer(d_model, n_heads=n_heads).to(device)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model * 2, 1),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "\n",
    "        self.mlm_decoder = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model)\n",
    "        ).to(device)  # TODO try making more complex\n",
    "\n",
    "        self.mnm_decoder = nn.Sequential(\n",
    "            nn.Linear(self.n_columns * self.d_model, self.d_model * 4),  # Try making more complex\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_model*4, 6),\n",
    "        ).to(device)\n",
    "\n",
    "        self.flatten_layer = nn.Linear(len(self.col_tokens), 1).to(device)\n",
    "\n",
    "    def forward(self, num_inputs, cat_inputs, task=\"regression\"):\n",
    "        # Embed column indices\n",
    "        repeated_col_indices = self.col_indices.unsqueeze(0).repeat(\n",
    "            num_inputs.size(0), 1\n",
    "        )\n",
    "        col_embeddings = self.embeddings(repeated_col_indices)\n",
    "\n",
    "        repeated_numeric_indices = self.numeric_indices.unsqueeze(0).repeat(\n",
    "            num_inputs.size(0), 1\n",
    "        )\n",
    "        numeric_col_embeddings = self.embeddings(repeated_numeric_indices)\n",
    "\n",
    "        cat_embeddings = self.embeddings(cat_inputs)\n",
    "        \n",
    "        expanded_num_inputs = num_inputs.unsqueeze(2).repeat(1, 1, self.d_model)\n",
    "        inf_mask = (expanded_num_inputs == float('-inf')).all(dim=2)\n",
    "        base_numeric = torch.zeros_like(expanded_num_inputs)\n",
    "        \n",
    "        num_embeddings = numeric_col_embeddings[~inf_mask] * expanded_num_inputs[~inf_mask]\n",
    "        base_numeric[~inf_mask] = num_embeddings\n",
    "        base_numeric[inf_mask] = self.embeddings(self.numeric_mask_token)\n",
    "        # print(base_numeric)\n",
    "\n",
    "\n",
    "        # Replace those positions with the new embedding\n",
    "        # num_embeddings[inf_mask] = self.embeddings(self.numeric_mask_token)\n",
    "        \n",
    "        # if mnm is not None:\n",
    "        #     mnm = mnm.to(device)\n",
    "        #     # print(\n",
    "        #     #     f\"mnm.shape: {mnm.shape}, num_embeddings.shape: {num_embeddings.shape}\"\n",
    "        #     # )\n",
    "        #     # print(num_embeddings.sum())\n",
    "        #     numeric_mask_embedding = self.embeddings(self.numeric_mask_token)\n",
    "        #     # numeric_mask_embedding = torch.ones_like(numeric_mask_embedding)\n",
    "        #     # numeric_mask_embedding = torch.zeros_like(numeric_mask_embedding)\n",
    "        #     num_embeddings[mnm] = numeric_mask_embedding\n",
    "        #     # print(num_embeddings.sum())\n",
    "\n",
    "        query_embeddings = torch.cat([cat_embeddings, base_numeric], dim=1)\n",
    "        out = self.transformer_encoder(\n",
    "            col_embeddings,\n",
    "            query_embeddings,\n",
    "            query_embeddings\n",
    "            # col_embeddings, query_embeddings, query_embeddings\n",
    "        )\n",
    "        if task == \"regression\":\n",
    "            out = self.regressor(out)\n",
    "            out = self.flatten_layer(out.squeeze(-1))\n",
    "\n",
    "            return out\n",
    "        elif task == \"mlm\":\n",
    "            cat_out = self.mlm_decoder(out)\n",
    "            # print(f\"Out shape: {out.shape}, cat_out shape: {cat_out.shape}\")\n",
    "            numeric_out = out.view(out.size(0), -1)\n",
    "            # print(f\"numeric_out shape: {numeric_out.shape}\")\n",
    "            numeric_out = self.mnm_decoder(numeric_out)\n",
    "            return cat_out, numeric_out\n",
    "        else:\n",
    "            raise ValueError(f\"Task {task} not supported.\")\n",
    "\n",
    "\n",
    "no_price_tokens = tokens.copy()\n",
    "no_price_tokens.remove(\"price\")\n",
    "\n",
    "numeric_col_tokens = (\n",
    "    df.head().drop(\"price\", axis=1).select_dtypes(include=np.number).columns.to_list()\n",
    ")\n",
    "cat_col_tokens = df.head().select_dtypes(exclude=np.number).columns.to_list()\n",
    "\n",
    "model = TabTransformer(\n",
    "    no_price_tokens,\n",
    "    numeric_col_tokens=numeric_col_tokens,\n",
    "    cat_col_tokens=cat_col_tokens,\n",
    "    token_dict=token_dict,\n",
    ").to(device)\n",
    "batch_size = 3\n",
    "test_num = X_train_num_tensor[0:batch_size, :]\n",
    "test_num_mask = mask_tensor(test_num, model)\n",
    "test_cat = X_train_cat_tensor[0:batch_size, :]\n",
    "test_cat_mask = mask_tensor(test_cat, model)\n",
    "with torch.no_grad():\n",
    "    x = model(\n",
    "        test_num_mask,\n",
    "        test_cat_mask,\n",
    "        task=\"mlm\",\n",
    "    )\n",
    "x[0].shape, x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5147, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "mse_loss(test_num, x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cut', 'color', 'clarity', 'carat', 'depth', 'table', 'x', 'y', 'z']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.col_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask_pred(idx, batch_size, model, probability):\n",
    "    numeric_values = X_train_num_tensor[i : i + batch_size, :]\n",
    "    categorical_values = X_train_cat_tensor[i : i + batch_size, :]\n",
    "    numeric_masked = mask_tensor(numeric_values, model, propability=probability)\n",
    "    categorical_masked = mask_tensor(categorical_values, model, propability=probability)\n",
    "    \n",
    "    with torch.zero_grad():\n",
    "        cat_preds, numeric_preds = model(\n",
    "            numeric_masked, categorical_masked, task=\"mlm\"\n",
    "        )\n",
    "    cat_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([152, 64, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Loss: 0.8996\n",
      "Epoch 5/20 Loss: 0.5680\n",
      "Epoch 7/20 Loss: 0.4508\n",
      "Epoch 10/20 Loss: 0.3985\n",
      "Epoch 12/20 Loss: 0.3511\n",
      "Epoch 14/20 Loss: 0.3219\n",
      "Epoch 16/20 Loss: 0.2886\n",
      "Epoch 19/20 Loss: 0.2807\n"
     ]
    }
   ],
   "source": [
    "# Masked Tabualr Modeling\n",
    "epochs = 20\n",
    "batch_size = 1000\n",
    "lr = 0.001\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = f\"TryAgainPretrain.8_{model_time}\"\n",
    "\n",
    "summary_writer = SummaryWriter(\"runs/\" + model_name)\n",
    "\n",
    "batch_count = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, X_train_num_tensor.size(0), batch_size):\n",
    "        numeric_values = X_train_num_tensor[i : i + batch_size, :]\n",
    "        categorical_values = X_train_cat_tensor[i : i + batch_size, :]\n",
    "        numeric_masked = mask_tensor(numeric_values, model, propability=0.8)\n",
    "        categorical_masked = mask_tensor(categorical_values, model, propability=0.8)\n",
    "        optimizer.zero_grad()\n",
    "        cat_preds, numeric_preds = model(\n",
    "            numeric_masked, categorical_masked, task=\"mlm\"\n",
    "        )\n",
    "        cat_targets = torch.cat(\n",
    "            (categorical_values, model.numeric_indices.expand(categorical_values.size(0), -1)), dim=1\n",
    "        )\n",
    "        cat_preds = cat_preds.permute(0, 2, 1)\n",
    "        # print(\n",
    "        #     f\"cat_preds.shape: {cat_preds.shape}, cat_targets.shape: {cat_targets.shape}\"\n",
    "        # )\n",
    "        cat_loss = ce_loss(cat_preds, cat_targets)\n",
    "        numeric_loss = mse_loss(numeric_preds, numeric_values)\n",
    "        loss = cat_loss + numeric_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_count += 1\n",
    "        learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "        summary_writer.add_scalar(\"Loss/masked_loss\", loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\"Loss/mlm_loss\", cat_loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\"Loss/mnm_loss\", numeric_loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\"Metrics/LearningRate\", learning_rate, batch_count)\n",
    "        if batch_count % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():,.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the previous model seems to work but when I pre-train, we run into issues. Let's try again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Loss: 790,781.75\n",
      "Epoch 5/20 Loss: 555,031.38\n",
      "Epoch 7/20 Loss: 639,944.38\n",
      "Epoch 10/20 Loss: 475,933.25\n",
      "Epoch 12/20 Loss: 554,887.69\n",
      "Epoch 14/20 Loss: 562,919.56\n",
      "Epoch 16/20 Loss: 403,517.44\n",
      "Epoch 19/20 Loss: 454,190.78\n"
     ]
    }
   ],
   "source": [
    "# Regression Model\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 1000\n",
    "lr = 0.01\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = f\"AfterAlreadyPreTrain.8_{model_time}\"\n",
    "\n",
    "summary_writer = SummaryWriter(\"runs/\" + model_name)\n",
    "\n",
    "\n",
    "batch_count = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, X_train_num_tensor.size(0), batch_size):\n",
    "        num_inputs = X_train_num_tensor[i : i + batch_size, :]\n",
    "        cat_inputs = X_train_cat_tensor[i : i + batch_size, :]\n",
    "        # numeric_mask = torch.rand(num_inputs.shape) > 0.8\n",
    "        # cat_mask = torch.rand(cat_inputs.shape) > 0.8\n",
    "        # mlm = torch.rand(cat_inputs.shape) > 0.8  # Greater than 1 for testing\n",
    "        # mnm = torch.rand(num_inputs.shape) > 0.8\n",
    "        # mlm = None\n",
    "        # mnm = None\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(num_inputs, cat_inputs)\n",
    "        loss = loss_fn(y_pred, y_train_tensor[i : i + batch_size, :])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_count += 1\n",
    "        learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "        summary_writer.add_scalar(\"Loss/train\", loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\"Metrics/LearningRate\", learning_rate, batch_count)\n",
    "        if batch_count % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 3/20 Loss: 416,668.31\n",
    "Epoch 5/20 Loss: 308,602.41\n",
    "Epoch 7/20 Loss: 375,060.84\n",
    "Epoch 10/20 Loss: 346,249.38\n",
    "Epoch 12/20 Loss: 421,598.84\n",
    "Epoch 14/20 Loss: 362,426.00\n",
    "Epoch 16/20 Loss: 339,481.22\n",
    "Epoch 19/20 Loss: 379,399.06\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 660,564.94\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_num_tensor[0:10, :], X_test_cat_tensor[0:10, :])\n",
    "    loss = loss_fn(y_pred, y_test_tensor[0:10])\n",
    "    print(f\"Test loss: {loss.item():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 643.20 Actual: 559.00 Diff: 84.20\n",
      "Predicted: 2,318.71 Actual: 2,201.00 Diff: 117.71\n",
      "Predicted: 1,285.72 Actual: 1,238.00 Diff: 47.72\n",
      "Predicted: 1,374.23 Actual: 1,304.00 Diff: 70.23\n",
      "Predicted: 8,949.88 Actual: 6,901.00 Diff: 2,048.88\n",
      "Predicted: 4,276.42 Actual: 3,011.00 Diff: 1,265.42\n",
      "Predicted: 1,850.08 Actual: 1,765.00 Diff: 85.08\n",
      "Predicted: 1,819.77 Actual: 1,679.00 Diff: 140.77\n",
      "Predicted: 2,033.86 Actual: 2,102.00 Diff: -68.14\n",
      "Predicted: 5,653.07 Actual: 4,789.00 Diff: 864.07\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\n",
    "        f\"Predicted: {y_pred[i].item():,.2f} Actual: {y_test_tensor[i].item():,.2f}\",\n",
    "        f\"Diff: {y_pred[i].item() - y_test_tensor[i].item():,.2f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Predicted: 2,085.14 Actual: 559.00 Diff: 1,526.14\n",
    "Predicted: 3,381.02 Actual: 2,201.00 Diff: 1,180.02\n",
    "Predicted: 1,725.17 Actual: 1,238.00 Diff: 487.17\n",
    "Predicted: 1,914.37 Actual: 1,304.00 Diff: 610.37\n",
    "Predicted: 15,271.41 Actual: 6,901.00 Diff: 8,370.41\n",
    "Predicted: 7,173.91 Actual: 3,011.00 Diff: 4,162.91\n",
    "Predicted: 947.38 Actual: 1,765.00 Diff: -817.62\n",
    "Predicted: 604.91 Actual: 1,679.00 Diff: -1,074.09\n",
    "Predicted: 989.06 Actual: 2,102.00 Diff: -1,112.94\n",
    "Predicted: 9,508.21 Actual: 4,789.00 Diff: 4,719.21\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 643.20 Actual: 559.00\n",
      "Predicted: 2,318.71 Actual: 2,201.00\n",
      "Predicted: 1,285.72 Actual: 1,238.00\n",
      "Predicted: 1,374.23 Actual: 1,304.00\n",
      "Predicted: 8,949.88 Actual: 6,901.00\n",
      "Predicted: 4,276.42 Actual: 3,011.00\n",
      "Predicted: 1,850.08 Actual: 1,765.00\n",
      "Predicted: 1,819.77 Actual: 1,679.00\n",
      "Predicted: 2,033.86 Actual: 2,102.00\n",
      "Predicted: 5,653.07 Actual: 4,789.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Predicted: {y_pred[i].item():,.2f} Actual: {y_test_tensor[i].item():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 643.20 Actual: 559.00\n",
      "Predicted: 2,318.71 Actual: 2,201.00\n",
      "Predicted: 1,285.72 Actual: 1,238.00\n",
      "Predicted: 1,374.23 Actual: 1,304.00\n",
      "Predicted: 8,949.88 Actual: 6,901.00\n",
      "Predicted: 4,276.42 Actual: 3,011.00\n",
      "Predicted: 1,850.08 Actual: 1,765.00\n",
      "Predicted: 1,819.77 Actual: 1,679.00\n",
      "Predicted: 2,033.86 Actual: 2,102.00\n",
      "Predicted: 5,653.07 Actual: 4,789.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Predicted: {y_pred[i].item():,.2f} Actual: {y_test_tensor[i].item():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted: 688.47 Actual: 559.00\n",
    "# Predicted: 2,547.17 Actual: 2,201.00\n",
    "# Predicted: 1,044.95 Actual: 1,238.00\n",
    "# Predicted: 1,790.95 Actual: 1,304.00\n",
    "# Predicted: 10,160.45 Actual: 6,901.00\n",
    "# Predicted: 3,790.90 Actual: 3,011.00\n",
    "# Predicted: 1,729.77 Actual: 1,765.00\n",
    "# Predicted: 1,749.63 Actual: 1,679.00\n",
    "# Predicted: 2,328.92 Actual: 2,102.00\n",
    "# Predicted: 5,928.75 Actual: 4,789.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False,  True, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False,  True, False, False]],\n",
       "\n",
       "        [[False,  True, False, False,  True],\n",
       "         [False,  True, False,  True, False],\n",
       "         [False,  True,  True, False, False],\n",
       "         [ True,  True, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False],\n",
       "         [False, False,  True,  True, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False,  True, False,  True,  True]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 4, 5) > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rand() received an invalid combination of arguments - got (), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: rand() received an invalid combination of arguments - got (), but expected one of:\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "torch.rand()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "lcc_arn": "arn:aws:sagemaker:us-west-2:385115691352:studio-lifecycle-config/base-installs-widgets",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
