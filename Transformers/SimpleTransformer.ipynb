{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir='runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch.nn.init as init\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Load and preprocess the dataset (assuming you have a CSV file)\n",
    "df = pd.read_csv(\"../data/diamonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        init.xavier_uniform_(module.weight, gain=1)\n",
    "        if module.bias is not None:\n",
    "            init.constant_(module.bias, 0.000)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        init.uniform_(module.weight, 0.0, 0.5)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        init.normal_(module.weight, mean=0, std=1)\n",
    "        init.constant_(module.bias, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ideal': 0,\n",
       " 'Premium': 1,\n",
       " 'Good': 2,\n",
       " 'Very Good': 3,\n",
       " 'Fair': 4,\n",
       " 'E': 5,\n",
       " 'I': 6,\n",
       " 'J': 7,\n",
       " 'H': 8,\n",
       " 'F': 9,\n",
       " 'G': 10,\n",
       " 'D': 11,\n",
       " 'SI2': 12,\n",
       " 'SI1': 13,\n",
       " 'VS1': 14,\n",
       " 'VS2': 15,\n",
       " 'VVS2': 16,\n",
       " 'VVS1': 17,\n",
       " 'I1': 18,\n",
       " 'IF': 19,\n",
       " 'cut': 20,\n",
       " 'color': 21,\n",
       " 'clarity': 22,\n",
       " 'carat': 23,\n",
       " 'depth': 24,\n",
       " 'table': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28,\n",
       " 'PAD': 29,\n",
       " '[NUMERIC_MASK]': 30,\n",
       " '[MASK]': 31,\n",
       " 'price': 32}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = [\"cut\", \"color\", \"clarity\"]\n",
    "num_columns = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "cat_values = pd.unique(df[cat_columns].values.ravel(\"K\"))\n",
    "target_column = \"price\"\n",
    "tokens = list(\n",
    "    chain(\n",
    "        cat_values,\n",
    "        cat_columns,\n",
    "        num_columns,\n",
    "        [\"PAD\", \"[NUMERIC_MASK]\", \"[MASK]\"],\n",
    "        [target_column],\n",
    "    )\n",
    ")\n",
    "token_dict = {token: i for i, token in enumerate(tokens)}\n",
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnd_df = df.sample(frac=1, random_state=42)\n",
    "scaled_df = rnd_df.loc[:, cat_columns + num_columns + [target_column]]\n",
    "for col in cat_columns:\n",
    "    scaled_df[col] = scaled_df[col].map(token_dict)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_scaled = scaler.fit_transform(scaled_df[num_columns].copy())\n",
    "scaled_df[num_columns] = numeric_scaled\n",
    "\n",
    "X = scaled_df.drop(\"price\", axis=1)\n",
    "y = scaled_df[\"price\"]\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "# Categorical columns\n",
    "X_train_cat_tensor = torch.tensor(X_train[cat_columns].values, dtype=torch.int32).to(\n",
    "    device\n",
    ")\n",
    "X_test_cat_tensor = torch.tensor(X_test[cat_columns].values, dtype=torch.int32).to(\n",
    "    device\n",
    ")\n",
    "# Numeric columns\n",
    "X_train_num_tensor = torch.tensor(X_train[num_columns].values, dtype=torch.float32).to(\n",
    "    device\n",
    ")\n",
    "X_test_num_tensor = torch.tensor(X_test[num_columns].values, dtype=torch.float32).to(\n",
    "    device\n",
    ")\n",
    "y_train_tensor = (\n",
    "    torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    ")\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.177071</td>\n",
       "      <td>0.244725</td>\n",
       "      <td>-0.652139</td>\n",
       "      <td>-1.570008</td>\n",
       "      <td>-1.518684</td>\n",
       "      <td>-1.514447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cut  color  clarity     carat     depth     table         x         y  \\\n",
       "1388    0     10       17 -1.177071  0.244725 -0.652139 -1.570008 -1.518684   \n",
       "\n",
       "             z  \n",
       "1388 -1.514447  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 17], dtype=torch.int32),\n",
       " tensor([-1.1771,  0.2447, -0.6521, -1.5700, -1.5187, -1.5144]),\n",
       " tensor([559.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat_tensor[0], X_train_num_tensor[0], y_train_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_token_dict = {v: k for k, v in token_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_head = d_model // n_heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # self.initialize_parameters()\n",
    "        self.apply(initialize_parameters)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None, input_feed_forward=False):\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        if input_feed_forward:\n",
    "            q = (\n",
    "                self.q_linear(q)\n",
    "                .view(batch_size, -1, self.n_heads, self.d_head)\n",
    "                .transpose(1, 2)\n",
    "            )\n",
    "            k = (\n",
    "                self.k_linear(k)\n",
    "                .view(batch_size, -1, self.n_heads, self.d_head)\n",
    "                .transpose(1, 2)\n",
    "            )\n",
    "            v = (\n",
    "                self.v_linear(v)\n",
    "                .view(batch_size, -1, self.n_heads, self.d_head)\n",
    "                .transpose(1, 2)\n",
    "            )\n",
    "\n",
    "        attn_output, _ = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        attn_output = (\n",
    "            attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        )\n",
    "        out = self.out_linear(attn_output)\n",
    "        return out\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask=None):\n",
    "        matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
    "        d_k = q.size(-1)\n",
    "        scaled_attention_logits = matmul_qk / (d_k**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += mask * -1e9\n",
    "\n",
    "        attention_weights = F.softmax(scaled_attention_logits, dim=-1)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * d_model, d_model),\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        # self.initialize_parameters()\n",
    "        self.apply(initialize_parameters)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None, input_feed_forward=False):\n",
    "        attn_output = self.multi_head_attention(q, k, v, mask, input_feed_forward)\n",
    "        out1 = self.layernorm1(q + attn_output)\n",
    "\n",
    "        ff_output = self.feed_forward(out1)\n",
    "        out2 = self.layernorm2(out1 + ff_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "d_model = 64  # Embedding dimension\n",
    "n_heads = 4  # Number of attention heads\n",
    "seq_len_q = 10  # Sequence length for the query tensor\n",
    "seq_len_k = 20  # Sequence length for the key tensor\n",
    "batch_size = 32  # Batch size\n",
    "\n",
    "# Random data\n",
    "q = torch.rand((batch_size, seq_len_q, d_model))\n",
    "k = torch.rand((batch_size, seq_len_k, d_model))\n",
    "v = k  # Usually, value and key are the same in many applications\n",
    "\n",
    "# Model\n",
    "encoder_layer = TransformerEncoderLayer(d_model, n_heads)\n",
    "\n",
    "# Forward pass\n",
    "output = encoder_layer(q, k, v)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_tensor(tensor, model, probability=0.8):\n",
    "    if tensor.dtype == torch.float32:\n",
    "        is_numeric = True\n",
    "    elif tensor.dtype == torch.int32:\n",
    "        is_numeric = False\n",
    "    else:\n",
    "        raise ValueError(f\"Task {tensor.dtype} not supported.\")\n",
    "\n",
    "    tensor = tensor.clone()\n",
    "    bit_mask = torch.rand(tensor.shape) > probability\n",
    "    if is_numeric:\n",
    "        tensor[bit_mask] = torch.tensor(float(\"-Inf\"))\n",
    "    else:\n",
    "        tensor[bit_mask] = model.cat_mask_token\n",
    "    return tensor.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 9, 32]), torch.Size([3, 6]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TabTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokens,\n",
    "        numeric_col_tokens,\n",
    "        cat_col_tokens,\n",
    "        token_dict,\n",
    "        d_model=64,\n",
    "        n_heads=4,\n",
    "        device=device,\n",
    "    ):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.device = device\n",
    "        self.d_model = d_model\n",
    "        self.tokens = tokens\n",
    "        self.token_dict = token_dict\n",
    "        self.decoder_dict = {v: k for k, v in token_dict.items()}\n",
    "        # Masks\n",
    "        self.cat_mask_token = torch.tensor(self.token_dict[\"[MASK]\"]).to(device)\n",
    "        self.numeric_mask_token = torch.tensor(self.token_dict[\"[NUMERIC_MASK]\"]).to(\n",
    "            device\n",
    "        )\n",
    "\n",
    "        self.col_tokens = cat_col_tokens + numeric_col_tokens\n",
    "        self.n_tokens = len(tokens)  # TODO Make this\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.Embedding(self.n_tokens, self.d_model).to(device)\n",
    "        self.n_numeric_cols = len(numeric_col_tokens)\n",
    "        self.n_cat_cols = len(cat_col_tokens)\n",
    "        self.n_columns = self.n_numeric_cols + self.n_cat_cols\n",
    "        # self.numeric_embeddings = NumericEmbedding(d_model=self.d_model)\n",
    "        self.col_indices = torch.tensor(\n",
    "            [self.tokens.index(col) for col in self.col_tokens], dtype=torch.long\n",
    "        ).to(device)\n",
    "        self.numeric_indices = torch.tensor(\n",
    "            [self.tokens.index(col) for col in numeric_col_tokens], dtype=torch.long\n",
    "        ).to(device)\n",
    "        self.transformer_encoder1 = TransformerEncoderLayer(\n",
    "            d_model, n_heads=n_heads\n",
    "        ).to(device)\n",
    "        self.transformer_encoder2 = TransformerEncoderLayer(\n",
    "            d_model, n_heads=n_heads\n",
    "        ).to(device)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model * 2, 1),\n",
    "            # nn.ReLU(),\n",
    "        ).to(device)\n",
    "\n",
    "        self.mlm_decoder = nn.Sequential(nn.Linear(d_model, self.n_tokens)).to(\n",
    "            device\n",
    "        )  # TODO try making more complex\n",
    "\n",
    "        self.mnm_decoder = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                self.n_columns * self.d_model, self.d_model * 4\n",
    "            ),  # Try making more complex\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_model * 4, self.n_numeric_cols),\n",
    "        ).to(device)\n",
    "\n",
    "        self.flatten_layer = nn.Linear(len(self.col_tokens), 1).to(device)\n",
    "        self.apply(initialize_parameters)\n",
    "\n",
    "    def forward(self, num_inputs, cat_inputs, task=\"regression\"):\n",
    "        # Embed column indices\n",
    "        repeated_col_indices = self.col_indices.unsqueeze(0).repeat(\n",
    "            num_inputs.size(0), 1\n",
    "        )\n",
    "        col_embeddings = self.embeddings(repeated_col_indices)\n",
    "\n",
    "        cat_embeddings = self.embeddings(cat_inputs)\n",
    "\n",
    "        expanded_num_inputs = num_inputs.unsqueeze(2).repeat(1, 1, self.d_model)\n",
    "        with torch.no_grad():\n",
    "            repeated_numeric_indices = self.numeric_indices.unsqueeze(0).repeat(\n",
    "                num_inputs.size(0), 1\n",
    "            )\n",
    "            numeric_col_embeddings = self.embeddings(repeated_numeric_indices)\n",
    "\n",
    "            inf_mask = (expanded_num_inputs == float(\"-inf\")).all(dim=2)\n",
    "\n",
    "        base_numeric = torch.zeros_like(expanded_num_inputs)\n",
    "\n",
    "        num_embeddings = (\n",
    "            numeric_col_embeddings[~inf_mask] * expanded_num_inputs[~inf_mask]\n",
    "        )\n",
    "        base_numeric[~inf_mask] = num_embeddings\n",
    "        base_numeric[inf_mask] = self.embeddings(self.numeric_mask_token)\n",
    "\n",
    "        query_embeddings = torch.cat([cat_embeddings, base_numeric], dim=1)\n",
    "        out = self.transformer_encoder1(\n",
    "            col_embeddings,\n",
    "            # query_embeddings,\n",
    "            query_embeddings,\n",
    "            query_embeddings\n",
    "            # col_embeddings, query_embeddings, query_embeddings\n",
    "        )\n",
    "        out = self.transformer_encoder2(out, out, out)\n",
    "\n",
    "        if task == \"regression\":\n",
    "            out = self.regressor(out)\n",
    "            out = self.flatten_layer(out.squeeze(-1))\n",
    "\n",
    "            return out\n",
    "        elif task == \"mlm\":\n",
    "            cat_out = self.mlm_decoder(out)\n",
    "            # print(f\"Out shape: {out.shape}, cat_out shape: {cat_out.shape}\")\n",
    "            numeric_out = out.view(out.size(0), -1)\n",
    "            # print(f\"numeric_out shape: {numeric_out.shape}\")\n",
    "            numeric_out = self.mnm_decoder(numeric_out)\n",
    "            return cat_out, numeric_out\n",
    "        else:\n",
    "            raise ValueError(f\"Task {task} not supported.\")\n",
    "\n",
    "\n",
    "no_price_tokens = tokens.copy()\n",
    "no_price_tokens.remove(\"price\")\n",
    "\n",
    "numeric_col_tokens = (\n",
    "    df.head().drop(\"price\", axis=1).select_dtypes(include=np.number).columns.to_list()\n",
    ")\n",
    "cat_col_tokens = df.head().select_dtypes(exclude=np.number).columns.to_list()\n",
    "\n",
    "\n",
    "tab_transformer_model_config = dict(\n",
    "    tokens=no_price_tokens,\n",
    "    numeric_col_tokens=numeric_col_tokens,\n",
    "    cat_col_tokens=cat_col_tokens,\n",
    "    token_dict=token_dict,\n",
    "    n_heads=8,\n",
    ")\n",
    "model = TabTransformer(**tab_transformer_model_config).to(device)\n",
    "\n",
    "batch_size = 3\n",
    "test_num = X_train_num_tensor[0:batch_size, :]\n",
    "test_num_mask = mask_tensor(test_num, model)\n",
    "test_cat = X_train_cat_tensor[0:batch_size, :]\n",
    "test_cat_mask = mask_tensor(test_cat, model)\n",
    "with torch.no_grad():\n",
    "    x = model(\n",
    "        test_num_mask,\n",
    "        test_cat_mask,\n",
    "        task=\"mlm\",\n",
    "    )\n",
    "x[0].shape, x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ideal', 'G', 'VVS1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.decoder_dict[i.item()] for i in X_train_cat_tensor[0 : 0 + 1, :][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual': {'cut': 'Ideal',\n",
       "  'color': 'G',\n",
       "  'clarity': 'VVS1',\n",
       "  'carat': -1.1770710945129395,\n",
       "  'depth': 0.2447250783443451,\n",
       "  'table': -0.6521385312080383,\n",
       "  'x': -1.5700081586837769,\n",
       "  'y': -1.5186843872070312,\n",
       "  'z': -1.5144472122192383},\n",
       " 'masked': {'cut': 'Ideal',\n",
       "  'color': '[MASK]',\n",
       "  'clarity': 'VVS1',\n",
       "  'carat': -1.1770710945129395,\n",
       "  'depth': 0.2447250783443451,\n",
       "  'table': -inf,\n",
       "  'x': -1.5700081586837769,\n",
       "  'y': -1.5186843872070312,\n",
       "  'z': -1.5144472122192383},\n",
       " 'pred': {'cut': 'Very Good',\n",
       "  'color': 'G',\n",
       "  'clarity': 'VS1',\n",
       "  'carat': -2.6973633766174316,\n",
       "  'depth': 0.8388558626174927,\n",
       "  'table': -1.164834976196289,\n",
       "  'x': -0.07436558604240417,\n",
       "  'y': 0.6589386463165283,\n",
       "  'z': -2.2548511028289795}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_mask_pred(i, model, probability):\n",
    "    numeric_values = X_train_num_tensor[i : i + 1, :]\n",
    "    categorical_values = X_train_cat_tensor[i : i + 1, :]\n",
    "    numeric_masked = mask_tensor(numeric_values, model, probability=probability)\n",
    "    categorical_masked = mask_tensor(categorical_values, model, probability=probability)\n",
    "    # Predictions\n",
    "    with torch.no_grad():\n",
    "        cat_preds, numeric_preds = model(numeric_masked, categorical_masked, task=\"mlm\")\n",
    "    # Get the predicted tokens from cat_preds\n",
    "    cat_preds = cat_preds.argmax(dim=2)\n",
    "    # Get the words from the tokens\n",
    "    decoder_dict = model.decoder_dict\n",
    "    cat_preds = [decoder_dict[i.item()] for i in cat_preds[0]]\n",
    "\n",
    "    results_dict = {k: cat_preds[i] for i, k in enumerate(model.col_tokens)}\n",
    "    for i, k in enumerate(model.col_tokens[model.n_cat_cols :]):\n",
    "        results_dict[k] = numeric_preds[0][i].item()\n",
    "    # Get the masked values\n",
    "    categorical_masked = [decoder_dict[i.item()] for i in categorical_masked[0]]\n",
    "    numeric_masked = numeric_masked[0].tolist()\n",
    "    masked_values = categorical_masked + numeric_masked\n",
    "    # zip the masked values with the column names\n",
    "    masked_values = dict(zip(model.col_tokens, masked_values))\n",
    "    # Get the original values\n",
    "    categorical_values = [decoder_dict[i.item()] for i in categorical_values[0]]\n",
    "    numeric_values = numeric_values[0].tolist()\n",
    "    original_values = categorical_values + numeric_values\n",
    "    # zip the original values with the column names\n",
    "    original_values = dict(zip(model.col_tokens, original_values))\n",
    "    # print(numeric_masked)\n",
    "    # print(categorical_masked)\n",
    "    result_dict = {\n",
    "        \"actual\": original_values,\n",
    "        \"masked\": masked_values,\n",
    "        \"pred\": results_dict,\n",
    "    }\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "show_mask_pred(0, model, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked Tabualr Modeling\n",
    "base_model_name = \"no_grad10x8h\"\n",
    "\n",
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = f\"{base_model_name}_{model_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Loss: 2.6014\n",
      "Epoch 5/100 Loss: 2.4068\n",
      "Epoch 7/100 Loss: 1.8258\n",
      "Epoch 10/100 Loss: 1.7211\n",
      "Epoch 12/100 Loss: 1.5793\n",
      "Epoch 14/100 Loss: 1.8378\n",
      "Epoch 16/100 Loss: 1.4947\n",
      "Epoch 19/100 Loss: 1.2633\n",
      "Epoch 21/100 Loss: 1.0506\n",
      "Epoch 23/100 Loss: 0.9923\n",
      "Epoch 25/100 Loss: 1.2857\n",
      "Epoch 28/100 Loss: 1.0476\n",
      "Epoch 30/100 Loss: 1.8471\n",
      "Epoch 32/100 Loss: 1.2106\n",
      "Epoch 35/100 Loss: 1.2373\n",
      "Epoch 37/100 Loss: 1.0830\n",
      "Epoch 39/100 Loss: 1.0620\n",
      "Epoch 41/100 Loss: 1.0463\n",
      "Epoch 44/100 Loss: 0.9681\n",
      "Epoch 46/100 Loss: 0.8273\n",
      "Epoch 48/100 Loss: 0.8465\n",
      "Epoch 50/100 Loss: 0.7984\n",
      "Epoch 53/100 Loss: 0.9512\n",
      "Epoch 55/100 Loss: 1.4639\n",
      "Epoch 57/100 Loss: 0.9741\n",
      "Epoch 60/100 Loss: 0.8424\n",
      "Epoch 62/100 Loss: 0.9699\n",
      "Epoch 64/100 Loss: 1.1518\n",
      "Epoch 66/100 Loss: 0.9715\n",
      "Epoch 69/100 Loss: 0.8965\n",
      "Epoch 71/100 Loss: 0.8300\n",
      "Epoch 73/100 Loss: 0.8194\n",
      "Epoch 75/100 Loss: 0.5000\n",
      "Epoch 78/100 Loss: 0.8621\n",
      "Epoch 80/100 Loss: 0.8035\n",
      "Epoch 82/100 Loss: 0.7000\n",
      "Epoch 85/100 Loss: 0.9032\n",
      "Epoch 87/100 Loss: 0.7467\n",
      "Epoch 89/100 Loss: 1.0550\n",
      "Epoch 91/100 Loss: 0.9859\n",
      "Epoch 94/100 Loss: 0.6953\n",
      "Epoch 96/100 Loss: 0.8010\n",
      "Epoch 98/100 Loss: 0.7316\n",
      "Epoch 100/100 Loss: 0.8190\n"
     ]
    }
   ],
   "source": [
    "# Masked Tabualr Modeling\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "lr = 0.001\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "numeric_loss_scaler = 15\n",
    "summary_writer = SummaryWriter(\"runs/\" + model_name)\n",
    "\n",
    "batch_count = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, X_train_num_tensor.size(0), batch_size):\n",
    "        numeric_values = X_train_num_tensor[i : i + batch_size, :]\n",
    "        categorical_values = X_train_cat_tensor[i : i + batch_size, :]\n",
    "        numeric_masked = mask_tensor(numeric_values, model, probability=0.8)\n",
    "        categorical_masked = mask_tensor(categorical_values, model, probability=0.8)\n",
    "        optimizer.zero_grad()\n",
    "        cat_preds, numeric_preds = model(numeric_masked, categorical_masked, task=\"mlm\")\n",
    "        cat_targets = torch.cat(\n",
    "            (\n",
    "                categorical_values,\n",
    "                model.numeric_indices.expand(categorical_values.size(0), -1),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        cat_preds = cat_preds.permute(0, 2, 1)  # TODO investigate as possible bug\n",
    "        # print(\n",
    "        #     f\"cat_preds.shape: {cat_preds.shape}, cat_targets.shape: {cat_targets.shape}\"\n",
    "        # )\n",
    "        cat_loss = ce_loss(cat_preds, cat_targets)\n",
    "        numeric_loss = (\n",
    "            mse_loss(numeric_preds, numeric_values) * numeric_loss_scaler\n",
    "        )  # Hyper param\n",
    "        loss = cat_loss + numeric_loss  # TODO Look at scaling\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_count += 1\n",
    "        learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "        summary_writer.add_scalar(\"LossTrain/agg_mask\", loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\"LossTrain/mlm_loss\", cat_loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\n",
    "            \"LossTrain/mnm_loss\", numeric_loss.item(), batch_count\n",
    "        )\n",
    "        summary_writer.add_scalar(\"Metrics/mtm_lr\", learning_rate, batch_count)\n",
    "        if batch_count % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():,.4f}\")\n",
    "            # Test set\n",
    "            with torch.no_grad():\n",
    "                numeric_values = X_test_num_tensor\n",
    "                categorical_values = X_test_cat_tensor\n",
    "                numeric_masked = mask_tensor(numeric_values, model, probability=0.8)\n",
    "                categorical_masked = mask_tensor(\n",
    "                    categorical_values, model, probability=0.8\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                cat_preds, numeric_preds = model(\n",
    "                    numeric_masked, categorical_masked, task=\"mlm\"\n",
    "                )\n",
    "                cat_targets = torch.cat(\n",
    "                    (\n",
    "                        categorical_values,\n",
    "                        model.numeric_indices.expand(categorical_values.size(0), -1),\n",
    "                    ),\n",
    "                    dim=1,\n",
    "                )\n",
    "\n",
    "                cat_preds = cat_preds.permute(0, 2, 1)\n",
    "                # print(\n",
    "                #     f\"cat_preds.shape: {cat_preds.shape}, cat_targets.shape: {cat_targets.shape}\"\n",
    "                # )\n",
    "                cat_loss = ce_loss(cat_preds, cat_targets)\n",
    "                numeric_loss = (\n",
    "                    mse_loss(numeric_preds, numeric_values) * numeric_loss_scaler\n",
    "                )  # Hyper param\n",
    "                loss = cat_loss + numeric_loss\n",
    "                summary_writer.add_scalar(\"LossTest/agg_loss\", loss.item(), batch_count)\n",
    "            summary_writer.add_scalar(\"LossTest/mlm_loss\", cat_loss.item(), batch_count)\n",
    "            summary_writer.add_scalar(\n",
    "                \"LossTest/mnm_loss\", numeric_loss.item(), batch_count\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>-1.177071</td>\n",
       "      <td>0.244725</td>\n",
       "      <td>-0.652139</td>\n",
       "      <td>-1.570008</td>\n",
       "      <td>-1.518684</td>\n",
       "      <td>-1.514447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masked</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>[MASK]</td>\n",
       "      <td>[MASK]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.652139</td>\n",
       "      <td>-1.570008</td>\n",
       "      <td>-1.518684</td>\n",
       "      <td>-1.514447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>-1.209662</td>\n",
       "      <td>0.089562</td>\n",
       "      <td>-0.724785</td>\n",
       "      <td>-1.542991</td>\n",
       "      <td>-1.519413</td>\n",
       "      <td>-1.501559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cut   color clarity     carat     depth     table         x  \\\n",
       "actual  Ideal       G    VVS1 -1.177071  0.244725 -0.652139 -1.570008   \n",
       "masked  Ideal  [MASK]  [MASK]      -inf      -inf -0.652139 -1.570008   \n",
       "pred    Ideal       G     VS2 -1.209662  0.089562 -0.724785 -1.542991   \n",
       "\n",
       "               y         z  \n",
       "actual -1.518684 -1.514447  \n",
       "masked -1.518684 -1.514447  \n",
       "pred   -1.519413 -1.501559  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = show_mask_pred(\n",
    "    0, model, 0.8\n",
    ")  # Check for learning... XFKAT # Why is color `GOOD`????? TODO\n",
    "pd.DataFrame(x).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the previous model seems to work but when I pre-train, we run into issues. Let's try again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MTM model\n",
    "torch.save(model.state_dict(), \"./models/latest_mtm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 Test Loss: 31,068,604.00\n",
      "Epoch 2/500 Test Loss: 30,947,444.00\n",
      "Epoch 3/500 Test Loss: 30,781,222.00\n",
      "Epoch 4/500 Test Loss: 30,600,790.00\n",
      "Epoch 5/500 Test Loss: 30,413,112.00\n",
      "Epoch 6/500 Test Loss: 30,200,550.00\n",
      "Epoch 7/500 Test Loss: 29,949,886.00\n",
      "Epoch 8/500 Test Loss: 29,655,768.00\n",
      "Epoch 9/500 Test Loss: 29,316,668.00\n",
      "Epoch 10/500 Test Loss: 28,933,258.00\n",
      "Epoch 11/500 Test Loss: 28,501,498.00\n",
      "Epoch 12/500 Test Loss: 28,015,534.00\n",
      "Epoch 13/500 Test Loss: 27,470,594.00\n",
      "Epoch 14/500 Test Loss: 26,865,714.00\n",
      "Epoch 15/500 Test Loss: 26,201,934.00\n",
      "Epoch 16/500 Test Loss: 25,479,440.00\n",
      "Epoch 17/500 Test Loss: 24,698,682.00\n",
      "Epoch 18/500 Test Loss: 23,862,788.00\n",
      "Epoch 19/500 Test Loss: 22,978,056.00\n",
      "Epoch 20/500 Test Loss: 22,053,906.00\n",
      "Epoch 21/500 Test Loss: 21,103,454.00\n",
      "Epoch 22/500 Test Loss: 20,143,922.00\n",
      "Epoch 23/500 Test Loss: 19,197,380.00\n",
      "Epoch 24/500 Test Loss: 18,291,930.00\n",
      "Epoch 25/500 Test Loss: 17,462,276.00\n",
      "Epoch 26/500 Test Loss: 16,749,183.00\n",
      "Epoch 27/500 Test Loss: 16,197,425.00\n",
      "Epoch 28/500 Test Loss: 15,852,296.00\n",
      "Epoch 29/500 Test Loss: 15,750,877.00\n",
      "Epoch 30/500 Test Loss: 15,906,495.00\n",
      "Epoch 31/500 Test Loss: 16,286,707.00\n",
      "Epoch 32/500 Test Loss: 16,791,086.00\n",
      "Epoch 33/500 Test Loss: 17,244,780.00\n",
      "Epoch 34/500 Test Loss: 17,431,318.00\n",
      "Epoch 35/500 Test Loss: 17,190,744.00\n",
      "Epoch 36/500 Test Loss: 16,533,704.00\n",
      "Epoch 37/500 Test Loss: 15,639,819.00\n",
      "Epoch 38/500 Test Loss: 15,580,851.00\n",
      "Epoch 39/500 Test Loss: 14,849,566.00\n",
      "Epoch 40/500 Test Loss: 14,228,011.00\n",
      "Epoch 41/500 Test Loss: 14,716,146.00\n",
      "Epoch 42/500 Test Loss: 10,403,961.00\n",
      "Epoch 43/500 Test Loss: 10,405,576.00\n",
      "Epoch 44/500 Test Loss: 8,634,228.00\n",
      "Epoch 45/500 Test Loss: 8,319,248.50\n",
      "Epoch 46/500 Test Loss: 7,873,295.50\n",
      "Epoch 47/500 Test Loss: 6,889,867.50\n",
      "Epoch 48/500 Test Loss: 6,652,700.00\n",
      "Epoch 49/500 Test Loss: 6,007,621.00\n",
      "Epoch 50/500 Test Loss: 5,196,253.00\n",
      "Epoch 51/500 Test Loss: 4,915,561.50\n",
      "Epoch 52/500 Test Loss: 4,038,622.25\n",
      "Epoch 53/500 Test Loss: 4,465,683.50\n",
      "Epoch 54/500 Test Loss: 3,244,880.25\n",
      "Epoch 55/500 Test Loss: 3,274,222.75\n",
      "Epoch 56/500 Test Loss: 2,396,183.00\n",
      "Epoch 57/500 Test Loss: 3,037,148.00\n",
      "Epoch 58/500 Test Loss: 1,928,656.12\n",
      "Epoch 59/500 Test Loss: 2,166,325.25\n",
      "Epoch 60/500 Test Loss: 1,751,798.38\n",
      "Epoch 61/500 Test Loss: 1,737,973.62\n",
      "Epoch 62/500 Test Loss: 1,618,070.38\n",
      "Epoch 63/500 Test Loss: 1,250,339.12\n",
      "Epoch 64/500 Test Loss: 1,283,578.75\n",
      "Epoch 65/500 Test Loss: 980,563.94\n",
      "Epoch 66/500 Test Loss: 1,254,513.38\n",
      "Epoch 67/500 Test Loss: 979,381.94\n",
      "Epoch 68/500 Test Loss: 1,071,065.88\n",
      "Epoch 69/500 Test Loss: 891,936.19\n",
      "Epoch 70/500 Test Loss: 852,635.50\n",
      "Epoch 71/500 Test Loss: 861,366.25\n",
      "Epoch 72/500 Test Loss: 742,907.69\n",
      "Epoch 73/500 Test Loss: 846,667.75\n",
      "Epoch 74/500 Test Loss: 670,406.19\n",
      "Epoch 75/500 Test Loss: 737,362.44\n",
      "Epoch 76/500 Test Loss: 627,814.94\n",
      "Epoch 77/500 Test Loss: 718,011.88\n",
      "Epoch 78/500 Test Loss: 600,351.12\n",
      "Epoch 79/500 Test Loss: 655,717.19\n",
      "Epoch 80/500 Test Loss: 575,315.81\n",
      "Epoch 81/500 Test Loss: 625,550.88\n",
      "Epoch 82/500 Test Loss: 557,308.25\n",
      "Epoch 83/500 Test Loss: 608,825.50\n",
      "Epoch 84/500 Test Loss: 554,944.62\n",
      "Epoch 85/500 Test Loss: 573,319.19\n",
      "Epoch 86/500 Test Loss: 552,710.69\n",
      "Epoch 87/500 Test Loss: 555,827.75\n",
      "Epoch 88/500 Test Loss: 534,530.62\n",
      "Epoch 89/500 Test Loss: 525,692.44\n",
      "Epoch 90/500 Test Loss: 532,640.56\n",
      "Epoch 91/500 Test Loss: 514,469.59\n",
      "Epoch 92/500 Test Loss: 516,256.00\n",
      "Epoch 93/500 Test Loss: 510,383.09\n",
      "Epoch 94/500 Test Loss: 512,485.81\n",
      "Epoch 95/500 Test Loss: 504,074.72\n",
      "Epoch 96/500 Test Loss: 498,871.88\n",
      "Epoch 97/500 Test Loss: 508,519.28\n",
      "Epoch 98/500 Test Loss: 497,150.00\n",
      "Epoch 99/500 Test Loss: 500,003.97\n",
      "Epoch 100/500 Test Loss: 498,796.25\n",
      "Epoch 101/500 Test Loss: 499,123.25\n",
      "Epoch 102/500 Test Loss: 500,947.38\n",
      "Epoch 103/500 Test Loss: 491,768.50\n",
      "Epoch 104/500 Test Loss: 502,003.44\n",
      "Epoch 105/500 Test Loss: 492,820.50\n",
      "Epoch 106/500 Test Loss: 496,643.69\n",
      "Epoch 107/500 Test Loss: 499,025.91\n",
      "Epoch 108/500 Test Loss: 495,468.88\n",
      "Epoch 109/500 Test Loss: 495,638.62\n",
      "Epoch 110/500 Test Loss: 502,984.62\n",
      "Epoch 111/500 Test Loss: 499,004.28\n",
      "Epoch 112/500 Test Loss: 500,624.91\n",
      "Epoch 113/500 Test Loss: 505,050.00\n",
      "Epoch 114/500 Test Loss: 504,326.97\n",
      "Epoch 115/500 Test Loss: 504,261.34\n",
      "Epoch 116/500 Test Loss: 507,895.88\n",
      "Epoch 117/500 Test Loss: 507,211.38\n",
      "Epoch 118/500 Test Loss: 508,806.75\n",
      "Epoch 119/500 Test Loss: 509,144.19\n",
      "Epoch 120/500 Test Loss: 511,615.94\n",
      "Epoch 121/500 Test Loss: 514,758.00\n",
      "Epoch 122/500 Test Loss: 517,702.06\n",
      "Epoch 123/500 Test Loss: 518,939.91\n",
      "Epoch 124/500 Test Loss: 521,392.31\n",
      "Epoch 125/500 Test Loss: 522,590.72\n",
      "Epoch 126/500 Test Loss: 526,104.50\n",
      "Epoch 127/500 Test Loss: 527,146.38\n",
      "Epoch 128/500 Test Loss: 531,346.75\n",
      "Epoch 129/500 Test Loss: 532,641.06\n",
      "Epoch 130/500 Test Loss: 544,579.31\n",
      "Epoch 131/500 Test Loss: 557,374.81\n",
      "Epoch 132/500 Test Loss: 622,708.44\n",
      "Epoch 133/500 Test Loss: 654,599.56\n",
      "Epoch 134/500 Test Loss: 654,899.62\n",
      "Epoch 135/500 Test Loss: 552,145.88\n",
      "Epoch 136/500 Test Loss: 575,112.75\n",
      "Epoch 137/500 Test Loss: 639,838.88\n",
      "Epoch 138/500 Test Loss: 558,164.94\n",
      "Epoch 139/500 Test Loss: 564,685.19\n",
      "Epoch 140/500 Test Loss: 620,140.31\n",
      "Epoch 141/500 Test Loss: 552,141.06\n",
      "Epoch 142/500 Test Loss: 571,114.62\n",
      "Epoch 143/500 Test Loss: 599,072.81\n",
      "Epoch 144/500 Test Loss: 547,733.00\n",
      "Epoch 145/500 Test Loss: 567,292.44\n",
      "Epoch 146/500 Test Loss: 588,473.44\n",
      "Epoch 147/500 Test Loss: 550,022.44\n",
      "Epoch 148/500 Test Loss: 573,527.69\n",
      "Epoch 149/500 Test Loss: 588,643.88\n",
      "Epoch 150/500 Test Loss: 557,381.19\n",
      "Epoch 151/500 Test Loss: 575,665.69\n",
      "Epoch 152/500 Test Loss: 593,310.38\n",
      "Epoch 153/500 Test Loss: 559,153.00\n",
      "Epoch 154/500 Test Loss: 574,221.31\n",
      "Epoch 155/500 Test Loss: 597,994.38\n",
      "Epoch 156/500 Test Loss: 564,777.88\n",
      "Epoch 157/500 Test Loss: 569,828.62\n",
      "Epoch 158/500 Test Loss: 597,928.12\n",
      "Epoch 159/500 Test Loss: 572,908.94\n",
      "Epoch 160/500 Test Loss: 571,823.69\n",
      "Epoch 161/500 Test Loss: 591,198.19\n",
      "Epoch 162/500 Test Loss: 584,014.19\n",
      "Epoch 163/500 Test Loss: 586,130.38\n",
      "Epoch 164/500 Test Loss: 583,875.94\n",
      "Epoch 165/500 Test Loss: 586,747.19\n",
      "Epoch 166/500 Test Loss: 603,650.25\n",
      "Epoch 167/500 Test Loss: 589,016.25\n",
      "Epoch 168/500 Test Loss: 590,982.94\n",
      "Epoch 169/500 Test Loss: 592,925.62\n",
      "Epoch 170/500 Test Loss: 593,465.25\n",
      "Epoch 171/500 Test Loss: 610,550.62\n",
      "Epoch 172/500 Test Loss: 600,562.88\n",
      "Epoch 173/500 Test Loss: 611,994.56\n",
      "Epoch 174/500 Test Loss: 600,292.75\n",
      "Epoch 175/500 Test Loss: 604,652.62\n",
      "Epoch 176/500 Test Loss: 601,504.62\n",
      "Epoch 177/500 Test Loss: 603,546.00\n",
      "Epoch 178/500 Test Loss: 609,687.75\n",
      "Epoch 179/500 Test Loss: 607,708.81\n",
      "Epoch 180/500 Test Loss: 627,652.38\n",
      "Epoch 181/500 Test Loss: 625,104.56\n",
      "Epoch 182/500 Test Loss: 672,137.44\n",
      "Epoch 183/500 Test Loss: 635,356.00\n",
      "Epoch 184/500 Test Loss: 616,388.12\n",
      "Epoch 185/500 Test Loss: 606,183.50\n",
      "Epoch 186/500 Test Loss: 621,654.56\n",
      "Epoch 187/500 Test Loss: 647,578.38\n",
      "Epoch 188/500 Test Loss: 610,485.38\n",
      "Epoch 189/500 Test Loss: 600,071.38\n",
      "Epoch 190/500 Test Loss: 609,082.19\n",
      "Epoch 191/500 Test Loss: 612,387.12\n",
      "Epoch 192/500 Test Loss: 618,629.75\n",
      "Epoch 193/500 Test Loss: 602,010.12\n",
      "Epoch 194/500 Test Loss: 604,843.31\n",
      "Epoch 195/500 Test Loss: 624,393.00\n",
      "Epoch 196/500 Test Loss: 616,041.25\n",
      "Epoch 197/500 Test Loss: 622,073.62\n",
      "Epoch 198/500 Test Loss: 608,067.88\n",
      "Epoch 199/500 Test Loss: 610,842.75\n",
      "Epoch 200/500 Test Loss: 619,120.69\n",
      "Epoch 201/500 Test Loss: 621,401.12\n",
      "Epoch 202/500 Test Loss: 632,806.06\n",
      "Epoch 203/500 Test Loss: 623,657.88\n",
      "Epoch 204/500 Test Loss: 636,950.38\n",
      "Epoch 205/500 Test Loss: 626,343.75\n",
      "Epoch 206/500 Test Loss: 644,542.25\n",
      "Epoch 207/500 Test Loss: 634,873.06\n",
      "Epoch 208/500 Test Loss: 659,319.44\n",
      "Epoch 209/500 Test Loss: 644,327.44\n",
      "Epoch 210/500 Test Loss: 658,695.69\n",
      "Epoch 211/500 Test Loss: 633,768.62\n",
      "Epoch 212/500 Test Loss: 632,506.62\n",
      "Epoch 213/500 Test Loss: 624,593.19\n",
      "Epoch 214/500 Test Loss: 628,213.44\n",
      "Epoch 215/500 Test Loss: 644,899.38\n",
      "Epoch 216/500 Test Loss: 638,913.69\n",
      "Epoch 217/500 Test Loss: 647,892.69\n",
      "Epoch 218/500 Test Loss: 632,304.31\n",
      "Epoch 219/500 Test Loss: 635,436.50\n",
      "Epoch 220/500 Test Loss: 635,331.75\n",
      "Epoch 221/500 Test Loss: 637,486.38\n",
      "Epoch 222/500 Test Loss: 652,638.94\n",
      "Epoch 223/500 Test Loss: 647,650.19\n",
      "Epoch 224/500 Test Loss: 689,070.25\n",
      "Epoch 225/500 Test Loss: 693,596.19\n",
      "Epoch 226/500 Test Loss: 743,822.62\n",
      "Epoch 227/500 Test Loss: 694,228.75\n",
      "Epoch 228/500 Test Loss: 628,488.19\n",
      "Epoch 229/500 Test Loss: 602,846.75\n",
      "Epoch 230/500 Test Loss: 653,495.38\n",
      "Epoch 231/500 Test Loss: 649,958.69\n",
      "Epoch 232/500 Test Loss: 611,276.81\n",
      "Epoch 233/500 Test Loss: 612,462.06\n",
      "Epoch 234/500 Test Loss: 637,498.00\n",
      "Epoch 235/500 Test Loss: 618,641.81\n",
      "Epoch 236/500 Test Loss: 604,851.19\n",
      "Epoch 237/500 Test Loss: 626,879.44\n",
      "Epoch 238/500 Test Loss: 635,641.44\n",
      "Epoch 239/500 Test Loss: 613,064.69\n",
      "Epoch 240/500 Test Loss: 610,270.88\n",
      "Epoch 241/500 Test Loss: 623,337.81\n",
      "Epoch 242/500 Test Loss: 623,938.00\n",
      "Epoch 243/500 Test Loss: 614,921.31\n",
      "Epoch 244/500 Test Loss: 617,108.31\n",
      "Epoch 245/500 Test Loss: 628,783.00\n",
      "Epoch 246/500 Test Loss: 632,585.19\n",
      "Epoch 247/500 Test Loss: 629,120.50\n",
      "Epoch 248/500 Test Loss: 627,488.12\n",
      "Epoch 249/500 Test Loss: 635,316.56\n",
      "Epoch 250/500 Test Loss: 643,349.19\n",
      "Epoch 251/500 Test Loss: 641,677.06\n",
      "Epoch 252/500 Test Loss: 640,850.94\n",
      "Epoch 253/500 Test Loss: 640,531.62\n",
      "Epoch 254/500 Test Loss: 644,065.06\n",
      "Epoch 255/500 Test Loss: 650,412.88\n",
      "Epoch 256/500 Test Loss: 652,313.62\n",
      "Epoch 257/500 Test Loss: 656,275.88\n",
      "Epoch 258/500 Test Loss: 652,138.50\n",
      "Epoch 259/500 Test Loss: 649,715.88\n",
      "Epoch 260/500 Test Loss: 649,682.06\n",
      "Epoch 261/500 Test Loss: 652,780.94\n",
      "Epoch 262/500 Test Loss: 657,602.19\n",
      "Epoch 263/500 Test Loss: 662,059.88\n",
      "Epoch 264/500 Test Loss: 670,610.44\n",
      "Epoch 265/500 Test Loss: 681,665.56\n",
      "Epoch 266/500 Test Loss: 718,859.38\n",
      "Epoch 267/500 Test Loss: 762,503.50\n",
      "Epoch 268/500 Test Loss: 802,690.50\n",
      "Epoch 269/500 Test Loss: 693,544.06\n",
      "Epoch 270/500 Test Loss: 674,283.88\n",
      "Epoch 271/500 Test Loss: 716,947.12\n",
      "Epoch 272/500 Test Loss: 694,697.62\n",
      "Epoch 273/500 Test Loss: 643,082.19\n",
      "Epoch 274/500 Test Loss: 744,099.81\n",
      "Epoch 275/500 Test Loss: 651,802.38\n",
      "Epoch 276/500 Test Loss: 647,590.12\n",
      "Epoch 277/500 Test Loss: 659,053.38\n",
      "Epoch 278/500 Test Loss: 635,075.69\n",
      "Epoch 279/500 Test Loss: 640,463.56\n",
      "Epoch 280/500 Test Loss: 636,007.44\n",
      "Epoch 281/500 Test Loss: 626,024.94\n",
      "Epoch 282/500 Test Loss: 660,501.00\n",
      "Epoch 283/500 Test Loss: 642,916.62\n",
      "Epoch 284/500 Test Loss: 627,077.38\n",
      "Epoch 285/500 Test Loss: 659,898.06\n",
      "Epoch 286/500 Test Loss: 653,216.88\n",
      "Epoch 287/500 Test Loss: 633,140.56\n",
      "Epoch 288/500 Test Loss: 661,345.50\n",
      "Epoch 289/500 Test Loss: 648,873.31\n",
      "Epoch 290/500 Test Loss: 650,934.12\n",
      "Epoch 291/500 Test Loss: 666,342.25\n",
      "Epoch 292/500 Test Loss: 649,187.69\n",
      "Epoch 293/500 Test Loss: 660,399.50\n",
      "Epoch 294/500 Test Loss: 666,682.56\n",
      "Epoch 295/500 Test Loss: 661,216.56\n",
      "Epoch 296/500 Test Loss: 660,194.31\n",
      "Epoch 297/500 Test Loss: 674,856.38\n",
      "Epoch 298/500 Test Loss: 665,461.44\n",
      "Epoch 299/500 Test Loss: 661,759.50\n",
      "Epoch 300/500 Test Loss: 666,138.50\n",
      "Epoch 301/500 Test Loss: 669,771.44\n",
      "Epoch 302/500 Test Loss: 662,739.06\n",
      "Epoch 303/500 Test Loss: 669,906.69\n",
      "Epoch 304/500 Test Loss: 670,477.12\n",
      "Epoch 305/500 Test Loss: 669,782.50\n",
      "Epoch 306/500 Test Loss: 670,078.50\n",
      "Epoch 307/500 Test Loss: 671,526.56\n",
      "Epoch 308/500 Test Loss: 673,275.25\n",
      "Epoch 309/500 Test Loss: 670,397.81\n",
      "Epoch 310/500 Test Loss: 671,906.25\n",
      "Epoch 311/500 Test Loss: 675,494.88\n",
      "Epoch 312/500 Test Loss: 680,272.38\n",
      "Epoch 313/500 Test Loss: 678,972.06\n",
      "Epoch 314/500 Test Loss: 679,052.12\n",
      "Epoch 315/500 Test Loss: 679,775.19\n",
      "Epoch 316/500 Test Loss: 680,494.81\n",
      "Epoch 317/500 Test Loss: 683,532.25\n",
      "Epoch 318/500 Test Loss: 684,799.94\n",
      "Epoch 319/500 Test Loss: 686,920.44\n",
      "Epoch 320/500 Test Loss: 687,205.75\n",
      "Epoch 321/500 Test Loss: 688,236.44\n",
      "Epoch 322/500 Test Loss: 690,670.31\n",
      "Epoch 323/500 Test Loss: 691,519.94\n",
      "Epoch 324/500 Test Loss: 694,338.50\n",
      "Epoch 325/500 Test Loss: 693,947.06\n",
      "Epoch 326/500 Test Loss: 696,257.81\n",
      "Epoch 327/500 Test Loss: 696,634.38\n",
      "Epoch 328/500 Test Loss: 698,678.75\n",
      "Epoch 329/500 Test Loss: 698,345.88\n",
      "Epoch 330/500 Test Loss: 701,970.50\n",
      "Epoch 331/500 Test Loss: 702,823.44\n",
      "Epoch 332/500 Test Loss: 709,477.50\n",
      "Epoch 333/500 Test Loss: 710,857.62\n",
      "Epoch 334/500 Test Loss: 712,586.56\n",
      "Epoch 335/500 Test Loss: 707,859.62\n",
      "Epoch 336/500 Test Loss: 699,199.19\n",
      "Epoch 337/500 Test Loss: 691,372.56\n",
      "Epoch 338/500 Test Loss: 688,667.69\n",
      "Epoch 339/500 Test Loss: 694,294.31\n",
      "Epoch 340/500 Test Loss: 701,494.19\n",
      "Epoch 341/500 Test Loss: 699,530.50\n",
      "Epoch 342/500 Test Loss: 695,500.00\n",
      "Epoch 343/500 Test Loss: 691,949.69\n",
      "Epoch 344/500 Test Loss: 693,757.69\n",
      "Epoch 345/500 Test Loss: 699,067.25\n",
      "Epoch 346/500 Test Loss: 703,142.38\n",
      "Epoch 347/500 Test Loss: 704,939.12\n",
      "Epoch 348/500 Test Loss: 704,087.31\n",
      "Epoch 349/500 Test Loss: 701,857.19\n",
      "Epoch 350/500 Test Loss: 701,356.12\n",
      "Epoch 351/500 Test Loss: 702,861.31\n",
      "Epoch 352/500 Test Loss: 705,451.31\n",
      "Epoch 353/500 Test Loss: 708,956.38\n",
      "Epoch 354/500 Test Loss: 711,418.81\n",
      "Epoch 355/500 Test Loss: 715,671.19\n",
      "Epoch 356/500 Test Loss: 718,238.25\n",
      "Epoch 357/500 Test Loss: 722,184.38\n",
      "Epoch 358/500 Test Loss: 723,423.06\n",
      "Epoch 359/500 Test Loss: 725,726.75\n",
      "Epoch 360/500 Test Loss: 725,421.06\n",
      "Epoch 361/500 Test Loss: 721,955.38\n",
      "Epoch 362/500 Test Loss: 715,518.25\n",
      "Epoch 363/500 Test Loss: 706,434.44\n",
      "Epoch 364/500 Test Loss: 704,294.44\n",
      "Epoch 365/500 Test Loss: 708,865.81\n",
      "Epoch 366/500 Test Loss: 715,195.62\n",
      "Epoch 367/500 Test Loss: 718,517.00\n",
      "Epoch 368/500 Test Loss: 717,847.38\n",
      "Epoch 369/500 Test Loss: 715,328.12\n",
      "Epoch 370/500 Test Loss: 711,225.62\n",
      "Epoch 371/500 Test Loss: 710,114.38\n",
      "Epoch 372/500 Test Loss: 712,098.00\n",
      "Epoch 373/500 Test Loss: 715,999.12\n",
      "Epoch 374/500 Test Loss: 719,717.88\n",
      "Epoch 375/500 Test Loss: 722,784.56\n",
      "Epoch 376/500 Test Loss: 724,169.81\n",
      "Epoch 377/500 Test Loss: 724,267.88\n",
      "Epoch 378/500 Test Loss: 724,173.25\n",
      "Epoch 379/500 Test Loss: 724,417.19\n",
      "Epoch 380/500 Test Loss: 723,548.50\n",
      "Epoch 381/500 Test Loss: 722,984.75\n",
      "Epoch 382/500 Test Loss: 722,249.75\n",
      "Epoch 383/500 Test Loss: 722,575.94\n",
      "Epoch 384/500 Test Loss: 723,657.56\n",
      "Epoch 385/500 Test Loss: 724,836.25\n",
      "Epoch 386/500 Test Loss: 725,772.12\n",
      "Epoch 387/500 Test Loss: 726,934.75\n",
      "Epoch 388/500 Test Loss: 728,453.44\n",
      "Epoch 389/500 Test Loss: 730,550.12\n",
      "Epoch 390/500 Test Loss: 735,182.19\n",
      "Epoch 391/500 Test Loss: 739,190.81\n",
      "Epoch 392/500 Test Loss: 751,101.25\n",
      "Epoch 393/500 Test Loss: 775,098.88\n",
      "Epoch 394/500 Test Loss: 837,919.06\n",
      "Epoch 395/500 Test Loss: 993,744.62\n",
      "Epoch 396/500 Test Loss: 1,048,909.88\n",
      "Epoch 397/500 Test Loss: 821,064.50\n",
      "Epoch 398/500 Test Loss: 754,279.75\n",
      "Epoch 399/500 Test Loss: 851,155.31\n",
      "Epoch 400/500 Test Loss: 692,034.81\n",
      "Epoch 401/500 Test Loss: 764,568.69\n",
      "Epoch 402/500 Test Loss: 773,264.62\n",
      "Epoch 403/500 Test Loss: 650,220.31\n",
      "Epoch 404/500 Test Loss: 748,123.44\n",
      "Epoch 405/500 Test Loss: 632,970.88\n",
      "Epoch 406/500 Test Loss: 704,343.44\n",
      "Epoch 407/500 Test Loss: 646,726.31\n",
      "Epoch 408/500 Test Loss: 679,467.94\n",
      "Epoch 409/500 Test Loss: 640,794.81\n",
      "Epoch 410/500 Test Loss: 654,436.75\n",
      "Epoch 411/500 Test Loss: 685,123.69\n",
      "Epoch 412/500 Test Loss: 639,598.75\n",
      "Epoch 413/500 Test Loss: 649,335.75\n",
      "Epoch 414/500 Test Loss: 647,188.19\n",
      "Epoch 415/500 Test Loss: 681,364.25\n",
      "Epoch 416/500 Test Loss: 654,616.12\n",
      "Epoch 417/500 Test Loss: 664,275.31\n",
      "Epoch 418/500 Test Loss: 680,912.00\n",
      "Epoch 419/500 Test Loss: 686,800.38\n",
      "Epoch 420/500 Test Loss: 680,805.31\n",
      "Epoch 421/500 Test Loss: 669,745.62\n",
      "Epoch 422/500 Test Loss: 681,010.31\n",
      "Epoch 423/500 Test Loss: 677,875.19\n",
      "Epoch 424/500 Test Loss: 689,071.25\n",
      "Epoch 425/500 Test Loss: 694,453.25\n",
      "Epoch 426/500 Test Loss: 690,338.81\n",
      "Epoch 427/500 Test Loss: 690,730.25\n",
      "Epoch 428/500 Test Loss: 695,819.94\n",
      "Epoch 429/500 Test Loss: 692,101.38\n",
      "Epoch 430/500 Test Loss: 693,282.00\n",
      "Epoch 431/500 Test Loss: 696,437.62\n",
      "Epoch 432/500 Test Loss: 702,110.62\n",
      "Epoch 433/500 Test Loss: 698,887.44\n",
      "Epoch 434/500 Test Loss: 700,325.75\n",
      "Epoch 435/500 Test Loss: 704,842.25\n",
      "Epoch 436/500 Test Loss: 706,230.81\n",
      "Epoch 437/500 Test Loss: 705,365.50\n",
      "Epoch 438/500 Test Loss: 707,899.25\n",
      "Epoch 439/500 Test Loss: 709,044.00\n",
      "Epoch 440/500 Test Loss: 714,475.12\n",
      "Epoch 441/500 Test Loss: 716,834.44\n",
      "Epoch 442/500 Test Loss: 715,480.75\n",
      "Epoch 443/500 Test Loss: 714,058.25\n",
      "Epoch 444/500 Test Loss: 714,760.00\n",
      "Epoch 445/500 Test Loss: 713,784.25\n",
      "Epoch 446/500 Test Loss: 715,449.25\n",
      "Epoch 447/500 Test Loss: 720,651.50\n",
      "Epoch 448/500 Test Loss: 724,119.94\n",
      "Epoch 449/500 Test Loss: 724,635.56\n",
      "Epoch 450/500 Test Loss: 725,711.69\n",
      "Epoch 451/500 Test Loss: 725,628.62\n",
      "Epoch 452/500 Test Loss: 727,582.31\n",
      "Epoch 453/500 Test Loss: 730,297.56\n",
      "Epoch 454/500 Test Loss: 732,600.50\n",
      "Epoch 455/500 Test Loss: 734,486.06\n",
      "Epoch 456/500 Test Loss: 735,339.19\n",
      "Epoch 457/500 Test Loss: 734,718.25\n",
      "Epoch 458/500 Test Loss: 734,608.25\n",
      "Epoch 459/500 Test Loss: 734,947.06\n",
      "Epoch 460/500 Test Loss: 735,613.25\n",
      "Epoch 461/500 Test Loss: 737,624.44\n",
      "Epoch 462/500 Test Loss: 739,662.69\n",
      "Epoch 463/500 Test Loss: 741,185.50\n",
      "Epoch 464/500 Test Loss: 741,046.00\n",
      "Epoch 465/500 Test Loss: 740,134.12\n",
      "Epoch 466/500 Test Loss: 741,031.94\n",
      "Epoch 467/500 Test Loss: 743,324.38\n",
      "Epoch 468/500 Test Loss: 745,538.94\n",
      "Epoch 469/500 Test Loss: 747,102.38\n",
      "Epoch 470/500 Test Loss: 746,804.06\n",
      "Epoch 471/500 Test Loss: 745,965.25\n",
      "Epoch 472/500 Test Loss: 746,456.38\n",
      "Epoch 473/500 Test Loss: 748,064.56\n",
      "Epoch 474/500 Test Loss: 750,060.44\n",
      "Epoch 475/500 Test Loss: 751,006.25\n",
      "Epoch 476/500 Test Loss: 751,113.12\n",
      "Epoch 477/500 Test Loss: 751,240.50\n",
      "Epoch 478/500 Test Loss: 751,522.75\n",
      "Epoch 479/500 Test Loss: 752,704.50\n",
      "Epoch 480/500 Test Loss: 754,020.50\n",
      "Epoch 481/500 Test Loss: 754,686.62\n",
      "Epoch 482/500 Test Loss: 754,853.38\n",
      "Epoch 483/500 Test Loss: 754,855.56\n",
      "Epoch 484/500 Test Loss: 755,071.38\n",
      "Epoch 485/500 Test Loss: 755,453.31\n",
      "Epoch 486/500 Test Loss: 756,414.00\n",
      "Epoch 487/500 Test Loss: 757,354.38\n",
      "Epoch 488/500 Test Loss: 757,729.12\n",
      "Epoch 489/500 Test Loss: 757,985.62\n",
      "Epoch 490/500 Test Loss: 758,343.88\n",
      "Epoch 491/500 Test Loss: 758,976.00\n",
      "Epoch 492/500 Test Loss: 759,680.88\n",
      "Epoch 493/500 Test Loss: 760,384.25\n",
      "Epoch 494/500 Test Loss: 760,594.25\n",
      "Epoch 495/500 Test Loss: 760,689.31\n",
      "Epoch 496/500 Test Loss: 761,109.25\n",
      "Epoch 497/500 Test Loss: 761,570.19\n",
      "Epoch 498/500 Test Loss: 762,045.25\n",
      "Epoch 499/500 Test Loss: 762,453.56\n",
      "Epoch 500/500 Test Loss: 762,844.19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_rows': 100, 'test_loss': 762844.1875}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fine_tune_model(model, n_rows, model_name, epochs=100, lr=0.01):\n",
    "    # Regression Model\n",
    "\n",
    "    batch_size = 1000\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model_time = dt.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    model_name = f\"{model_name}_{n_rows}_{model_time}\"\n",
    "\n",
    "    summary_writer = SummaryWriter(\"runs/\" + model_name)\n",
    "    if n_rows is None:\n",
    "        n_rows = X_train_num_tensor.size(0)\n",
    "    if n_rows > X_train_num_tensor.size(0):\n",
    "        raise ValueError(\n",
    "            f\"n_rows ({n_rows}) must be less than or equal to {X_train_num_tensor.size(0)}\"\n",
    "        )\n",
    "\n",
    "    train_set_size = n_rows  # X_train_num_tensor.size(0)\n",
    "    batch_count = 0\n",
    "    model.train()\n",
    "    for epoch in trange(epochs):\n",
    "        for i in range(0, train_set_size, batch_size):\n",
    "            num_inputs = X_train_num_tensor[i : i + batch_size, :]\n",
    "            cat_inputs = X_train_cat_tensor[i : i + batch_size, :]\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(num_inputs, cat_inputs)\n",
    "            loss = loss_fn(y_pred, y_train_tensor[i : i + batch_size, :])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_count += 1\n",
    "            learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "            summary_writer.add_scalar(\n",
    "                \"LossTrain/regression_loss\", loss.item(), batch_count\n",
    "            )\n",
    "            summary_writer.add_scalar(\n",
    "                \"Metrics/regression_lr\", learning_rate, batch_count\n",
    "            )\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test_num_tensor, X_test_cat_tensor)\n",
    "            loss_test = loss_fn(y_pred, y_test_tensor)\n",
    "            summary_writer.add_scalar(\n",
    "                \"LossTest/regression_loss\", loss_test.item(), batch_count\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1}/{epochs} Test Loss: {loss_test.item():,.2f}\")\n",
    "            # print(\n",
    "            #     f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():,.2f} \"\n",
    "            #     + f\"Test loss: {loss_test.item():,.2f}\"\n",
    "            # )\n",
    "    return {\"n_rows\": n_rows, \"test_loss\": loss_test.item()}\n",
    "\n",
    "\n",
    "model = TabTransformer(**tab_transformer_model_config).to(device)\n",
    "model.load_state_dict(torch.load(\"./models/latest_mtm.pt\"))\n",
    "fine_tune_model(model=model, n_rows=100, model_name=\"model\", epochs=100, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Model\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "lr = 0.001\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model_time = dt.now()\n",
    "model_time = model_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = f\"FULL{model_time}\"\n",
    "\n",
    "summary_writer = SummaryWriter(\"runs/\" + model_name)\n",
    "\n",
    "small_test = True\n",
    "train_set_size = X_train_num_tensor.size(0)\n",
    "batch_count = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, train_set_size, batch_size):\n",
    "        num_inputs = X_train_num_tensor[i : i + batch_size, :]\n",
    "        cat_inputs = X_train_cat_tensor[i : i + batch_size, :]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(num_inputs, cat_inputs)\n",
    "        loss = loss_fn(y_pred, y_train_tensor[i : i + batch_size, :])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_count += 1\n",
    "        learning_rate = optimizer.param_groups[0][\"lr\"]\n",
    "        summary_writer.add_scalar(\"LossTrain/regression_loss\", loss.item(), batch_count)\n",
    "        summary_writer.add_scalar(\"Metrics/regression_lr\", learning_rate, batch_count)\n",
    "\n",
    "    # Test set\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_num_tensor, X_test_cat_tensor)\n",
    "        loss_test = loss_fn(y_pred, y_test_tensor)\n",
    "        summary_writer.add_scalar(\"LossTest/regression_loss\", loss.item(), batch_count)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():,.2f} \"\n",
    "            + f\"Test loss: {loss_test.item():,.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 541,435.44\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_num_tensor, X_test_cat_tensor)\n",
    "    loss = loss_fn(y_pred, y_test_tensor)\n",
    "    print(f\"Test loss: {loss.item():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.266401221478674"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(673_383.84 - loss.item()) / (673_383.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1,471.62 Actual: 1,754.00 Diff: -282.38\n",
      "Predicted: 6,565.45 Actual: 6,927.00 Diff: -361.55\n",
      "Predicted: 955.20 Actual: 1,264.00 Diff: -308.80\n",
      "Predicted: 2,384.49 Actual: 2,278.00 Diff: 106.49\n",
      "Predicted: 3,408.32 Actual: 2,858.00 Diff: 550.32\n",
      "Predicted: 2,491.25 Actual: 8,133.00 Diff: -5,641.75\n",
      "Predicted: 759.22 Actual: 840.00 Diff: -80.78\n",
      "Predicted: 16,254.14 Actual: 16,792.00 Diff: -537.86\n",
      "Predicted: 779.46 Actual: 815.00 Diff: -35.54\n",
      "Predicted: 816.92 Actual: 734.00 Diff: 82.92\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\n",
    "        f\"Predicted: {y_pred[i].item():,.2f} Actual: {y_test_tensor[i].item():,.2f}\",\n",
    "        f\"Diff: {y_pred[i].item() - y_test_tensor[i].item():,.2f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39m1\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Loss: 31,439,220.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_12919/1167013342.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cat[col] = le.fit_transform(X_train_cat.loc[:, col])\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_12919/1167013342.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_cat[col] = le.transform(X_test_cat.loc[:, col])\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_12919/1167013342.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cat[col] = le.fit_transform(X_train_cat.loc[:, col])\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_12919/1167013342.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_cat[col] = le.transform(X_test_cat.loc[:, col])\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_12919/1167013342.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_cat[col] = le.fit_transform(X_train_cat.loc[:, col])\n",
      "/var/folders/rs/qflxwtyx6kvfj8jcqx5zm5hr0000gn/T/ipykernel_12919/1167013342.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_cat[col] = le.transform(X_test_cat.loc[:, col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/2000, Loss: 669,738.62\n",
      "Epoch 401/2000, Loss: 439,377.12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 107\u001b[0m\n\u001b[1;32m    102\u001b[0m outputs \u001b[39m=\u001b[39m simple_model(\n\u001b[1;32m    103\u001b[0m     X_train_num_tensor,  \u001b[39m# [0:batch_size],\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     X_train_cat_tensor,  \u001b[39m# [0:batch_size],\u001b[39;00m\n\u001b[1;32m    105\u001b[0m )  \u001b[39m# Pass numeric and categorical tensors separately\u001b[39;00m\n\u001b[1;32m    106\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, y_train_tensor)\n\u001b[0;32m--> 107\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    108\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m200\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load and preprocess the dataset (assuming you have a CSV file)\n",
    "data = pd.read_csv(\"../data/diamonds.csv\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(\"price\", axis=1)\n",
    "y = data[\"price\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess categorical features\n",
    "cat_columns = [\"cut\", \"color\", \"clarity\"]\n",
    "X_train_cat = X_train[cat_columns]\n",
    "X_test_cat = X_test[cat_columns]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_cat[col] = le.fit_transform(X_train_cat.loc[:, col])\n",
    "    X_test_cat[col] = le.transform(X_test_cat.loc[:, col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Preprocess numeric features\n",
    "num_columns = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[num_columns])\n",
    "X_test_num = scaler.transform(X_test[num_columns])\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat.values, dtype=torch.int64)\n",
    "X_train_num_tensor = torch.tensor(X_train_num, dtype=torch.float32)\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat.values, dtype=torch.int64)\n",
    "X_test_num_tensor = torch.tensor(X_test_num, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "# Define the neural network model\n",
    "class DiamondPricePredictor(nn.Module):\n",
    "    def __init__(self, num_input_dim, cat_embedding_sizes, hidden_dim):\n",
    "        super(DiamondPricePredictor, self).__init__()\n",
    "\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [\n",
    "                nn.Embedding(num_classes, emb_size)\n",
    "                for num_classes, emb_size in cat_embedding_sizes\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        total_emb_dim = sum(emb_size for _, emb_size in cat_embedding_sizes)\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(num_input_dim + total_emb_dim, hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "        # self.fc1 = nn.Linear(num_input_dim + total_emb_dim, hidden_dim)\n",
    "        # self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, num_inputs, cat_inputs):\n",
    "        embeddings = [\n",
    "            embedding(cat_inputs[:, i]) for i, embedding in enumerate(self.embeddings)\n",
    "        ]\n",
    "        cat_features = torch.cat(embeddings, dim=1)\n",
    "        x = torch.cat([num_inputs, cat_features], dim=1)\n",
    "\n",
    "        x = self.predictor(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "num_input_dim = X_train_num.shape[1]\n",
    "cat_embedding_sizes = [\n",
    "    (len(le.classes_), min(50, (len(le.classes_) + 1) // 2))\n",
    "    for le in label_encoders.values()\n",
    "]\n",
    "hidden_dim = 64\n",
    "simple_model = DiamondPricePredictor(num_input_dim, cat_embedding_sizes, hidden_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(simple_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = simple_model(\n",
    "        X_train_num_tensor,  # [0:batch_size],\n",
    "        X_train_cat_tensor,  # [0:batch_size],\n",
    "    )  # Pass numeric and categorical tensors separately\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():,.2f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Data: 30,910,758.00\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_num_tensor, X_test_cat_tensor)\n",
    "    mse = mean_squared_error(y_test_tensor, test_predictions)\n",
    "    print(f\"Mean Squared Error on Test Data: {mse:,.2f}\")  # 735,349.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Params in Tabular Model:261,809 Number of Params in Simple Model:45,900\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Number of Params in Tabular Model:{count_parameters(model):,}\",\n",
    "    f\"Number of Params in Simple Model:{count_parameters(simple_model):,}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 673,383.84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the diamonds dataset\n",
    "diamonds_data = pd.read_csv(\"../data/diamonds.csv\")\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "label_encoders = {}\n",
    "categorical_features = [\"cut\", \"color\", \"clarity\"]\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    diamonds_data[feature] = le.fit_transform(diamonds_data[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = diamonds_data.drop(\"price\", axis=1)\n",
    "y = diamonds_data[\"price\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train the XGBoost regressor\n",
    "xgb_regressor = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_regressor.fit(\n",
    "    X_train[0:batch_size],\n",
    "    y_train[0:batch_size],\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:,.2f}\")\n",
    "\n",
    "# You can also access feature importance scores\n",
    "# feature_importances = xgb_regressor.feature_importances_\n",
    "# print(\"Feature Importance:\")\n",
    "# for feature, importance in zip(X.columns, feature_importances):\n",
    "#     print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_tester(train_set_size):\n",
    "    xgb_regressor = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    xgb_regressor.fit(\n",
    "        X_train[0:train_set_size],\n",
    "        y_train[0:train_set_size],\n",
    "    )\n",
    "\n",
    "    y_pred = xgb_regressor.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "\n",
    "mses = {}\n",
    "for i in range(1000, 44000, 1000):\n",
    "    mse = xgb_tester(i)\n",
    "    mses[i] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the dictionary\n",
    "\n",
    "# Extract the x and y values from the dictionary\n",
    "x = list(mses.keys())\n",
    "y = list(mses.values())\n",
    "\n",
    "# Create a line plot\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE vs. Number of Samples\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: 673383.8424745769,\n",
       " 2000: 488658.2629755395,\n",
       " 3000: 422387.5912084758,\n",
       " 4000: 400050.20091023814,\n",
       " 5000: 382692.46425053675,\n",
       " 6000: 361696.7359423982,\n",
       " 7000: 347060.8782991371,\n",
       " 8000: 335927.7780321159,\n",
       " 9000: 347646.5456652291,\n",
       " 10000: 342515.203624628,\n",
       " 11000: 340405.0255080609,\n",
       " 12000: 321155.15150586085,\n",
       " 13000: 321786.4186075241,\n",
       " 14000: 313044.210626029,\n",
       " 15000: 317607.4170493895,\n",
       " 16000: 311893.83646389376,\n",
       " 17000: 308288.66516828345,\n",
       " 18000: 311645.89919669274,\n",
       " 19000: 310051.99311877246,\n",
       " 20000: 305460.9976913605,\n",
       " 21000: 298675.61869602784,\n",
       " 22000: 297213.8142488428,\n",
       " 23000: 297484.2940444159,\n",
       " 24000: 296799.75403719075,\n",
       " 25000: 292727.36708097695,\n",
       " 26000: 293802.83884854906,\n",
       " 27000: 294219.3616975973,\n",
       " 28000: 298747.65880516416,\n",
       " 29000: 289433.0572588045,\n",
       " 30000: 294304.356059232,\n",
       " 31000: 290512.14676491043,\n",
       " 32000: 292071.330825601,\n",
       " 33000: 287885.04899814393,\n",
       " 34000: 287511.3364757178,\n",
       " 35000: 286662.58478553843,\n",
       " 36000: 286205.7910110461,\n",
       " 37000: 286931.27869797597,\n",
       " 38000: 284858.488959447,\n",
       " 39000: 287277.45748249197,\n",
       " 40000: 282404.30501941923,\n",
       " 41000: 278983.8855670251,\n",
       " 42000: 283920.87883220165,\n",
       " 43000: 280097.0041370276}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43152, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "lcc_arn": "arn:aws:sagemaker:us-west-2:385115691352:studio-lifecycle-config/base-installs-widgets",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
