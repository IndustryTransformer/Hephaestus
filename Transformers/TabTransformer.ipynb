{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm4wrZzyQYDl"
   },
   "source": [
    "# Industrial Transformers\n",
    "\n",
    "## Libraries\n",
    "\n",
    "Based off of [Vanilla Transformers](https://colab.research.google.com/drive/1VAsHQLrCSNb4V_c-mCFdIYfQBXXIQYz0#scrollTo=_QWiUFmzTkXL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 17 15:19:03 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   32C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1675008075047,
     "user": {
      "displayName": "Kai Lukowiak",
      "userId": "12340107642472090190"
     },
     "user_tz": 420
    },
    "id": "pw58b4kNQHfd",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Tuple, Union\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from numbers import Number\n",
    "import re\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "import optax\n",
    "from jax import lax\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "\n",
    "# from flax import optim\n",
    "from flax import jax_utils\n",
    "from flax.training import train_state, checkpoints, common_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "- Drop all completely empty columns.\n",
    "- Make local_* variables strings.\n",
    "- Scale numeric variables.\n",
    "- Drop id and date variables.\n",
    "- Separate strings using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635664, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 25)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>station_name</th><th>climate_identifier</th><th>province_code</th><th>local_year</th><th>local_month</th><th>local_day</th><th>local_hour</th><th>temp</th><th>temp_flag</th><th>dew_point_temp</th><th>dew_point_temp_flag</th><th>humidex</th><th>precip_amount</th><th>precip_amount_flag</th><th>relative_humidity</th><th>relative_humidity_flag</th><th>station_pressure</th><th>station_pressure_flag</th><th>wind_chill</th><th>wind_direction</th><th>wind_direction_flag</th><th>wind_speed</th><th>wind_speed_flag</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>-111.213333</td><td>56.651111</td><td>&quot;FORT MCMURRAY …</td><td>&quot;3062696&quot;</td><td>&quot;AB&quot;</td><td>&quot;2019&quot;</td><td>&quot;8&quot;</td><td>&quot;23&quot;</td><td>&quot;0&quot;</td><td>7.9</td><td>&quot;missing&quot;</td><td>5.4</td><td>&quot;missing&quot;</td><td>null</td><td>0.0</td><td>&quot;missing&quot;</td><td>84.0</td><td>&quot;missing&quot;</td><td>96.98</td><td>&quot;missing&quot;</td><td>null</td><td>20.0</td><td>&quot;missing&quot;</td><td>11.0</td><td>&quot;missing&quot;</td></tr><tr><td>-112.7675</td><td>49.695</td><td>&quot;LETHBRIDGE CDA…</td><td>&quot;3033890&quot;</td><td>&quot;AB&quot;</td><td>&quot;2010&quot;</td><td>&quot;11&quot;</td><td>&quot;3&quot;</td><td>&quot;16&quot;</td><td>14.2</td><td>&quot;missing&quot;</td><td>-8.0</td><td>&quot;missing&quot;</td><td>null</td><td>null</td><td>&quot;missing&quot;</td><td>21.0</td><td>&quot;missing&quot;</td><td>92.64</td><td>&quot;missing&quot;</td><td>null</td><td>15.0</td><td>&quot;missing&quot;</td><td>7.0</td><td>&quot;missing&quot;</td></tr><tr><td>-112.7675</td><td>49.695</td><td>&quot;LETHBRIDGE CDA…</td><td>&quot;3033890&quot;</td><td>&quot;AB&quot;</td><td>&quot;2013&quot;</td><td>&quot;12&quot;</td><td>&quot;9&quot;</td><td>&quot;23&quot;</td><td>-6.5</td><td>&quot;missing&quot;</td><td>-12.3</td><td>&quot;missing&quot;</td><td>null</td><td>null</td><td>&quot;missing&quot;</td><td>63.0</td><td>&quot;missing&quot;</td><td>90.56</td><td>&quot;missing&quot;</td><td>-15.0</td><td>27.0</td><td>&quot;missing&quot;</td><td>33.0</td><td>&quot;missing&quot;</td></tr><tr><td>-111.213333</td><td>56.651111</td><td>&quot;FORT MCMURRAY …</td><td>&quot;3062696&quot;</td><td>&quot;AB&quot;</td><td>&quot;2013&quot;</td><td>&quot;9&quot;</td><td>&quot;25&quot;</td><td>&quot;3&quot;</td><td>2.6</td><td>&quot;missing&quot;</td><td>0.2</td><td>&quot;missing&quot;</td><td>null</td><td>null</td><td>&quot;missing&quot;</td><td>84.0</td><td>&quot;missing&quot;</td><td>96.64</td><td>&quot;missing&quot;</td><td>null</td><td>24.0</td><td>&quot;missing&quot;</td><td>11.0</td><td>&quot;missing&quot;</td></tr><tr><td>-114.6825</td><td>51.778056</td><td>&quot;SUNDRE A&quot;</td><td>&quot;3026KNQ&quot;</td><td>&quot;AB&quot;</td><td>&quot;2020&quot;</td><td>&quot;4&quot;</td><td>&quot;21&quot;</td><td>&quot;5&quot;</td><td>-1.4</td><td>&quot;missing&quot;</td><td>-4.4</td><td>&quot;missing&quot;</td><td>null</td><td>0.0</td><td>&quot;missing&quot;</td><td>80.0</td><td>&quot;missing&quot;</td><td>88.23</td><td>&quot;missing&quot;</td><td>-4.0</td><td>23.0</td><td>&quot;missing&quot;</td><td>6.0</td><td>&quot;missing&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 25)\n",
       "┌─────────┬────────┬────────────┬────────────┬───┬────────────┬────────────┬──────────┬────────────┐\n",
       "│ x       ┆ y      ┆ station_na ┆ climate_id ┆ … ┆ wind_direc ┆ wind_direc ┆ wind_spe ┆ wind_speed │\n",
       "│ ---     ┆ ---    ┆ me         ┆ entifier   ┆   ┆ tion       ┆ tion_flag  ┆ ed       ┆ _flag      │\n",
       "│ f64     ┆ f64    ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---      ┆ ---        │\n",
       "│         ┆        ┆ str        ┆ str        ┆   ┆ f64        ┆ str        ┆ f64      ┆ str        │\n",
       "╞═════════╪════════╪════════════╪════════════╪═══╪════════════╪════════════╪══════════╪════════════╡\n",
       "│ -111.21 ┆ 56.651 ┆ FORT       ┆ 3062696    ┆ … ┆ 20.0       ┆ missing    ┆ 11.0     ┆ missing    │\n",
       "│ 3333    ┆ 111    ┆ MCMURRAY   ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│         ┆        ┆ CS         ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -112.76 ┆ 49.695 ┆ LETHBRIDGE ┆ 3033890    ┆ … ┆ 15.0       ┆ missing    ┆ 7.0      ┆ missing    │\n",
       "│ 75      ┆        ┆ CDA        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -112.76 ┆ 49.695 ┆ LETHBRIDGE ┆ 3033890    ┆ … ┆ 27.0       ┆ missing    ┆ 33.0     ┆ missing    │\n",
       "│ 75      ┆        ┆ CDA        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -111.21 ┆ 56.651 ┆ FORT       ┆ 3062696    ┆ … ┆ 24.0       ┆ missing    ┆ 11.0     ┆ missing    │\n",
       "│ 3333    ┆ 111    ┆ MCMURRAY   ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│         ┆        ┆ CS         ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -114.68 ┆ 51.778 ┆ SUNDRE A   ┆ 3026KNQ    ┆ … ┆ 23.0       ┆ missing    ┆ 6.0      ┆ missing    │\n",
       "│ 25      ┆ 056    ┆            ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "└─────────┴────────┴────────────┴────────────┴───┴────────────┴────────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pl.read_parquet(\"../data/weather_clean.parquet\")\n",
    "print(weather.shape)\n",
    "weather.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111743, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>local_year</th><th>local_month</th><th>local_day</th><th>local_hour</th><th>total_energy_no_imports</th><th>total_imports</th><th>total_exports</th><th>actual_pool_price</th><th>actual_ail</th><th>day_ahead_pool_price</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2014&quot;</td><td>&quot;9&quot;</td><td>&quot;27&quot;</td><td>&quot;17&quot;</td><td>6671.968413</td><td>275.0</td><td>0.0</td><td>47.48</td><td>8835</td><td>44.37</td></tr><tr><td>&quot;2014&quot;</td><td>&quot;7&quot;</td><td>&quot;19&quot;</td><td>&quot;6&quot;</td><td>6112.240516</td><td>0.0</td><td>0.0</td><td>12.44</td><td>8097</td><td>13.92</td></tr><tr><td>&quot;2014&quot;</td><td>&quot;4&quot;</td><td>&quot;25&quot;</td><td>&quot;8&quot;</td><td>6912.162844</td><td>350.0</td><td>0.0</td><td>55.3</td><td>8987</td><td>52.99</td></tr><tr><td>&quot;2015&quot;</td><td>&quot;11&quot;</td><td>&quot;13&quot;</td><td>&quot;21&quot;</td><td>7441.938827</td><td>0.0</td><td>104.0</td><td>17.53</td><td>9477</td><td>17.13</td></tr><tr><td>&quot;2014&quot;</td><td>&quot;2&quot;</td><td>&quot;10&quot;</td><td>&quot;13&quot;</td><td>7645.64203</td><td>650.0</td><td>0.0</td><td>90.48</td><td>10449</td><td>91.16</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌──────────┬───────────┬──────────┬──────────┬───┬────────────┬────────────┬──────────┬────────────┐\n",
       "│ local_ye ┆ local_mon ┆ local_da ┆ local_ho ┆ … ┆ total_expo ┆ actual_poo ┆ actual_a ┆ day_ahead_ │\n",
       "│ ar       ┆ th        ┆ y        ┆ ur       ┆   ┆ rts        ┆ l_price    ┆ il       ┆ pool_price │\n",
       "│ ---      ┆ ---       ┆ ---      ┆ ---      ┆   ┆ ---        ┆ ---        ┆ ---      ┆ ---        │\n",
       "│ str      ┆ str       ┆ str      ┆ str      ┆   ┆ f64        ┆ f64        ┆ i64      ┆ f64        │\n",
       "╞══════════╪═══════════╪══════════╪══════════╪═══╪════════════╪════════════╪══════════╪════════════╡\n",
       "│ 2014     ┆ 9         ┆ 27       ┆ 17       ┆ … ┆ 0.0        ┆ 47.48      ┆ 8835     ┆ 44.37      │\n",
       "│ 2014     ┆ 7         ┆ 19       ┆ 6        ┆ … ┆ 0.0        ┆ 12.44      ┆ 8097     ┆ 13.92      │\n",
       "│ 2014     ┆ 4         ┆ 25       ┆ 8        ┆ … ┆ 0.0        ┆ 55.3       ┆ 8987     ┆ 52.99      │\n",
       "│ 2015     ┆ 11        ┆ 13       ┆ 21       ┆ … ┆ 104.0      ┆ 17.53      ┆ 9477     ┆ 17.13      │\n",
       "│ 2014     ┆ 2         ┆ 10       ┆ 13       ┆ … ┆ 0.0        ┆ 90.48      ┆ 10449    ┆ 91.16      │\n",
       "└──────────┴───────────┴──────────┴──────────┴───┴────────────┴────────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy = pl.read_parquet(\"../data/energy_clean.parquet\")\n",
    "print(energy.shape)\n",
    "energy.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale numeric variables and remove spaces from strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_numeric(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == pl.Float64 or df[col].dtype == pl.Int64:\n",
    "            df = df.with_columns(\n",
    "                ((pl.col(col) - pl.col(col).mean()) / pl.col(col).std()).alias(col)\n",
    "            )  # .select(pl.col([\"dew_point_temp\", \"NewCOL\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "weather = scale_numeric(weather)\n",
    "energy = scale_numeric(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_lower_remove_special_chars(df):\n",
    "    df = df.with_columns(\n",
    "        pl.col(pl.Utf8).str.to_lowercase().str.replace_all(\"[^a-zA-Z0-9]\", \" \")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "weather = make_lower_remove_special_chars(weather)\n",
    "energy = make_lower_remove_special_chars(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
       "       '19', '2', '20', '2010', '2011', '2012', '2013', '2014', '2015',\n",
       "       '2016', '2017', '2018', '2019', '2020', '2021', '2022', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '4',\n",
       "       '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_utf8_values(df):\n",
    "    arr = np.array([])\n",
    "    for col in df.select(pl.col(pl.Utf8)).columns:\n",
    "        arr = np.append(arr, df[col].unique().to_numpy())\n",
    "\n",
    "    return np.unique(arr)\n",
    "\n",
    "\n",
    "weather_val_tokens = get_unique_utf8_values(weather)\n",
    "energy_val_tokens = get_unique_utf8_values(energy)\n",
    "energy_val_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actual', 'ahead', 'ail', 'day', 'energy', 'exports', 'hour',\n",
       "       'imports', 'local', 'month', 'no', 'pool', 'price', 'total',\n",
       "       'year'], dtype='<U7')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_col_tokens(df):\n",
    "    tokens = []\n",
    "    for col_name in df.columns:\n",
    "        sub_strs = re.split(r\"[^a-zA-Z0-9]\", col_name)\n",
    "        tokens.extend(sub_strs)\n",
    "    return np.unique(np.array(tokens))\n",
    "\n",
    "\n",
    "weather_col_tokens = get_col_tokens(weather)\n",
    "energy_col_tokens = get_col_tokens(energy)\n",
    "energy_col_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', '0', '1', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '2', '20', '2010', '2011', '2012', '2013', '2014',\n",
       "       '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
       "       '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30',\n",
       "       '3012206', '3026knq', '3031094', '3033890', '3035208', '3062696',\n",
       "       '31', '4', '5', '6', '7', '8', '9', ':', '<batch-end>',\n",
       "       '<batch-start>', '<pad>', '<row-end>', '<row-start>', '<unk>',\n",
       "       'ab', 'actual', 'ahead', 'ail', 'amount', 'calgary int l cs',\n",
       "       'chill', 'climate', 'code', 'day', 'dew', 'direction',\n",
       "       'edmonton international cs', 'energy', 'exports', 'flag',\n",
       "       'fort mcmurray cs', 'hour', 'humidex', 'humidity', 'identifier',\n",
       "       'imports', 'lethbridge cda', 'local', 'm', 'missing', 'month',\n",
       "       'name', 'no', 'pincher creek climate', 'point', 'pool', 'precip',\n",
       "       'pressure', 'price', 'province', 'relative', 'speed', 'station',\n",
       "       'sundre a', 'temp', 'total', 'wind', 'x', 'y', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = np.array(\n",
    "    [\n",
    "        \"missing\",\n",
    "        \"<batch-start>\",\n",
    "        \"<batch-end>\",\n",
    "        \"<pad>\",\n",
    "        \"<unk>\",\n",
    "        \":\",\n",
    "        \",\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")\n",
    "tokens = np.unique(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            weather_val_tokens,\n",
    "            energy_val_tokens,\n",
    "            weather_col_tokens,\n",
    "            energy_col_tokens,\n",
    "            special_tokens,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringNumeric(value='climate', is_numeric=False, embedding_idx=None)\n",
      "StringNumeric(value=1.0, is_numeric=True, embedding_idx=0)\n",
      "StringNumeric(value='SomeRandomString', is_numeric=False, embedding_idx=None)\n",
      "StringNumeric(value='climate', is_numeric=False, embedding_idx=67)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class StringNumeric:\n",
    "    value: Union[str, float]\n",
    "    # all_tokens: np.array\n",
    "    is_numeric: bool = field(default=None, repr=True)\n",
    "    embedding_idx: int = field(default=None, repr=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if isinstance(self.value, str):\n",
    "            self.is_numeric = False\n",
    "        else:\n",
    "            self.is_numeric = True\n",
    "            self.embedding_idx = 0\n",
    "\n",
    "    def gen_embed_idx(self, tokens: np.array):\n",
    "        if not self.is_numeric:\n",
    "            try:\n",
    "                self.embedding_idx = np.where(tokens == self.value)[0][0] + 1\n",
    "            except IndexError:\n",
    "                self.embedding_idx = np.where(tokens == \"<unk>\")[0][0] + 1\n",
    "\n",
    "\n",
    "x = StringNumeric(value=\"climate\")\n",
    "# xx = StringNumeric(value=\"climate\", tokens=tokens)\n",
    "print(x)\n",
    "y = StringNumeric(value=1.0)\n",
    "print(y)\n",
    "z = StringNumeric(value=\"SomeRandomString\")\n",
    "print(z)\n",
    "x.gen_embed_idx(tokens)\n",
    "print(x)\n",
    "# print(StringNumeric(value=1.0, all_tokens=tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', '0', '1', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '2', '20', '2010', '2011', '2012', '2013', '2014',\n",
       "       '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
       "       '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30',\n",
       "       '3012206', '3026knq', '3031094', '3033890', '3035208', '3062696',\n",
       "       '31', '4', '5', '6', '7', '8', '9', ':', '<batch-end>',\n",
       "       '<batch-start>', '<pad>', '<row-end>', '<row-start>', '<unk>',\n",
       "       'ab', 'actual', 'ahead', 'ail', 'amount', 'calgary int l cs',\n",
       "       'chill', 'climate', 'code', 'day', 'dew', 'direction',\n",
       "       'edmonton international cs', 'energy', 'exports', 'flag',\n",
       "       'fort mcmurray cs', 'hour', 'humidex', 'humidity', 'identifier',\n",
       "       'imports', 'lethbridge cda', 'local', 'm', 'missing', 'month',\n",
       "       'name', 'no', 'pincher creek climate', 'point', 'pool', 'precip',\n",
       "       'pressure', 'price', 'province', 'relative', 'speed', 'station',\n",
       "       'sundre a', 'temp', 'total', 'wind', 'x', 'y', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QNBVZG85Qgoh",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringNumeric(value='<batch-start>', is_numeric=False, embedding_idx=55), StringNumeric(value='<row-start>', is_numeric=False, embedding_idx=58), StringNumeric(value='x', is_numeric=False, embedding_idx=103), StringNumeric(value=':', is_numeric=False, embedding_idx=53), StringNumeric(value=-0.551099305737714, is_numeric=True, embedding_idx=0), StringNumeric(value=',', is_numeric=False, embedding_idx=1), StringNumeric(value='y', is_numeric=False, embedding_idx=104), StringNumeric(value=':', is_numeric=False, embedding_idx=53), StringNumeric(value=-0.37817406811183396, is_numeric=True, embedding_idx=0), StringNumeric(value=',', is_numeric=False, embedding_idx=1)]\n"
     ]
    }
   ],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    # def __init__(self, df: pl.DataFrame, vocab_dict: Dict, m_dim: int) -> Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        vocab,\n",
    "        shuffle_cols=False,\n",
    "        n_rows=None,\n",
    "        max_seq_length=512,\n",
    "    ) -> Dataset:\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.shuffle_cols = shuffle_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.max_seq_length = max_seq_length\n",
    "        # self.vocab_dict = vocab_dict\n",
    "        # self.embedding = nn.Embedding(len(self.string_vocab), m_dim)\n",
    "        # Numeric Scale\n",
    "\n",
    "        # self.col_vocab = self.df.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of sequences in the dataset.\"\"\"\n",
    "        length = self.df.shape[0] // self.n_rows\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a tuple of (input, target) at the given index.\"\"\"\n",
    "        batch = self.batch(idx)\n",
    "        start = StringNumeric(\"<batch-start>\")\n",
    "        start.gen_embed_idx(self.vocab)\n",
    "        end = StringNumeric(\"<batch-end>\")\n",
    "        end.gen_embed_idx(self.vocab)\n",
    "        batch = self.padder(batch)\n",
    "        batch = [start] + batch + [end]\n",
    "        return batch\n",
    "\n",
    "    def batch(self, idx):\n",
    "        \"\"\"Returns a batch from splitter from the starting index to the start\n",
    "        index + n_rows\"\"\"\n",
    "        batch = []\n",
    "        for i in range(idx, idx + self.n_rows):\n",
    "            row = self.df[i]\n",
    "            row = self.splitter(row)\n",
    "            batch.extend(row)\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def padder(self, batch: List[StringNumeric]):\n",
    "        diff = self.max_seq_length - len(batch)  # -2 for start and end\n",
    "        if diff > 0:\n",
    "            pad = StringNumeric(\"<pad>\")\n",
    "            pad.gen_embed_idx(self.vocab)\n",
    "            batch.extend([pad] * diff)\n",
    "        elif diff < 0:\n",
    "            batch = batch[: self.max_seq_length - 1]\n",
    "            # add warning\n",
    "            new_end = StringNumeric(\"<batch-end>\")\n",
    "            new_end.gen_embed_idx(self.vocab)\n",
    "            batch.append(new_end)\n",
    "            print(\"Batch too long, truncating\")\n",
    "            Warning(\"Batch too long, truncating\")\n",
    "        return batch\n",
    "\n",
    "    def splitter(self, row: pl.DataFrame) -> List[Union[str, float, None]]:\n",
    "        vals = [\"<row-start>\"]\n",
    "        cols = row.columns\n",
    "        if self.shuffle_cols:\n",
    "            np.random.shuffle(cols)\n",
    "\n",
    "        for col in cols:\n",
    "            value = row[col][0]\n",
    "            col = col.split(\"_\")\n",
    "            vals.extend(col)\n",
    "            vals.append(\":\")\n",
    "            if isinstance(value, Number):\n",
    "                vals.append(value)\n",
    "            elif value is None:\n",
    "                vals.append(\"missing\")\n",
    "                # Nones are only for numeric columns, others are \"None\"\n",
    "            elif isinstance(value, str):\n",
    "                vals.extend(value.split(\" \"))\n",
    "            else:\n",
    "                raise ValueError(\"Unknown type\")\n",
    "            vals.append(\",\")\n",
    "        vals.append(\"<row-end>\")\n",
    "\n",
    "        vals = [StringNumeric(value=val) for val in vals]\n",
    "        for val in vals:\n",
    "            val.gen_embed_idx(self.vocab)\n",
    "\n",
    "        return vals\n",
    "\n",
    "\n",
    "weather_ds = TabularDataset(weather, tokens, shuffle_cols=False, n_rows=2)\n",
    "energy_ds = TabularDataset(energy, tokens, shuffle_cols=False, n_rows=2)\n",
    "print(weather_ds[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    embed_dim: int = 256\n",
    "    n_heads: int = 8\n",
    "    kvq_dim: int = embed_dim // n_heads\n",
    "    ff_dim: int = 512\n",
    "    p_drop: float = 0.2\n",
    "    encoder_vocab_size: int = weather_ds.vocab.shape[0]\n",
    "    decoder_vocab_size: int = energy_ds.vocab.shape[0]\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jnp.arange(10) * jnp.arange(10).T#[:, None]\n",
    "# jnp.einsum(\"i,j->ij\", jnp.arange(10), jnp.arange(10))\n",
    "jnp.arange(10)[jnp.newaxis, :].ndim  # [:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Adds positional encoding to the input.\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.array) -> jnp.array:\n",
    "        assert x.ndim == 3, \"Input must have rank 3\"\n",
    "        config = self.config\n",
    "\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        pe = jnp.zeros(batch_size, seq_len, config.embed_dim)\n",
    "\n",
    "        position = jnp.arrange(seq_len)[jnp.newaxis, :]\n",
    "        div_term = jnp.exp(\n",
    "            jnp.arange(0, config.embed_dim, 2) * (-jnp.log(10000.0) / config.embed_dim)\n",
    "        )\n",
    "        radians = jnp.einsum(\n",
    "            \"ij,kl->jl\", position, div_term\n",
    "        )  # just a matrix multiplication\n",
    "        pe = pe.at[:, :, 0::2].set(jnp.sin(radians))\n",
    "        pe = pe.at[:, :, 1::2].set(jnp.cos(radians))\n",
    "        return (x + pe).astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi Headed Dot Product Attention\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        q: jnp.array,\n",
    "        k: jnp.array,\n",
    "        v: jnp.array,\n",
    "        mask: jnp.array = None,\n",
    "        dropout: float = 0.0,\n",
    "    ) -> jnp.array:\n",
    "        config = self.config\n",
    "\n",
    "        assert q.ndim == k.ndim == v.ndim == 3, \"Input must have rank 3\"\n",
    "        assert q.shape[0] == k.shape[0] == v.shape[0], \"Batch size must be equal\"\n",
    "        assert (\n",
    "            q.shape[2] == k.shape[2] == v.shape[2]\n",
    "        ), \"Embedding dimension must be equal\"\n",
    "\n",
    "        batch_size, seq_len, embed_dim = q.shape\n",
    "        assert (\n",
    "            embed_dim % config.num_heads == 0\n",
    "        ), \"Embedding dimension must be divisible by number of heads\"\n",
    "\n",
    "        q = nn.Dense(config.embed_dim, name=\"DenseQ\")(q)\n",
    "        k = nn.Dense(config.embed_dim, name=\"DenseK\")(k)\n",
    "        v = nn.Dense(config.embed_dim, name=\"DenseV\")(v)\n",
    "\n",
    "        q = q.reshape(-1, seq_len, config.n_heads, config.kvq_dim)\n",
    "        k = k.reshape(-1, seq_len, config.n_heads, config.kvq_dim)\n",
    "        v = v.reshape(-1, seq_len, config.n_heads, config.kvq_dim)\n",
    "\n",
    "        attention = jnp.einsum(\"...qhd,...khd->...hqk\", q, k) / jnp.sqrt(config.kvq_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            attention = jnp.where(mask, attention, -jnp.inf)\n",
    "\n",
    "        attention = nn.softmax(attention, axis=-1)\n",
    "        values = jnp.einsum(\"...hqk,...khd->...qhd\", attention, v)\n",
    "        values = values.reshape(-1, seq_len, embed_dim)\n",
    "        out = nn.Dense(embed_dim)(values)\n",
    "\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Feed Forward Neural Network\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.array, deterministic: bool) -> jnp.array:\n",
    "        config = self.config\n",
    "        x = nn.Dense(config.ff_dim * 4, name=\"FFDense1\")(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.Dense(config.ff_dim, name=\"FFDense2\")(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"Transformer Encoder Layer\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.array, mask: jnp.array, deterministic: bool) -> jnp.array:\n",
    "        config = self.config\n",
    "        res = x\n",
    "        x, attention = MultiHeadAttention(config)(x, x, x, mask)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm1\")(x + res)\n",
    "        res = x\n",
    "        x = FeedForward(config, name=\"FeedForward\")(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm2\")(x + res)\n",
    "\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer Decoder Layer\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.array,\n",
    "        memory: jnp.array,\n",
    "        decoder_mask: jnp.array,\n",
    "        encoder_decoder_mask: jnp.array,\n",
    "        deterministic: bool,\n",
    "    ) -> Tuple[jnp.array, jnp.array, jnp.array]:\n",
    "        config = self.config\n",
    "        res = x\n",
    "        x, attention = MultiHeadAttention(config)(x, x, x, decoder_mask)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm1\")(x + res)\n",
    "        res = x\n",
    "        x, attention = MultiHeadAttention(config)(\n",
    "            x, memory, memory, encoder_decoder_mask\n",
    "        )\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm2\")(x + res)\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.1656743 ,  0.0334887 ,  0.7145505 , -0.69273764, -0.7260953 ],\n",
       "       [-0.12573542, -0.35354394,  0.10587429,  0.05312492,  0.4437487 ],\n",
       "       [-0.04921824, -0.10327773, -0.13198015, -0.4364049 , -0.38484678],\n",
       "       [ 0.31554   ,  0.09454814,  0.4258944 , -0.27779824,  0.07495691],\n",
       "       [ 0.71339667, -0.04502202, -0.35073858,  0.59638804,  0.05645175],\n",
       "       [        nan,         nan,         nan,         nan,         nan]],      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.array([1, 1, 3, 3, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "emb = nn.Embed(num_embeddings=10, features=5)\n",
    "emb_variables = emb.init(random.PRNGKey(0), x)\n",
    "emb_output = emb.apply(emb_variables, x)\n",
    "emb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.1656743 ,  0.0334887 ,  0.7145505 , -0.69273764, -0.7260953 ],\n",
       "       [-0.12573542, -0.35354394,  0.10587429,  0.05312492,  0.4437487 ],\n",
       "       [-0.04921824, -0.10327773, -0.13198015, -0.4364049 , -0.38484678],\n",
       "       [ 0.31554   ,  0.09454814,  0.4258944 , -0.27779824,  0.07495691],\n",
       "       [ 0.71339667, -0.04502202, -0.35073858,  0.59638804,  0.05645175],\n",
       "       [        nan,         nan,         nan,         nan,         nan]],      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[  0   1 100   3   4   5   6   7   8   9]\n"
     ]
    }
   ],
   "source": [
    "y = jnp.arange(10)\n",
    "print(y)\n",
    "y = y.at[2].set(100)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FloatEmbedding(nn.Module):\n",
    "    # config: Config\n",
    "    \"\"\"Embedding lookup for token ids.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: list[StringNumeric]) -> jnp.array:\n",
    "        config = Config()\n",
    "        embed = nn.Embed(\n",
    "            config.vocab_size,\n",
    "            config.embed_dim,\n",
    "            embedding_init=jax.nn.initializers.normal(stddev=config.embed_dim**-0.5),\n",
    "            name=\"FloatEmbedding\",\n",
    "        )\n",
    "        embeddings = jnp.zeros((len(x), config.embed_dim))\n",
    "        # return embeddings\n",
    "        for i, sn in enumerate(x):\n",
    "            if sn.is_numeric:\n",
    "                arr = jnp.zeros(config.embed_dim)\n",
    "                arr = arr.at[0].set(sn.value)\n",
    "                embeddings = embeddings.at[i].set(arr)\n",
    "            else:\n",
    "                embeddings = embeddings.at[i].set(embed(sn.embedding_idx))\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer Encoder\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.array,\n",
    "        mask: jnp.array,\n",
    "        deterministic: bool,\n",
    "        return_attention: bool = False,\n",
    "    ) -> Union[jnp.array, Tuple[jnp.array, List[jnp.array]]]:\n",
    "        config = self.config\n",
    "        x = FloatEmbedding(config)(x)\n",
    "        x = PositionalEncoding(config)(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        attention_list = []\n",
    "        for i in range(config.n_layers):\n",
    "            x, attention = TransformerEncoderLayer(config, name=f\"EncoderLayer_{i}\")(\n",
    "                x, mask, deterministic\n",
    "            )\n",
    "            attention_list.append(attention)\n",
    "\n",
    "        x = nn.LayerNorm(name=\"LayerNorm\")(x)\n",
    "        if return_attention:\n",
    "            return x, attention_list\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer Decoder\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.array,\n",
    "        memory: jnp.array,\n",
    "        decoder_mask: jnp.array,\n",
    "        encoder_decoder_mask: jnp.array,\n",
    "        deterministic: bool,\n",
    "        return_attention: bool = False,\n",
    "    ) -> Union[jnp.array, Tuple[jnp.array, List[jnp.array]]]:\n",
    "        config = self.config\n",
    "        x = FloatEmbedding(config)(x)\n",
    "        x = PositionalEncoding(config)(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        self_attention_list, src_attention_list = [], []\n",
    "        for i in range(config.n_layers):\n",
    "            x, self_attention, src_attention = TransformerDecoderLayer(\n",
    "                config, name=f\"DecoderLayer_{i}\"\n",
    "            )(\n",
    "                x,\n",
    "                memory,\n",
    "                decoder_mask,\n",
    "                encoder_decoder_mask,\n",
    "                deterministic,\n",
    "            )\n",
    "            self_attention_list.append(self_attention)\n",
    "            src_attention_list.append(src_attention)\n",
    "\n",
    "        x = nn.LayerNorm(name=\"LayerNorm\")(x)\n",
    "        x = nn.Dense(config.vocab_size, name=\"Dense\")(x)\n",
    "        if return_attention:\n",
    "            return x, self_attention_list, src_attention_list\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer\"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.Encoder = TransformerEncoder(self.config)\n",
    "        self.Decoder = TransformerDecoder(self.config)\n",
    "\n",
    "        def encode(self, src: TabularDataset, train: bool = True) -> jnp.array:\n",
    "            config = self.config\n",
    "\n",
    "            encoder_mask = nn.make_attention_mask(jnp.ones_like(src), src, dtype=\"bool\")\n",
    "\n",
    "        def __call__(\n",
    "            self, src: jnp.array, tgt: jnp.array, train: bool = False\n",
    "        ) -> jnp.array:\n",
    "            config = self.config\n",
    "\n",
    "            memory = self.encode(src, train=train)\n",
    "            logits = self.decode(trg, src, memory, train=train)\n",
    "\n",
    "        def encode(\n",
    "            self, src: njp.array, train: bool = False, return_attn: bool = False\n",
    "        ) -> Union[jnp.array, Tuple[jnp.array, List[jnp.array]]]:\n",
    "            encoder_mask = nn.make_attention_mask(\n",
    "                jnp.ones_like(src), src != config.pad_idx, dtype=bool\n",
    "            )\n",
    "\n",
    "            if return_attn:\n",
    "                memory, encoder_attention_list = self.Encoder(\n",
    "                    src, encoder_mask, not train, return_attn=return_attn\n",
    "                )\n",
    "                return memory, encoder_attention_list\n",
    "            else:\n",
    "                memory = self.Encoder(\n",
    "                    src, encoder_mask, not train, return_attn=return_attn\n",
    "                )\n",
    "                return memory\n",
    "\n",
    "        def decode(\n",
    "            self,\n",
    "            trg: jnp.array,\n",
    "            src: jnp.array,  # only for making mask\n",
    "            memory: jnp.array,\n",
    "            train: bool = False,\n",
    "            return_attn: bool = False,\n",
    "        ) -> Union[jnp.array, Tuple[jnp.array, List[jnp.array], List[jnp.array]]]:\n",
    "            \"\"\"Decode targets with Transformer Decoder.\n",
    "\n",
    "            Args:\n",
    "              trg: targets of shape [batch_size, trg_length].\n",
    "              src: sources of shape [batch_size, src_length].\n",
    "              memory: encoded sources from Transformer Encoder of shape [batch_size, src_length, features].\n",
    "              train: To train, it should be set True, otherwise False.\n",
    "              return_attn: if true, returns Self-Attention and Source-Target-Attention matrixes.\n",
    "\n",
    "            Returns:\n",
    "              If return_attn is True,\n",
    "                the logits of shape [batch_size, trg_length, target_vocab_size],\n",
    "                list of attention matrix in Self-Attention for the number of layers,\n",
    "                and list of attention matrix in Source-Target-Attention for the number of layers.\n",
    "              else,\n",
    "                the logits.\n",
    "            \"\"\"\n",
    "\n",
    "            assert trg.ndim == 2\n",
    "            config = self.config\n",
    "\n",
    "            decoder_mask = nn.combine_masks(\n",
    "                nn.make_attention_mask(\n",
    "                    jnp.ones_like(trg), trg != config.pad_idx, dtype=bool\n",
    "                ),\n",
    "                nn.make_causal_mask(trg, dtype=bool),\n",
    "            )  # [Batch, 1, SeqLen_q, SeqLen_k]\n",
    "            encoder_decoder_mask = nn.make_attention_mask(\n",
    "                jnp.ones_like(trg), src != config.pad_idx, dtype=bool\n",
    "            )  # [Batch, 1, SeqLen_q, SeqLen_k]\n",
    "\n",
    "            if return_attn:\n",
    "                logits, decoder_attention_list, src_trg_attention_list = self.Decoder(\n",
    "                    memory,\n",
    "                    trg,\n",
    "                    decoder_mask,\n",
    "                    encoder_decoder_mask,\n",
    "                    not train,\n",
    "                    return_attn=return_attn,\n",
    "                )\n",
    "                return logits, decoder_attention_list, src_trg_attention_list\n",
    "            else:\n",
    "                logits = self.Decoder(\n",
    "                    memory,\n",
    "                    trg,\n",
    "                    decoder_mask,\n",
    "                    encoder_decoder_mask,\n",
    "                    not train,\n",
    "                    return_attn=return_attn,\n",
    "                )\n",
    "                return logits"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "authorship_tag": "ABX9TyO80HV+1vvnHCe4/KXEdo9l",
   "provenance": []
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "46ccecb0382603292763ecbdda78a1f11d4c009df5d14d09120607e175cb3ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
