{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mm4wrZzyQYDl"
   },
   "source": [
    "# Industrial Transformers\n",
    "\n",
    "## Libraries\n",
    "\n",
    "Based off of [Vanilla Transformers](https://colab.research.google.com/drive/1VAsHQLrCSNb4V_c-mCFdIYfQBXXIQYz0#scrollTo=_QWiUFmzTkXL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 22 21:29:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8    N/A /  N/A |      6MiB /  4040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3264      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1675008075047,
     "user": {
      "displayName": "Kai Lukowiak",
      "userId": "12340107642472090190"
     },
     "user_tz": 420
    },
    "id": "pw58b4kNQHfd"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from numbers import Number\n",
    "import re\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "import optax\n",
    "from jax import lax\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "\n",
    "# from flax import optim\n",
    "from flax import jax_utils\n",
    "from flax.training import train_state, checkpoints, common_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "- Drop all completely empty columns.\n",
    "- Make local_* variables strings.\n",
    "- Scale numeric variables.\n",
    "- Drop id and date variables.\n",
    "- Separate strings using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635664, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 25)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>station_name</th><th>climate_identifier</th><th>province_code</th><th>local_year</th><th>local_month</th><th>local_day</th><th>local_hour</th><th>temp</th><th>temp_flag</th><th>dew_point_temp</th><th>dew_point_temp_flag</th><th>humidex</th><th>precip_amount</th><th>precip_amount_flag</th><th>relative_humidity</th><th>relative_humidity_flag</th><th>station_pressure</th><th>station_pressure_flag</th><th>wind_chill</th><th>wind_direction</th><th>wind_direction_flag</th><th>wind_speed</th><th>wind_speed_flag</th></tr><tr><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>-111.213333</td><td>56.651111</td><td>&quot;FORT MCMURRAY …</td><td>&quot;3062696&quot;</td><td>&quot;AB&quot;</td><td>&quot;2013&quot;</td><td>&quot;5&quot;</td><td>&quot;18&quot;</td><td>&quot;12&quot;</td><td>22.6</td><td>&quot;missing&quot;</td><td>-1.9</td><td>&quot;missing&quot;</td><td>null</td><td>null</td><td>&quot;missing&quot;</td><td>19.0</td><td>&quot;missing&quot;</td><td>96.88</td><td>&quot;missing&quot;</td><td>null</td><td>9.0</td><td>&quot;missing&quot;</td><td>13.0</td><td>&quot;missing&quot;</td></tr><tr><td>-114.004722</td><td>49.521667</td><td>&quot;PINCHER CREEK …</td><td>&quot;3035208&quot;</td><td>&quot;AB&quot;</td><td>&quot;2016&quot;</td><td>&quot;2&quot;</td><td>&quot;16&quot;</td><td>&quot;9&quot;</td><td>6.1</td><td>&quot;missing&quot;</td><td>-2.7</td><td>&quot;missing&quot;</td><td>null</td><td>0.0</td><td>&quot;missing&quot;</td><td>53.0</td><td>&quot;missing&quot;</td><td>87.17</td><td>&quot;missing&quot;</td><td>null</td><td>25.0</td><td>&quot;missing&quot;</td><td>52.0</td><td>&quot;missing&quot;</td></tr><tr><td>-112.7675</td><td>49.695</td><td>&quot;LETHBRIDGE CDA…</td><td>&quot;3033890&quot;</td><td>&quot;AB&quot;</td><td>&quot;2016&quot;</td><td>&quot;5&quot;</td><td>&quot;25&quot;</td><td>&quot;3&quot;</td><td>4.4</td><td>&quot;missing&quot;</td><td>3.9</td><td>&quot;missing&quot;</td><td>null</td><td>0.0</td><td>&quot;missing&quot;</td><td>96.0</td><td>&quot;missing&quot;</td><td>90.66</td><td>&quot;missing&quot;</td><td>null</td><td>19.0</td><td>&quot;missing&quot;</td><td>8.0</td><td>&quot;missing&quot;</td></tr><tr><td>-111.213333</td><td>56.651111</td><td>&quot;FORT MCMURRAY …</td><td>&quot;3062696&quot;</td><td>&quot;AB&quot;</td><td>&quot;2016&quot;</td><td>&quot;7&quot;</td><td>&quot;30&quot;</td><td>&quot;15&quot;</td><td>22.0</td><td>&quot;missing&quot;</td><td>12.4</td><td>&quot;missing&quot;</td><td>null</td><td>0.0</td><td>&quot;missing&quot;</td><td>54.0</td><td>&quot;missing&quot;</td><td>96.07</td><td>&quot;missing&quot;</td><td>null</td><td>4.0</td><td>&quot;missing&quot;</td><td>19.0</td><td>&quot;missing&quot;</td></tr><tr><td>-113.605836</td><td>53.306667</td><td>&quot;EDMONTON INTER…</td><td>&quot;3012206&quot;</td><td>&quot;AB&quot;</td><td>&quot;2011&quot;</td><td>&quot;7&quot;</td><td>&quot;20&quot;</td><td>&quot;22&quot;</td><td>8.8</td><td>&quot;missing&quot;</td><td>8.8</td><td>&quot;missing&quot;</td><td>null</td><td>null</td><td>&quot;missing&quot;</td><td>100.0</td><td>&quot;missing&quot;</td><td>null</td><td>&quot;M&quot;</td><td>null</td><td>null</td><td>&quot;M&quot;</td><td>null</td><td>&quot;M&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 25)\n",
       "┌─────────┬────────┬────────────┬────────────┬───┬────────────┬────────────┬──────────┬────────────┐\n",
       "│ x       ┆ y      ┆ station_na ┆ climate_id ┆ … ┆ wind_direc ┆ wind_direc ┆ wind_spe ┆ wind_speed │\n",
       "│ ---     ┆ ---    ┆ me         ┆ entifier   ┆   ┆ tion       ┆ tion_flag  ┆ ed       ┆ _flag      │\n",
       "│ f64     ┆ f64    ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---      ┆ ---        │\n",
       "│         ┆        ┆ str        ┆ str        ┆   ┆ f64        ┆ str        ┆ f64      ┆ str        │\n",
       "╞═════════╪════════╪════════════╪════════════╪═══╪════════════╪════════════╪══════════╪════════════╡\n",
       "│ -111.21 ┆ 56.651 ┆ FORT       ┆ 3062696    ┆ … ┆ 9.0        ┆ missing    ┆ 13.0     ┆ missing    │\n",
       "│ 3333    ┆ 111    ┆ MCMURRAY   ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│         ┆        ┆ CS         ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -114.00 ┆ 49.521 ┆ PINCHER    ┆ 3035208    ┆ … ┆ 25.0       ┆ missing    ┆ 52.0     ┆ missing    │\n",
       "│ 4722    ┆ 667    ┆ CREEK      ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│         ┆        ┆ CLIMATE    ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -112.76 ┆ 49.695 ┆ LETHBRIDGE ┆ 3033890    ┆ … ┆ 19.0       ┆ missing    ┆ 8.0      ┆ missing    │\n",
       "│ 75      ┆        ┆ CDA        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -111.21 ┆ 56.651 ┆ FORT       ┆ 3062696    ┆ … ┆ 4.0        ┆ missing    ┆ 19.0     ┆ missing    │\n",
       "│ 3333    ┆ 111    ┆ MCMURRAY   ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│         ┆        ┆ CS         ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ -113.60 ┆ 53.306 ┆ EDMONTON   ┆ 3012206    ┆ … ┆ null       ┆ M          ┆ null     ┆ M          │\n",
       "│ 5836    ┆ 667    ┆ INTERNATIO ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│         ┆        ┆ NAL CS     ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "└─────────┴────────┴────────────┴────────────┴───┴────────────┴────────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pl.read_parquet(\"../data/weather_clean.parquet\")\n",
    "print(weather.shape)\n",
    "weather.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111743, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>local_year</th><th>local_month</th><th>local_day</th><th>local_hour</th><th>total_energy_no_imports</th><th>total_imports</th><th>total_exports</th><th>actual_pool_price</th><th>actual_ail</th><th>day_ahead_pool_price</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2012&quot;</td><td>&quot;12&quot;</td><td>&quot;6&quot;</td><td>&quot;22&quot;</td><td>7090.006864</td><td>250.0</td><td>0.0</td><td>38.16</td><td>9545</td><td>36.91</td></tr><tr><td>&quot;2011&quot;</td><td>&quot;2&quot;</td><td>&quot;9&quot;</td><td>&quot;4&quot;</td><td>6435.332551</td><td>245.0</td><td>100.0</td><td>21.33</td><td>8356</td><td>23.54</td></tr><tr><td>&quot;2017&quot;</td><td>&quot;10&quot;</td><td>&quot;15&quot;</td><td>&quot;17&quot;</td><td>7361.620082</td><td>0.0</td><td>150.0</td><td>18.29</td><td>9250</td><td>18.29</td></tr><tr><td>&quot;2022&quot;</td><td>&quot;3&quot;</td><td>&quot;18&quot;</td><td>&quot;23&quot;</td><td>6595.433734</td><td>300.0</td><td>0.0</td><td>43.71</td><td>9528</td><td>41.88</td></tr><tr><td>&quot;2013&quot;</td><td>&quot;10&quot;</td><td>&quot;9&quot;</td><td>&quot;10&quot;</td><td>7204.043731</td><td>45.0</td><td>0.0</td><td>857.29</td><td>8897</td><td>889.35</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌──────────┬───────────┬──────────┬──────────┬───┬────────────┬────────────┬──────────┬────────────┐\n",
       "│ local_ye ┆ local_mon ┆ local_da ┆ local_ho ┆ … ┆ total_expo ┆ actual_poo ┆ actual_a ┆ day_ahead_ │\n",
       "│ ar       ┆ th        ┆ y        ┆ ur       ┆   ┆ rts        ┆ l_price    ┆ il       ┆ pool_price │\n",
       "│ ---      ┆ ---       ┆ ---      ┆ ---      ┆   ┆ ---        ┆ ---        ┆ ---      ┆ ---        │\n",
       "│ str      ┆ str       ┆ str      ┆ str      ┆   ┆ f64        ┆ f64        ┆ i64      ┆ f64        │\n",
       "╞══════════╪═══════════╪══════════╪══════════╪═══╪════════════╪════════════╪══════════╪════════════╡\n",
       "│ 2012     ┆ 12        ┆ 6        ┆ 22       ┆ … ┆ 0.0        ┆ 38.16      ┆ 9545     ┆ 36.91      │\n",
       "│ 2011     ┆ 2         ┆ 9        ┆ 4        ┆ … ┆ 100.0      ┆ 21.33      ┆ 8356     ┆ 23.54      │\n",
       "│ 2017     ┆ 10        ┆ 15       ┆ 17       ┆ … ┆ 150.0      ┆ 18.29      ┆ 9250     ┆ 18.29      │\n",
       "│ 2022     ┆ 3         ┆ 18       ┆ 23       ┆ … ┆ 0.0        ┆ 43.71      ┆ 9528     ┆ 41.88      │\n",
       "│ 2013     ┆ 10        ┆ 9        ┆ 10       ┆ … ┆ 0.0        ┆ 857.29     ┆ 8897     ┆ 889.35     │\n",
       "└──────────┴───────────┴──────────┴──────────┴───┴────────────┴────────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy = pl.read_parquet(\"../data/energy_clean.parquet\")\n",
    "print(energy.shape)\n",
    "energy.sample(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale numeric variables and remove spaces from strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numeric(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == pl.Float64 or df[col].dtype == pl.Int64:\n",
    "            df = df.with_columns(\n",
    "                ((pl.col(col) - pl.col(col).mean()) / pl.col(col).std()).alias(col)\n",
    "            )  # .select(pl.col([\"dew_point_temp\", \"NewCOL\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "weather = scale_numeric(weather)\n",
    "energy = scale_numeric(energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower_remove_special_chars(df):\n",
    "    df = df.with_columns(\n",
    "        pl.col(pl.Utf8).str.to_lowercase().str.replace_all(\"[^a-zA-Z0-9]\", \" \")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "weather = make_lower_remove_special_chars(weather)\n",
    "energy = make_lower_remove_special_chars(energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
       "       '19', '2', '20', '2010', '2011', '2012', '2013', '2014', '2015',\n",
       "       '2016', '2017', '2018', '2019', '2020', '2021', '2022', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '4',\n",
       "       '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_utf8_values(df):\n",
    "    arr = np.array([])\n",
    "    for col in df.select(pl.col(pl.Utf8)).columns:\n",
    "        arr = np.append(arr, df[col].unique().to_numpy())\n",
    "\n",
    "    return np.unique(arr)\n",
    "\n",
    "\n",
    "weather_val_tokens = get_unique_utf8_values(weather)\n",
    "energy_val_tokens = get_unique_utf8_values(energy)\n",
    "energy_val_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actual', 'ahead', 'ail', 'day', 'energy', 'exports', 'hour',\n",
       "       'imports', 'local', 'month', 'no', 'pool', 'price', 'total',\n",
       "       'year'], dtype='<U7')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_col_tokens(df):\n",
    "    tokens = []\n",
    "    for col_name in df.columns:\n",
    "        sub_strs = re.split(r\"[^a-zA-Z0-9]\", col_name)\n",
    "        tokens.extend(sub_strs)\n",
    "    return np.unique(np.array(tokens))\n",
    "\n",
    "\n",
    "weather_col_tokens = get_col_tokens(weather)\n",
    "energy_col_tokens = get_col_tokens(energy)\n",
    "energy_col_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', '0', '1', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '2', '20', '2010', '2011', '2012', '2013', '2014',\n",
       "       '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
       "       '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30',\n",
       "       '3012206', '3026knq', '3031094', '3033890', '3035208', '3062696',\n",
       "       '31', '4', '5', '6', '7', '8', '9', ':', '<batch-end>',\n",
       "       '<batch-start>', '<pad>', '<row-end>', '<row-start>', '<unk>',\n",
       "       'ab', 'actual', 'ahead', 'ail', 'amount', 'calgary int l cs',\n",
       "       'chill', 'climate', 'code', 'day', 'dew', 'direction',\n",
       "       'edmonton international cs', 'energy', 'exports', 'flag',\n",
       "       'fort mcmurray cs', 'hour', 'humidex', 'humidity', 'identifier',\n",
       "       'imports', 'lethbridge cda', 'local', 'm', 'missing', 'month',\n",
       "       'name', 'no', 'pincher creek climate', 'point', 'pool', 'precip',\n",
       "       'pressure', 'price', 'province', 'relative', 'speed', 'station',\n",
       "       'sundre a', 'temp', 'total', 'wind', 'x', 'y', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = np.array(\n",
    "    [\n",
    "        \"missing\",\n",
    "        \"<batch-start>\",\n",
    "        \"<batch-end>\",\n",
    "        \"<pad>\",\n",
    "        \"<unk>\",\n",
    "        \":\",\n",
    "        \",\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")\n",
    "tokens = np.unique(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            weather_val_tokens,\n",
    "            energy_val_tokens,\n",
    "            weather_col_tokens,\n",
    "            energy_col_tokens,\n",
    "            special_tokens,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringNumeric(value='climate', is_numeric=False, embedding_idx=None)\n",
      "StringNumeric(value=1.0, is_numeric=True, embedding_idx=0)\n",
      "StringNumeric(value='SomeRandomString', is_numeric=False, embedding_idx=None)\n",
      "StringNumeric(value='climate', is_numeric=False, embedding_idx=67)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class StringNumeric:\n",
    "    value: Union[str, float]\n",
    "    # all_tokens: np.array\n",
    "    is_numeric: bool = field(default=None, repr=True)\n",
    "    embedding_idx: int = field(default=None, repr=True)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if isinstance(self.value, str):\n",
    "            self.is_numeric = False\n",
    "        else:\n",
    "            self.is_numeric = True\n",
    "            self.embedding_idx = 0\n",
    "\n",
    "    def gen_embed_idx(self, tokens: np.array):\n",
    "        if not self.is_numeric:\n",
    "            try:\n",
    "                self.embedding_idx = np.where(tokens == self.value)[0][0] + 1\n",
    "            except IndexError:\n",
    "                self.embedding_idx = np.where(tokens == \"<unk>\")[0][0] + 1\n",
    "\n",
    "\n",
    "x = StringNumeric(value=\"climate\")\n",
    "# xx = StringNumeric(value=\"climate\", tokens=tokens)\n",
    "print(x)\n",
    "y = StringNumeric(value=1.0)\n",
    "print(y)\n",
    "z = StringNumeric(value=\"SomeRandomString\")\n",
    "print(z)\n",
    "x.gen_embed_idx(tokens)\n",
    "print(x)\n",
    "# print(StringNumeric(value=1.0, all_tokens=tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', '0', '1', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '2', '20', '2010', '2011', '2012', '2013', '2014',\n",
       "       '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
       "       '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30',\n",
       "       '3012206', '3026knq', '3031094', '3033890', '3035208', '3062696',\n",
       "       '31', '4', '5', '6', '7', '8', '9', ':', '<batch-end>',\n",
       "       '<batch-start>', '<pad>', '<row-end>', '<row-start>', '<unk>',\n",
       "       'ab', 'actual', 'ahead', 'ail', 'amount', 'calgary int l cs',\n",
       "       'chill', 'climate', 'code', 'day', 'dew', 'direction',\n",
       "       'edmonton international cs', 'energy', 'exports', 'flag',\n",
       "       'fort mcmurray cs', 'hour', 'humidex', 'humidity', 'identifier',\n",
       "       'imports', 'lethbridge cda', 'local', 'm', 'missing', 'month',\n",
       "       'name', 'no', 'pincher creek climate', 'point', 'pool', 'precip',\n",
       "       'pressure', 'price', 'province', 'relative', 'speed', 'station',\n",
       "       'sundre a', 'temp', 'total', 'wind', 'x', 'y', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QNBVZG85Qgoh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringNumeric(value='<batch-start>', is_numeric=False, embedding_idx=55), StringNumeric(value='<row-start>', is_numeric=False, embedding_idx=58), StringNumeric(value='x', is_numeric=False, embedding_idx=103), StringNumeric(value=':', is_numeric=False, embedding_idx=53), StringNumeric(value=-0.551099305737714, is_numeric=True, embedding_idx=0), StringNumeric(value=',', is_numeric=False, embedding_idx=1), StringNumeric(value='y', is_numeric=False, embedding_idx=104), StringNumeric(value=':', is_numeric=False, embedding_idx=53), StringNumeric(value=-0.37817406811183396, is_numeric=True, embedding_idx=0), StringNumeric(value=',', is_numeric=False, embedding_idx=1)]\n"
     ]
    }
   ],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    # def __init__(self, df: pl.DataFrame, vocab_dict: Dict, m_dim: int) -> Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        vocab,\n",
    "        shuffle_cols=False,\n",
    "        n_rows=None,\n",
    "        max_seq_length=512,\n",
    "    ) -> Dataset:\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.shuffle_cols = shuffle_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.max_seq_length = max_seq_length\n",
    "        # self.vocab_dict = vocab_dict\n",
    "        # self.embedding = nn.Embedding(len(self.string_vocab), m_dim)\n",
    "        # Numeric Scale\n",
    "\n",
    "        # self.col_vocab = self.df.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of sequences in the dataset.\"\"\"\n",
    "        length = self.df.shape[0] // self.n_rows\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a tuple of (input, target) at the given index.\"\"\"\n",
    "        batch = self.batch(idx)\n",
    "        start = StringNumeric(\"<batch-start>\")\n",
    "        start.gen_embed_idx(self.vocab)\n",
    "        end = StringNumeric(\"<batch-end>\")\n",
    "        end.gen_embed_idx(self.vocab)\n",
    "        batch = self.padder(batch)\n",
    "        batch = [start] + batch + [end]\n",
    "        return batch\n",
    "\n",
    "    def batch(self, idx):\n",
    "        \"\"\"Returns a batch from splitter from the starting index to the start\n",
    "        index + n_rows\"\"\"\n",
    "        batch = []\n",
    "        for i in range(idx, idx + self.n_rows):\n",
    "            row = self.df[i]\n",
    "            row = self.splitter(row)\n",
    "            batch.extend(row)\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def padder(self, batch: List[StringNumeric]):\n",
    "        diff = self.max_seq_length - len(batch)  # -2 for start and end\n",
    "        if diff > 0:\n",
    "            pad = StringNumeric(\"<pad>\")\n",
    "            pad.gen_embed_idx(self.vocab)\n",
    "            batch.extend([pad] * diff)\n",
    "        elif diff < 0:\n",
    "            batch = batch[: self.max_seq_length - 1]\n",
    "            # add warning\n",
    "            new_end = StringNumeric(\"<batch-end>\")\n",
    "            new_end.gen_embed_idx(self.vocab)\n",
    "            batch.append(new_end)\n",
    "            print(\"Batch too long, truncating\")\n",
    "            Warning(\"Batch too long, truncating\")\n",
    "        return batch\n",
    "\n",
    "    def splitter(self, row: pl.DataFrame) -> List[Union[str, float, None]]:\n",
    "        vals = [\"<row-start>\"]\n",
    "        cols = row.columns\n",
    "        if self.shuffle_cols:\n",
    "            np.random.shuffle(cols)\n",
    "\n",
    "        for col in cols:\n",
    "            value = row[col][0]\n",
    "            col = col.split(\"_\")\n",
    "            vals.extend(col)\n",
    "            vals.append(\":\")\n",
    "            if isinstance(value, Number):\n",
    "                vals.append(value)\n",
    "            elif value is None:\n",
    "                vals.append(\"missing\")\n",
    "                # Nones are only for numeric columns, others are \"None\"\n",
    "            elif isinstance(value, str):\n",
    "                vals.extend(value.split(\" \"))\n",
    "            else:\n",
    "                raise ValueError(\"Unknown type\")\n",
    "            vals.append(\",\")\n",
    "        vals.append(\"<row-end>\")\n",
    "\n",
    "        vals = [StringNumeric(value=val) for val in vals]\n",
    "        for val in vals:\n",
    "            val.gen_embed_idx(self.vocab)\n",
    "\n",
    "        return vals\n",
    "\n",
    "\n",
    "weather_ds = TabularDataset(weather, tokens, shuffle_cols=False, n_rows=2)\n",
    "energy_ds = TabularDataset(energy, tokens, shuffle_cols=False, n_rows=2)\n",
    "print(weather_ds[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    embed_dim: int = 256\n",
    "    n_heads: int = 8\n",
    "    kvq_dim: int = embed_dim // n_heads\n",
    "    ff_dim: int = 512\n",
    "    p_drop: float = 0.2\n",
    "    encoder_vocab_size: int = weather_ds.vocab.shape[0]\n",
    "    decoder_vocab_size: int = energy_ds.vocab.shape[0]\n",
    "\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jnp.arange(10) * jnp.arange(10).T#[:, None]\n",
    "# jnp.einsum(\"i,j->ij\", jnp.arange(10), jnp.arange(10))\n",
    "jnp.arange(10)[jnp.newaxis, :].ndim  # [:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Adds positional encoding to the input.\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.array) -> jnp.array:\n",
    "        assert x.ndim == 3, \"Input must have rank 3\"\n",
    "        config = self.config\n",
    "\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        pe = jnp.zeros(batch_size, seq_len, config.embed_dim)\n",
    "\n",
    "        position = jnp.arrange(seq_len)[jnp.newaxis, :]\n",
    "        div_term = jnp.exp(\n",
    "            jnp.arange(0, config.embed_dim, 2) * (-jnp.log(10000.0) / config.embed_dim)\n",
    "        )\n",
    "        radians = jnp.einsum(\n",
    "            \"ij,kl->jl\", position, div_term\n",
    "        )  # just a matrix multiplication\n",
    "        pe = pe.at[:, :, 0::2].set(jnp.sin(radians))\n",
    "        pe = pe.at[:, :, 1::2].set(jnp.cos(radians))\n",
    "        return (x + pe).astype(jnp.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi Headed Dot Product Attention\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        q: jnp.array,\n",
    "        k: jnp.array,\n",
    "        v: jnp.array,\n",
    "        mask: jnp.array = None,\n",
    "        dropout: float = 0.0,\n",
    "    ) -> jnp.array:\n",
    "        config = self.config\n",
    "\n",
    "        assert q.ndim == k.ndim == v.ndim == 3, \"Input must have rank 3\"\n",
    "        assert q.shape[0] == k.shape[0] == v.shape[0], \"Batch size must be equal\"\n",
    "        assert (\n",
    "            q.shape[2] == k.shape[2] == v.shape[2]\n",
    "        ), \"Embedding dimension must be equal\"\n",
    "\n",
    "        batch_size, seq_len, embed_dim = q.shape\n",
    "        assert (\n",
    "            embed_dim % config.num_heads == 0\n",
    "        ), \"Embedding dimension must be divisible by number of heads\"\n",
    "\n",
    "        q = nn.Dense(config.embed_dim, name=\"DenseQ\")(q)\n",
    "        k = nn.Dense(config.embed_dim, name=\"DenseK\")(k)\n",
    "        v = nn.Dense(config.embed_dim, name=\"DenseV\")(v)\n",
    "\n",
    "        q = q.reshape(-1, seq_len, config.n_heads, config.kvq_dim)\n",
    "        k = k.reshape(-1, seq_len, config.n_heads, config.kvq_dim)\n",
    "        v = v.reshape(-1, seq_len, config.n_heads, config.kvq_dim)\n",
    "\n",
    "        attention = jnp.einsum(\"...qhd,...khd->...hqk\", q, k) / jnp.sqrt(config.kvq_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            attention = jnp.where(mask, attention, -jnp.inf)\n",
    "\n",
    "        attention = nn.softmax(attention, axis=-1)\n",
    "        values = jnp.einsum(\"...hqk,...khd->...qhd\", attention, v)\n",
    "        values = values.reshape(-1, seq_len, embed_dim)\n",
    "        out = nn.Dense(embed_dim)(values)\n",
    "\n",
    "        return out, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Feed Forward Neural Network\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.array, deterministic: bool) -> jnp.array:\n",
    "        config = self.config\n",
    "        x = nn.Dense(config.ff_dim * 4, name=\"FFDense1\")(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.Dense(config.ff_dim, name=\"FFDense2\")(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"Transformer Encoder Layer\"\"\"\n",
    "\n",
    "    config: Config\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.array, mask: jnp.array, deterministic: bool) -> jnp.array:\n",
    "        config = self.config\n",
    "        res = x\n",
    "        x, attention = MultiHeadAttention(config)(x, x, x, mask)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm1\")(x + res)\n",
    "        res = x\n",
    "        x = FeedForward(config, name=\"FeedForward\")(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm2\")(x + res)\n",
    "\n",
    "        return x, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer Decoder Layer\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.array,\n",
    "        memory: jnp.array,\n",
    "        decoder_mask: jnp.array,\n",
    "        encoder_decoder_mask: jnp.array,\n",
    "        deterministic: bool,\n",
    "    ) -> Tuple[jnp.array, jnp.array, jnp.array]:\n",
    "        config = self.config\n",
    "        res = x\n",
    "        x, attention = MultiHeadAttention(config)(x, x, x, decoder_mask)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm1\")(x + res)\n",
    "        res = x\n",
    "        x, attention = MultiHeadAttention(config)(\n",
    "            x, memory, memory, encoder_decoder_mask\n",
    "        )\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        x = nn.LayerNorm(name=\"LayerNorm2\")(x + res)\n",
    "        return x, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.1656743 ,  0.0334887 ,  0.7145505 , -0.69273764, -0.7260953 ],\n",
       "       [-0.12573542, -0.35354394,  0.10587429,  0.05312492,  0.4437487 ],\n",
       "       [-0.04921824, -0.10327773, -0.13198015, -0.4364049 , -0.38484678],\n",
       "       [ 0.31554   ,  0.09454814,  0.4258944 , -0.27779824,  0.07495691],\n",
       "       [ 0.71339667, -0.04502202, -0.35073858,  0.59638804,  0.05645175],\n",
       "       [        nan,         nan,         nan,         nan,         nan]],      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.array([1, 1, 3, 3, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "emb = nn.Embed(num_embeddings=10, features=5)\n",
    "emb_variables = emb.init(random.PRNGKey(0), x)\n",
    "emb_output = emb.apply(emb_variables, x)\n",
    "emb_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.440659  ,  0.23434746,  0.44432253,  0.35004553, -1.0721016 ],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.5751345 , -0.31515005, -0.7112598 , -0.22740227,  0.52951103],\n",
       "       [-0.1656743 ,  0.0334887 ,  0.7145505 , -0.69273764, -0.7260953 ],\n",
       "       [-0.12573542, -0.35354394,  0.10587429,  0.05312492,  0.4437487 ],\n",
       "       [-0.04921824, -0.10327773, -0.13198015, -0.4364049 , -0.38484678],\n",
       "       [ 0.31554   ,  0.09454814,  0.4258944 , -0.27779824,  0.07495691],\n",
       "       [ 0.71339667, -0.04502202, -0.35073858,  0.59638804,  0.05645175],\n",
       "       [        nan,         nan,         nan,         nan,         nan]],      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[  0   1 100   3   4   5   6   7   8   9]\n"
     ]
    }
   ],
   "source": [
    "y = jnp.arange(10)\n",
    "print(y)\n",
    "y = y.at[2].set(100)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatEmbedding(nn.Module):\n",
    "    # config: Config\n",
    "    \"\"\"Embedding lookup for token ids.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: list[StringNumeric]) -> jnp.array:\n",
    "        config = Config()\n",
    "        embed = nn.Embed(\n",
    "            config.vocab_size,\n",
    "            config.embed_dim,\n",
    "            embedding_init=jax.nn.initializers.normal(stddev=config.embed_dim**-0.5),\n",
    "            name=\"FloatEmbedding\",\n",
    "        )\n",
    "        embeddings = jnp.zeros((len(x), config.embed_dim))\n",
    "        # return embeddings\n",
    "        for i, sn in enumerate(x):\n",
    "            if sn.is_numeric:\n",
    "                arr = jnp.zeros(config.embed_dim)\n",
    "                arr = arr.at[0].set(sn.value)\n",
    "                embeddings = embeddings.at[i].set(arr)\n",
    "            else:\n",
    "                embeddings = embeddings.at[i].set(embed(sn.embedding_idx))\n",
    "\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer Encoder\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.array,\n",
    "        mask: jnp.array,\n",
    "        deterministic: bool,\n",
    "        return_attention: bool = False,\n",
    "    ) -> Union[jnp.array, Tuple[jnp.array, List[jnp.array]]]:\n",
    "        config = self.config\n",
    "        x = FloatEmbedding(config)(x)\n",
    "        x = PositionalEncoding(config)(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        attention_list = []\n",
    "        for i in range(config.n_layers):\n",
    "            x, attention = TransformerEncoderLayer(config, name=f\"EncoderLayer_{i}\")(\n",
    "                x, mask, deterministic\n",
    "            )\n",
    "            attention_list.append(attention)\n",
    "\n",
    "        x = nn.LayerNorm(name=\"LayerNorm\")(x)\n",
    "        if return_attention:\n",
    "            return x, attention_list\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer Decoder\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.array,\n",
    "        memory: jnp.array,\n",
    "        decoder_mask: jnp.array,\n",
    "        encoder_decoder_mask: jnp.array,\n",
    "        deterministic: bool,\n",
    "        return_attention: bool = False,\n",
    "    ) -> Union[jnp.array, Tuple[jnp.array, List[jnp.array]]]:\n",
    "        config = self.config\n",
    "        x = FloatEmbedding(config)(x)\n",
    "        x = PositionalEncoding(config)(x)\n",
    "        x = nn.Dropout(config.p_drop)(x, deterministic=deterministic)\n",
    "        self_attention_list, src_attention_list = [], []\n",
    "        for i in range(config.n_layers):\n",
    "            x, self_attention, src_attention = TransformerDecoderLayer(config, name=f\"DecoderLayer_{i}\")(\n",
    "                x,\n",
    "                memory,\n",
    "                decoder_mask,\n",
    "                encoder_decoder_mask,\n",
    "                deterministic,\n",
    "            )\n",
    "            self_attention_list.append(self_attention)\n",
    "            src_attention_list.append(src_attention)\n",
    "\n",
    "\n",
    "        x = nn.LayerNorm(name=\"LayerNorm\")(x)\n",
    "        x = nn.Dense(config.vocab_size, name=\"Dense\")(x)\n",
    "        if return_attention:\n",
    "            return x, self_attention_list, src_attention_list\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    config: Config\n",
    "    \"\"\"Transformer\"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.Encoder = TransformerEncoder(self.config)\n",
    "        self.Decoder = TransformerDecoder(self.config)\n",
    "\n",
    "\n",
    "\n",
    "        def encode(self, src: TabularDataset, train: bool = True) -> jnp.array:\n",
    "            config = self.config\n",
    "\n",
    "            encoder_mask = nn.make_attention_mask(jnp.ones_like(src), src, dtype=\"bool\")\n",
    "\n",
    "\n",
    "        def __call__(\n",
    "                self,\n",
    "                src: TabularDataset,\n",
    "                tgt: TabularDataset,\n",
    "                train: bool = True\n",
    "        ) -> jnp.array:\n",
    "            \n",
    "\n",
    "            memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.8'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flax.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_attention_mask in module flax.linen.attention:\n",
      "\n",
      "make_attention_mask(query_input: Any, key_input: Any, pairwise_fn: Callable[..., Any] = <PjitFunction of <function jax.numpy.multiply at 0x7f84cff83ac0>>, extra_batch_dims: int = 0, dtype: Any = <class 'jax.numpy.float32'>)\n",
      "    Mask-making helper for attention weights.\n",
      "    \n",
      "    In case of 1d inputs (i.e., `[batch..., len_q]`, `[batch..., len_kv]`, the\n",
      "    attention weights will be `[batch..., heads, len_q, len_kv]` and this\n",
      "    function will produce `[batch..., 1, len_q, len_kv]`.\n",
      "    \n",
      "    Args:\n",
      "      query_input: a batched, flat input of query_length size\n",
      "      key_input: a batched, flat input of key_length size\n",
      "      pairwise_fn: broadcasting elementwise comparison function\n",
      "      extra_batch_dims: number of extra batch dims to add singleton\n",
      "        axes for, none by default\n",
      "      dtype: mask return dtype\n",
      "    \n",
      "    Returns:\n",
      "      A `[batch..., 1, len_q, len_kv]` shaped mask for 1d attention.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.make_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class partial in module functools:\n",
      "\n",
      "class partial(builtins.object)\n",
      " |  partial(func, *args, **keywords) - new function with partial application\n",
      " |  of the given arguments and keywords.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, /, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name, /)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value, /)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      See PEP 585\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |  \n",
      " |  __vectorcalloffset__\n",
      " |  \n",
      " |  args\n",
      " |      tuple of arguments to future partial calls\n",
      " |  \n",
      " |  func\n",
      " |      function object to use in future partial calls\n",
      " |  \n",
      " |  keywords\n",
      " |      dictionary of keyword arguments to future partial calls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO80HV+1vvnHCe4/KXEdo9l",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hepheastus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "46ccecb0382603292763ecbdda78a1f11d4c009df5d14d09120607e175cb3ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
