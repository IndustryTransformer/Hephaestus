{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import hephaestus as hp\n",
    "\n",
    "import hashlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>carat</th><th>cut</th><th>color</th><th>clarity</th><th>depth</th><th>table</th><th>price</th><th>x</th><th>y</th><th>z</th></tr><tr><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.23</td><td>&quot;Ideal&quot;</td><td>&quot;E&quot;</td><td>&quot;SI2&quot;</td><td>61.5</td><td>55.0</td><td>326</td><td>3.95</td><td>3.98</td><td>2.43</td></tr><tr><td>0.21</td><td>&quot;Premium&quot;</td><td>&quot;E&quot;</td><td>&quot;SI1&quot;</td><td>59.8</td><td>61.0</td><td>326</td><td>3.89</td><td>3.84</td><td>2.31</td></tr><tr><td>0.23</td><td>&quot;Good&quot;</td><td>&quot;E&quot;</td><td>&quot;VS1&quot;</td><td>56.9</td><td>65.0</td><td>327</td><td>4.05</td><td>4.07</td><td>2.31</td></tr><tr><td>0.29</td><td>&quot;Premium&quot;</td><td>&quot;I&quot;</td><td>&quot;VS2&quot;</td><td>62.4</td><td>58.0</td><td>334</td><td>4.2</td><td>4.23</td><td>2.63</td></tr><tr><td>0.31</td><td>&quot;Good&quot;</td><td>&quot;J&quot;</td><td>&quot;SI2&quot;</td><td>63.3</td><td>58.0</td><td>335</td><td>4.34</td><td>4.35</td><td>2.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────┬─────────┬───────┬─────────┬───┬───────┬──────┬──────┬──────┐\n",
       "│ carat ┆ cut     ┆ color ┆ clarity ┆ … ┆ price ┆ x    ┆ y    ┆ z    │\n",
       "│ ---   ┆ ---     ┆ ---   ┆ ---     ┆   ┆ ---   ┆ ---  ┆ ---  ┆ ---  │\n",
       "│ f64   ┆ str     ┆ str   ┆ str     ┆   ┆ i64   ┆ f64  ┆ f64  ┆ f64  │\n",
       "╞═══════╪═════════╪═══════╪═════════╪═══╪═══════╪══════╪══════╪══════╡\n",
       "│ 0.23  ┆ Ideal   ┆ E     ┆ SI2     ┆ … ┆ 326   ┆ 3.95 ┆ 3.98 ┆ 2.43 │\n",
       "│ 0.21  ┆ Premium ┆ E     ┆ SI1     ┆ … ┆ 326   ┆ 3.89 ┆ 3.84 ┆ 2.31 │\n",
       "│ 0.23  ┆ Good    ┆ E     ┆ VS1     ┆ … ┆ 327   ┆ 4.05 ┆ 4.07 ┆ 2.31 │\n",
       "│ 0.29  ┆ Premium ┆ I     ┆ VS2     ┆ … ┆ 334   ┆ 4.2  ┆ 4.23 ┆ 2.63 │\n",
       "│ 0.31  ┆ Good    ┆ J     ┆ SI2     ┆ … ┆ 335   ┆ 4.34 ┆ 4.35 ┆ 2.75 │\n",
       "└───────┴─────────┴───────┴─────────┴───┴───────┴──────┴──────┴──────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/diamonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hp.make_lower_remove_special_chars(df)\n",
    "val_tokens = hp.get_unique_utf8_values(df)\n",
    "col_tokens = hp.get_col_tokens(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = np.array(\n",
    "    [\n",
    "        \"missing\",\n",
    "        \"[MASK]\",\n",
    "        \"[NUMERIC]\",\n",
    "        \"<pad>\",\n",
    "        \"<unk>\",\n",
    "        \":\",\n",
    "        \",\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', ':', '<mask>', '<numeric>', '<numeric_mask><pad>',\n",
       "       '<row-end>', '<row-start>', '<unk>', 'carat', 'clarity', 'color',\n",
       "       'cut', 'd', 'depth', 'e', 'f', 'fair', 'g', 'good', 'h', 'i', 'i1',\n",
       "       'ideal', 'if', 'j', 'missing', 'premium', 'price', 'si1', 'si2',\n",
       "       'table', 'very good', 'vs1', 'vs2', 'vvs1', 'vvs2', 'x', 'y', 'z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = np.unique(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            val_tokens,\n",
    "            col_tokens,\n",
    "            special_tokens,\n",
    "            np.array(\n",
    "                [\n",
    "                    \"<numeric>\",\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>hash</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>685</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────┐\n",
       "│ hash │\n",
       "│ ---  │\n",
       "│ u32  │\n",
       "╞══════╡\n",
       "│ 685  │\n",
       "└──────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.with_columns(\n",
    "        pl.concat_str(pl.all().exclude(\"price\").cast(pl.Utf8)).alias(\"all_cols\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"all_cols\")\n",
    "        .apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "        .alias(\"hash\")\n",
    "    )\n",
    "    .drop(\"all_cols\")\n",
    ")\n",
    "df.select(pl.col(\"hash\").is_duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "n_train = int(train_fraction * len(df))\n",
    "train_test_df = df.select(pl.all().exclude([\"price\", \"hash\"]))\n",
    "\n",
    "train, test = train_test_df.head(n_train), train_test_df.tail(\n",
    "    len(train_test_df) - n_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "ds = hp.TabularDataset(\n",
    "    train,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=True,\n",
    "    max_row_length=50,\n",
    ")\n",
    "\n",
    "print(len(ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    device_name = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringNumericEmbedding(nn.Module):\n",
    "    def __init__(self, state_dict, device: torch.device, tokenizer):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.bert_tokenizer = tokenizer\n",
    "        self.word_embeddings = nn.Embedding(*state_dict[\"weight\"].shape).to(device)\n",
    "        self.word_embeddings.load_state_dict(state_dict)  # .to(device)\n",
    "        self.numeric_embedding = nn.Sequential(\n",
    "            nn.Linear(1, 128),  # First hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),  # Second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, state_dict[\"weight\"].shape[1]),  # Output layer\n",
    "        ).to(device)\n",
    "\n",
    "        # self.numeric_embedding = nn.Linear(1, d_model).to(device)\n",
    "\n",
    "    def forward(self, input: hp.StringNumeric):\n",
    "        tensor_list = [\n",
    "            self.word_embeddings(torch.tensor([101]).to(self.device)).reshape(1, 1, -1)\n",
    "        ]  # Start token\n",
    "        for val in input:\n",
    "            if val.is_numeric:\n",
    "                val = torch.Tensor([val.value]).float().to(self.device)\n",
    "                val = self.numeric_embedding(val)\n",
    "                val = val.reshape(1, 1, -1)  # val.shape[0])\n",
    "                tensor_list.append(val)\n",
    "            else:\n",
    "                tokens_ids = self.bert_tokenizer.encode_plus(\n",
    "                    val.value, return_tensors=\"pt\", add_special_tokens=False\n",
    "                )\n",
    "                tensor_list.append(\n",
    "                    self.word_embeddings(tokens_ids[\"input_ids\"].to(self.device))\n",
    "                )\n",
    "        tensor_list.append(\n",
    "            self.word_embeddings(torch.tensor([102]).to(self.device)).reshape(1, 1, -1)\n",
    "        )  # End token\n",
    "\n",
    "        tensor_list = torch.cat(tensor_list, dim=-2)\n",
    "\n",
    "        return tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 2, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 2, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 2, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
      "         [-0.0043, -0.0330, -0.0217,  ..., -0.0425, -0.0127, -0.0389],\n",
      "         [ 0.0789, -0.0312,  0.0030,  ..., -0.0320,  0.0042, -0.0183],\n",
      "         ...,\n",
      "         [ 0.0037, -0.0069,  0.0087,  ...,  0.0054, -0.0043, -0.0004],\n",
      "         [ 0.0298, -0.0373, -0.0356,  ...,  0.0161,  0.0192,  0.0173],\n",
      "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
      "       device='mps:0', grad_fn=<CatBackward0>) torch.Size([1, 15, 768])\n"
     ]
    }
   ],
   "source": [
    "class HybridBertModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: torch.device,\n",
    "        bert_model_name=\"bert-base-uncased\",\n",
    "    ):\n",
    "        super(HybridBertModel, self).__init__()\n",
    "\n",
    "        # BERT Tokenizer and Model\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.bert_lm = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "        # self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.tokenizer.add_tokens([\"[MISSING]\", \"[NUMERIC]\"])\n",
    "\n",
    "        # Add tokens to BERT model\n",
    "\n",
    "        # self.bert = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "        self.bert_lm.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.bert_embedding_state_dict = (\n",
    "            self.bert_lm.bert.embeddings.word_embeddings.state_dict()\n",
    "        )\n",
    "        self.embedding_dim = self.bert_lm.bert.config.hidden_size\n",
    "        self.string_numeric_embd = StringNumericEmbedding(\n",
    "            state_dict=self.bert_embedding_state_dict,\n",
    "            device=device,\n",
    "            tokenizer=self.tokenizer,\n",
    "        )\n",
    "        # self.decoder = nn.Linear(self.embedding_dim, len(self.tokenizer)).to(device)\n",
    "        # Numeric Neural Net for numbers prediction after BERT\n",
    "        self.numeric_predictor = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: hp.StringNumeric):\n",
    "        input = self.string_numeric_embd(input)\n",
    "        bert_output = self.bert_lm.bert(inputs_embeds=input)\n",
    "        last_hidden_state = bert_output.last_hidden_state\n",
    "        pooled_output = bert_output.pooler_output\n",
    "\n",
    "        bert_logits = self.bert_lm.cls(last_hidden_state, pooled_output)[0]\n",
    "        numeric_prediction = self.numeric_predictor(last_hidden_state)\n",
    "        # mlm_output = self.decoder(mlm_output.last_hidden_state)\n",
    "        return bert_logits, numeric_prediction\n",
    "\n",
    "\n",
    "# Sample usage:\n",
    "\n",
    "# Assuming we have our input prepared as:\n",
    "# input_data = [\n",
    "#     # hp.StringNumeric(\"<row-start>\"),\n",
    "#     hp.StringNumeric(\"Hello\"),\n",
    "#     # hp.StringNumeric(42.0),\n",
    "#     hp.StringNumeric(\"world\"),\n",
    "#     # hp.StringNumeric(12),\n",
    "#     # hp.StringNumeric(\"<row-end>\"),\n",
    "# ]\n",
    "string = \"Hello Greg, my name is Kai, nice to [MASK] [MASK]!\"\n",
    "input_data = [hp.StringNumeric(i) for i in string.split()]\n",
    "# input_data.append(hp.StringNumeric(42.0))\n",
    "model = HybridBertModel(device=device).to(device)\n",
    "# input_data_tensor = StringNumeric(input_data, device=device)\n",
    "cat_preds, numeric_preds = model(input_data)\n",
    "# print(type(mlm_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". hello greg, my name is kai, nice to meet you!.\n"
     ]
    }
   ],
   "source": [
    "pred_max = torch.argmax(cat_preds, dim=2)\n",
    "print(model.tokenizer.decode(pred_max[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a standard tokenizer and bert model we get:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 768)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertForMaskedLM.from_pretrained(bert_model_name).to(device)\n",
    "model.eval()\n",
    "# Set model to evaluation mode\n",
    "tokenizer.add_tokens(\n",
    "    [\n",
    "        \"<numeric>\",\n",
    "        \"<numeric-mask>\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'hello', 'greg', ',', 'my', 'name', 'is', 'kai', ',', 'nice', 'to', 'meet', 'you', '!', '.']\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tokenizer.encode(\n",
    "    string, add_special_tokens=True, return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "# Get the predicted token (the token with the highest score/logit)\n",
    "predicted_index = torch.argmax(predictions[0], dim=1)\n",
    "predicted_token = tokenizer.convert_ids_to_tokens(predicted_index)\n",
    "\n",
    "print(predicted_token)  # This should give you a word like \"is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7592,  6754,  1010,  2026,  2171,  2003, 11928,  1010,  3835,\n",
       "          2000,   103,   103,   999,   102]], device='mps:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 30522])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-4.3165e-03, -3.3047e-02, -2.1731e-02,  ..., -4.2466e-02,\n",
       "           -1.2679e-02, -3.8873e-02],\n",
       "          [ 7.8894e-02, -3.1152e-02,  2.9700e-03,  ..., -3.2025e-02,\n",
       "            4.1950e-03, -1.8331e-02],\n",
       "          [ 5.2089e-05, -1.0468e-02, -9.9103e-03,  ...,  1.4558e-02,\n",
       "            1.3217e-02,  2.2406e-02],\n",
       "          ...,\n",
       "          [ 3.7373e-03, -6.9417e-03,  8.7393e-03,  ...,  5.3652e-03,\n",
       "           -4.2512e-03, -4.4829e-04],\n",
       "          [ 3.7373e-03, -6.9417e-03,  8.7393e-03,  ...,  5.3652e-03,\n",
       "           -4.2512e-03, -4.4829e-04],\n",
       "          [ 2.9787e-02, -3.7259e-02, -3.5608e-02,  ...,  1.6110e-02,\n",
       "            1.9150e-02,  1.7307e-02]]], device='mps:0',\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([1, 13, 768]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd = model.get_input_embeddings()\n",
    "embed_tensor = embd(input_tensor)\n",
    "embed_tensor, embed_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1012,  7592,  6754,  1010,  2026,  2171,  2003, 11928,  1010,  3835,\n",
       "         2000,  3113,  2017,   999,  1012], device='mps:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_index = torch.argmax(predictions[0], dim=1)\n",
    "predicted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
