{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForPreTraining\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import hephaestus as hp\n",
    "\n",
    "import hashlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>carat</th><th>cut</th><th>color</th><th>clarity</th><th>depth</th><th>table</th><th>price</th><th>x</th><th>y</th><th>z</th></tr><tr><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.23</td><td>&quot;Ideal&quot;</td><td>&quot;E&quot;</td><td>&quot;SI2&quot;</td><td>61.5</td><td>55.0</td><td>326</td><td>3.95</td><td>3.98</td><td>2.43</td></tr><tr><td>0.21</td><td>&quot;Premium&quot;</td><td>&quot;E&quot;</td><td>&quot;SI1&quot;</td><td>59.8</td><td>61.0</td><td>326</td><td>3.89</td><td>3.84</td><td>2.31</td></tr><tr><td>0.23</td><td>&quot;Good&quot;</td><td>&quot;E&quot;</td><td>&quot;VS1&quot;</td><td>56.9</td><td>65.0</td><td>327</td><td>4.05</td><td>4.07</td><td>2.31</td></tr><tr><td>0.29</td><td>&quot;Premium&quot;</td><td>&quot;I&quot;</td><td>&quot;VS2&quot;</td><td>62.4</td><td>58.0</td><td>334</td><td>4.2</td><td>4.23</td><td>2.63</td></tr><tr><td>0.31</td><td>&quot;Good&quot;</td><td>&quot;J&quot;</td><td>&quot;SI2&quot;</td><td>63.3</td><td>58.0</td><td>335</td><td>4.34</td><td>4.35</td><td>2.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────┬─────────┬───────┬─────────┬───┬───────┬──────┬──────┬──────┐\n",
       "│ carat ┆ cut     ┆ color ┆ clarity ┆ … ┆ price ┆ x    ┆ y    ┆ z    │\n",
       "│ ---   ┆ ---     ┆ ---   ┆ ---     ┆   ┆ ---   ┆ ---  ┆ ---  ┆ ---  │\n",
       "│ f64   ┆ str     ┆ str   ┆ str     ┆   ┆ i64   ┆ f64  ┆ f64  ┆ f64  │\n",
       "╞═══════╪═════════╪═══════╪═════════╪═══╪═══════╪══════╪══════╪══════╡\n",
       "│ 0.23  ┆ Ideal   ┆ E     ┆ SI2     ┆ … ┆ 326   ┆ 3.95 ┆ 3.98 ┆ 2.43 │\n",
       "│ 0.21  ┆ Premium ┆ E     ┆ SI1     ┆ … ┆ 326   ┆ 3.89 ┆ 3.84 ┆ 2.31 │\n",
       "│ 0.23  ┆ Good    ┆ E     ┆ VS1     ┆ … ┆ 327   ┆ 4.05 ┆ 4.07 ┆ 2.31 │\n",
       "│ 0.29  ┆ Premium ┆ I     ┆ VS2     ┆ … ┆ 334   ┆ 4.2  ┆ 4.23 ┆ 2.63 │\n",
       "│ 0.31  ┆ Good    ┆ J     ┆ SI2     ┆ … ┆ 335   ┆ 4.34 ┆ 4.35 ┆ 2.75 │\n",
       "└───────┴─────────┴───────┴─────────┴───┴───────┴──────┴──────┴──────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/diamonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hp.make_lower_remove_special_chars(df)\n",
    "val_tokens = hp.get_unique_utf8_values(df)\n",
    "col_tokens = hp.get_col_tokens(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = np.array(\n",
    "    [\n",
    "        \"missing\",\n",
    "        \"<mask>\",\n",
    "        \"<numeric_mask>\" \"<pad>\",\n",
    "        \"<unk>\",\n",
    "        \":\",\n",
    "        \",\",\n",
    "        \"<row-start>\",\n",
    "        \"<row-end>\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([',', ':', '<mask>', '<numeric>', '<numeric_mask><pad>',\n",
       "       '<row-end>', '<row-start>', '<unk>', 'carat', 'clarity', 'color',\n",
       "       'cut', 'd', 'depth', 'e', 'f', 'fair', 'g', 'good', 'h', 'i', 'i1',\n",
       "       'ideal', 'if', 'j', 'missing', 'premium', 'price', 'si1', 'si2',\n",
       "       'table', 'very good', 'vs1', 'vs2', 'vvs1', 'vvs2', 'x', 'y', 'z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = np.unique(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            val_tokens,\n",
    "            col_tokens,\n",
    "            special_tokens,\n",
    "            np.array(\n",
    "                [\n",
    "                    \"<numeric>\",\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>hash</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>685</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────┐\n",
       "│ hash │\n",
       "│ ---  │\n",
       "│ u32  │\n",
       "╞══════╡\n",
       "│ 685  │\n",
       "└──────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.with_columns(\n",
    "        pl.concat_str(pl.all().exclude(\"price\").cast(pl.Utf8)).alias(\"all_cols\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"all_cols\")\n",
    "        .apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "        .alias(\"hash\")\n",
    "    )\n",
    "    .drop(\"all_cols\")\n",
    ")\n",
    "df.select(pl.col(\"hash\").is_duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "n_train = int(train_fraction * len(df))\n",
    "train_test_df = df.select(pl.all().exclude([\"price\", \"hash\"]))\n",
    "\n",
    "train, test = train_test_df.head(n_train), train_test_df.tail(\n",
    "    len(train_test_df) - n_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "ds = hp.TabularDataset(\n",
    "    train,\n",
    "    tokens,\n",
    "    special_tokens=special_tokens,\n",
    "    shuffle_cols=True,\n",
    "    max_row_length=50,\n",
    ")\n",
    "\n",
    "print(len(ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    device_name = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringNumericEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dict,\n",
    "        device: torch.device,\n",
    "        tokenizer,\n",
    "        bert_model_name=\"bert-base-uncased\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        # self.bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.bert_tokenizer = tokenizer\n",
    "        self.word_embeddings = nn.Embedding(*state_dict[\"weight\"].shape).to(device)\n",
    "        self.word_embeddings.load_state_dict(state_dict)  # .to(device)\n",
    "        self.numeric_embedding = nn.Sequential(\n",
    "            nn.Linear(1, 128),  # First hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),  # Second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, state_dict[\"weight\"].shape[1]),  # Output layer\n",
    "        ).to(device)\n",
    "\n",
    "        # self.numeric_embedding = nn.Linear(1, d_model).to(device)\n",
    "\n",
    "    def forward(self, input: hp.StringNumeric):\n",
    "        tensor_list = []\n",
    "        for idx, val in enumerate(input):\n",
    "            if val.is_numeric:\n",
    "                val = torch.Tensor([val.value]).float().to(self.device)\n",
    "                val = self.numeric_embedding(val)\n",
    "                val = val.reshape(1, 1, -1)  # val.shape[0])\n",
    "                tensor_list.append(val)\n",
    "            else:\n",
    "                tokens_ids = self.bert_tokenizer.encode_plus(\n",
    "                    val.value, return_tensors=\"pt\", add_special_tokens=False\n",
    "                )\n",
    "                tensor_list.append(\n",
    "                    self.word_embeddings(tokens_ids[\"input_ids\"].to(self.device))\n",
    "                )\n",
    "\n",
    "        # return tensor_list\n",
    "        return torch.cat(tensor_list, dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class HybridBertModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: torch.device,\n",
    "        bert_model_name=\"bert-base-uncased\",\n",
    "    ):\n",
    "        super(HybridBertModel, self).__init__()\n",
    "\n",
    "        # BERT Tokenizer and Model\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.bert_lm = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "        # self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.tokenizer.add_tokens(\n",
    "            [\n",
    "                \"<numeric>\",\n",
    "                \"<numeric-mask>\",\n",
    "                \"<row-start>\",\n",
    "                \"<row-end>\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Add tokens to BERT model\n",
    "\n",
    "        # self.bert = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "        self.bert_lm.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.bert_embedding_state_dict = (\n",
    "            self.bert_lm.bert.embeddings.word_embeddings.state_dict()\n",
    "        )\n",
    "        self.embedding_dim = self.bert_lm.bert.config.hidden_size\n",
    "        self.string_numeric_embd = StringNumericEmbedding(\n",
    "            state_dict=self.bert_embedding_state_dict,\n",
    "            device=device,\n",
    "            tokenizer=self.tokenizer,\n",
    "            bert_model_name=bert_model_name,\n",
    "        )\n",
    "        # self.decoder = nn.Linear(self.embedding_dim, len(self.tokenizer)).to(device)\n",
    "        # Numeric Neural Net for numbers prediction after BERT\n",
    "        self.numeric_predictor = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, 128), nn.ReLU(), nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: hp.StringNumeric):\n",
    "        input = self.string_numeric_embd(input)\n",
    "        bert_output = self.bert_lm.bert(inputs_embeds=input)\n",
    "        last_hidden_state = bert_output.last_hidden_state\n",
    "        pooled_output = bert_output.pooler_output\n",
    "\n",
    "        bert_logits = self.bert_lm.cls(last_hidden_state, pooled_output)\n",
    "        numeric_prediction = self.numeric_predictor(last_hidden_state)\n",
    "        # mlm_output = self.decoder(mlm_output.last_hidden_state)\n",
    "        return bert_logits, numeric_prediction\n",
    "\n",
    "\n",
    "# Sample usage:\n",
    "\n",
    "# Assuming we have our input prepared as:\n",
    "# input_data = [\n",
    "#     # hp.StringNumeric(\"<row-start>\"),\n",
    "#     hp.StringNumeric(\"Hello\"),\n",
    "#     # hp.StringNumeric(42.0),\n",
    "#     hp.StringNumeric(\"world\"),\n",
    "#     # hp.StringNumeric(12),\n",
    "#     # hp.StringNumeric(\"<row-end>\"),\n",
    "# ]\n",
    "input_data = [\n",
    "    hp.StringNumeric(i)\n",
    "    for i in \"Hello Greg, my name is Kai, nice to [MASK] [MASK]!\".split()\n",
    "]\n",
    "input_data.append(hp.StringNumeric(42.0))\n",
    "model = HybridBertModel(device=device).to(device)\n",
    "# input_data_tensor = StringNumeric(input_data, device=device)\n",
    "cat_preds, numeric_preds = model(input_data)\n",
    "# print(type(mlm_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [torch.argmax(cat_preds[0][0, i]) for i in range(cat_preds[0].size(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', greg, my name is kai, welcome to be you!,'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.decode(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 30522, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.encode_plus(\"<numeric>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model2 = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sent1 = \"Hello World\"\n",
    "# sent2 = \"Natural language processing is fascinating.\"\n",
    "\n",
    "encoding = tokenizer(sent1, return_tensors=\"pt\")\n",
    "outputs = model2(**encoding)\n",
    "preds2 = [\n",
    "    torch.argmax(outputs[\"prediction_logits\"][0][i])\n",
    "    for i in range(outputs[\"prediction_logits\"].size(1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2088,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 30522])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model2(**encoding)\n",
    "outputs[\"prediction_logits\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['prediction_logits', 'seq_relationship_logits'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..!.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"prediction_logits\"]\n",
    "preds2 = [\n",
    "    torch.argmax(outputs[\"prediction_logits\"][0][i])\n",
    "    for i in range(outputs[\"prediction_logits\"].size(1))\n",
    "]\n",
    "model.tokenizer.decode(preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1012), tensor(1012), tensor(999), tensor(1012)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "tokens = model.tokenizer(\n",
    "    \"Hello Word\",\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2773,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2(model.tokenizer(\"Hello Word\", return_tensors=\"pt\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The masked token is predicted as: meet\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Create a masked version of the sentence\n",
    "sent = \"Hello Greg, my name is Kai, nice to [MASK] [MASK]!\"\n",
    "\n",
    "# Tokenize the masked sentence\n",
    "encoding = tokenizer(sent, return_tensors=\"pt\")\n",
    "\n",
    "# Get the model's predictions\n",
    "outputs = model(**encoding)\n",
    "\n",
    "# Find the position of the [MASK] token\n",
    "mask_position = encoding[\"input_ids\"][0].tolist().index(tokenizer.mask_token_id)\n",
    "\n",
    "# Get the predicted token ID for the [MASK] position\n",
    "predicted_token_id = torch.argmax(outputs[\"prediction_logits\"][0][mask_position]).item()\n",
    "\n",
    "# Convert the predicted token ID to its string representation\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_id])[0]\n",
    "\n",
    "print(f\"The masked token is predicted as: {predicted_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The masked token is predicted as: meet\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Create a masked version of the sentence\n",
    "sent = \"Hello Greg, my name is Kai, nice to [MASK] [MASK]!\"\n",
    "\n",
    "# Tokenize the masked sentence\n",
    "encoding = tokenizer(sent, return_tensors=\"pt\")\n",
    "\n",
    "# Get the model's predictions\n",
    "outputs = model(**encoding)\n",
    "\n",
    "# Find the position of the [MASK] token\n",
    "mask_position = encoding[\"input_ids\"][0].tolist().index(tokenizer.mask_token_id)\n",
    "\n",
    "# Get the predicted token ID for the [MASK] position\n",
    "predicted_token_id = torch.argmax(outputs[\"logits\"][0][mask_position]).item()\n",
    "\n",
    "# Convert the predicted token ID to its string representation\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_id])[0]\n",
    "\n",
    "print(f\"The masked token is predicted as: {predicted_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -7.1926,  -7.1353,  -7.1031,  ...,  -6.4026,  -6.2798,  -4.2368],\n",
       "         [ -7.7025,  -7.7246,  -7.8318,  ...,  -7.7502,  -6.3765,  -7.1184],\n",
       "         [ -8.0176,  -8.0051,  -8.0756,  ...,  -7.3671,  -8.6753,  -5.8166],\n",
       "         ...,\n",
       "         [-15.9470, -16.0016, -16.3098,  ..., -15.1893, -13.7253, -12.3115],\n",
       "         [-11.4620, -11.3866, -11.6499,  ...,  -9.7340, -11.4527,  -9.2347],\n",
       "         [-13.1976, -13.0234, -12.6816,  ..., -10.6328, -10.5908, -11.3072]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
