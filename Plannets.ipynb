{"cells":[{"cell_type":"markdown","metadata":{"id":"trbcfMV6vked"},"source":["<https://github.com/PolymathicAI/xVal>\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"yKsx1R26dLGC"},"outputs":[],"source":["import os\n","\n","os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2102,"status":"ok","timestamp":1708903394514,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"RYm4WOeS1B8x","outputId":"a5c71de2-9597-4fcb-a9a7-b743f1a29feb"},"outputs":[{"data":{"text/plain":["{cuda(id=0)}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import jax.numpy as jnp  # Oddly works in colab to set gpu\n","\n","arr = jnp.array([1, 2, 3])\n","arr.devices()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Jqmm_5s9KXkI"},"outputs":[],"source":["import icecream\n","from icecream import ic\n","\n","icecream.install()\n","ic_disable = False\n","if ic_disable:\n","    ic.disable()\n","ic.configureOutput(includeContext=True, contextAbsPath=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18045,"status":"ok","timestamp":1708903436762,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"oSKniUdxtiTd","outputId":"49871258-6ef7-4956-ad3b-90af827f7253"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-13 01:55:31.012423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import os\n","import ast\n","import re\n","\n","from datetime import datetime as dt\n","from torch.utils.data import DataLoader\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import hephaestus as hp\n","import jax\n","import jax.numpy as jnp\n","import numpy as np\n","import optax\n","import pandas as pd\n","from flax.training import train_state\n","from icecream import ic\n","from jax import random\n","from jax.tree_util import tree_flatten\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.notebook import tqdm, trange\n","from hephaestus.models.simple_time_series import SimpleDS\n","\n","pd.options.mode.copy_on_write = True"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'bias'), ('pooler', 'dense', 'kernel')}\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["(3, 768)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import FlaxBertModel, BertTokenizerFast\n","import jax.numpy as jnp\n","\n","# Load pre-trained BERT model and tokenizer\n","model_name = \"bert-base-uncased\"\n","model = FlaxBertModel.from_pretrained(model_name)\n","tokenizer = BertTokenizerFast.from_pretrained(model_name)\n","\n","# Get the embeddings matrix\n","embeddings = model.params[\"embeddings\"][\"word_embeddings\"][\"embedding\"]\n","\n","# Now you can access specific embeddings like this:\n","# For example, to get embeddings for tokens 23, 293, and 993:\n","selected_embeddings = jnp.take(embeddings, jnp.array([23, 293, 993]), axis=0)\n","\n","# If you want to get embeddings for specific words:\n","words = [\"hello\", \"world\", \"example\"]\n","tokens = tokenizer.convert_tokens_to_ids(words)\n","word_embeddings = jnp.take(embeddings, jnp.array(tokens), axis=0)\n","word_embeddings.shape"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(3, 768)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["embeddings[jnp.array([23, 293, 993])].shape"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def line2df(line, idx):\n","    data_rows = []\n","    line = ast.literal_eval(line)\n","    for i, time_step in enumerate(line[\"data\"]):\n","        row = {\"time_step\": i}\n","        # Add position data for each planet\n","        for j, position in enumerate(time_step):\n","            row[f\"planet{j}_x\"] = position[0]\n","            row[f\"planet{j}_y\"] = position[1]\n","        data_rows.append(row)\n","\n","    df = pd.DataFrame(data_rows)\n","    description = line.pop(\"description\")\n","    step_size = description.pop(\"stepsize\")\n","    for k, v in description.items():\n","        for k_prop, v_prop in v.items():\n","            df[f\"{k}_{k_prop}\"] = v_prop\n","    df[\"time_step\"] = df[\"time_step\"] * step_size\n","    df.insert(0, \"idx\", idx)\n","\n","    return df"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>...</th>\n","      <th>planet3_y</th>\n","      <th>planet3_m</th>\n","      <th>planet3_a</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","      <th>total_mass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>4.165044e+06</td>\n","      <td>4.165044e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>...</td>\n","      <td>2.783627e+06</td>\n","      <td>2.783627e+06</td>\n","      <td>2.783627e+06</td>\n","      <td>2.783627e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>5.563957e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>6.248635e+04</td>\n","      <td>9.748911e+00</td>\n","      <td>-1.339198e-01</td>\n","      <td>7.391138e-02</td>\n","      <td>-1.340140e-01</td>\n","      <td>7.291389e-02</td>\n","      <td>-1.305344e-01</td>\n","      <td>7.065633e-02</td>\n","      <td>2.999306e+00</td>\n","      <td>1.624756e+00</td>\n","      <td>...</td>\n","      <td>6.559150e-02</td>\n","      <td>2.996303e+00</td>\n","      <td>1.623874e+00</td>\n","      <td>9.980576e-01</td>\n","      <td>-1.276881e-01</td>\n","      <td>6.519469e-02</td>\n","      <td>3.002531e+00</td>\n","      <td>1.625815e+00</td>\n","      <td>1.001317e+00</td>\n","      <td>1.049149e+01</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.607949e+04</td>\n","      <td>5.993534e+00</td>\n","      <td>1.228071e+00</td>\n","      <td>1.213232e+00</td>\n","      <td>1.227950e+00</td>\n","      <td>1.212650e+00</td>\n","      <td>1.217229e+00</td>\n","      <td>1.203678e+00</td>\n","      <td>1.157182e+00</td>\n","      <td>5.876632e-01</td>\n","      <td>...</td>\n","      <td>1.200148e+00</td>\n","      <td>1.153190e+00</td>\n","      <td>5.270725e-01</td>\n","      <td>5.764675e-01</td>\n","      <td>1.211648e+00</td>\n","      <td>1.199625e+00</td>\n","      <td>1.156856e+00</td>\n","      <td>5.167198e-01</td>\n","      <td>5.779763e-01</td>\n","      <td>3.991780e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-3.294763e+00</td>\n","      <td>-2.997514e+00</td>\n","      <td>-3.284004e+00</td>\n","      <td>-2.998546e+00</td>\n","      <td>-3.289790e+00</td>\n","      <td>-2.998050e+00</td>\n","      <td>1.000003e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>...</td>\n","      <td>-2.997621e+00</td>\n","      <td>1.000054e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>9.369537e-05</td>\n","      <td>-3.273603e+00</td>\n","      <td>-2.998913e+00</td>\n","      <td>1.000103e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>6.720938e-05</td>\n","      <td>2.014597e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.124400e+04</td>\n","      <td>4.655172e+00</td>\n","      <td>-1.030131e+00</td>\n","      <td>-9.020907e-01</td>\n","      <td>-1.030516e+00</td>\n","      <td>-9.028009e-01</td>\n","      <td>-1.050662e+00</td>\n","      <td>-9.211662e-01</td>\n","      <td>1.993948e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>...</td>\n","      <td>-9.321272e-01</td>\n","      <td>1.996853e+00</td>\n","      <td>1.191548e+00</td>\n","      <td>4.980967e-01</td>\n","      <td>-1.071974e+00</td>\n","      <td>-9.394428e-01</td>\n","      <td>2.004240e+00</td>\n","      <td>1.215927e+00</td>\n","      <td>5.032645e-01</td>\n","      <td>7.282371e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>6.249100e+04</td>\n","      <td>9.523810e+00</td>\n","      <td>-1.542335e-01</td>\n","      <td>1.117099e-01</td>\n","      <td>-1.538916e-01</td>\n","      <td>1.099474e-01</td>\n","      <td>-1.525520e-01</td>\n","      <td>1.118031e-01</td>\n","      <td>2.994477e+00</td>\n","      <td>1.543047e+00</td>\n","      <td>...</td>\n","      <td>1.067355e-01</td>\n","      <td>3.001879e+00</td>\n","      <td>1.535683e+00</td>\n","      <td>9.955040e-01</td>\n","      <td>-1.507184e-01</td>\n","      <td>1.055276e-01</td>\n","      <td>3.000454e+00</td>\n","      <td>1.519040e+00</td>\n","      <td>1.003118e+00</td>\n","      <td>1.028205e+01</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>9.372800e+04</td>\n","      <td>1.440000e+01</td>\n","      <td>8.583344e-01</td>\n","      <td>9.784987e-01</td>\n","      <td>8.581045e-01</td>\n","      <td>9.783998e-01</td>\n","      <td>8.762358e-01</td>\n","      <td>9.912902e-01</td>\n","      <td>4.005747e+00</td>\n","      <td>2.020672e+00</td>\n","      <td>...</td>\n","      <td>9.956064e-01</td>\n","      <td>3.986406e+00</td>\n","      <td>1.969644e+00</td>\n","      <td>1.497746e+00</td>\n","      <td>8.906780e-01</td>\n","      <td>9.991220e-01</td>\n","      <td>4.003332e+00</td>\n","      <td>1.950518e+00</td>\n","      <td>1.503457e+00</td>\n","      <td>1.345633e+01</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.249990e+05</td>\n","      <td>2.400000e+01</td>\n","      <td>2.996370e+00</td>\n","      <td>2.999014e+00</td>\n","      <td>2.993319e+00</td>\n","      <td>2.999536e+00</td>\n","      <td>2.990464e+00</td>\n","      <td>2.998478e+00</td>\n","      <td>4.999994e+00</td>\n","      <td>2.999984e+00</td>\n","      <td>...</td>\n","      <td>3.000881e+00</td>\n","      <td>4.999990e+00</td>\n","      <td>2.999909e+00</td>\n","      <td>1.999957e+00</td>\n","      <td>2.985180e+00</td>\n","      <td>2.998936e+00</td>\n","      <td>4.999679e+00</td>\n","      <td>2.999497e+00</td>\n","      <td>1.999999e+00</td>\n","      <td>2.382455e+01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 28 columns</p>\n","</div>"],"text/plain":["                idx     time_step     planet0_x     planet0_y     planet1_x  \\\n","count  5.563957e+06  5.563957e+06  5.563957e+06  5.563957e+06  5.563957e+06   \n","mean   6.248635e+04  9.748911e+00 -1.339198e-01  7.391138e-02 -1.340140e-01   \n","std    3.607949e+04  5.993534e+00  1.228071e+00  1.213232e+00  1.227950e+00   \n","min    0.000000e+00  0.000000e+00 -3.294763e+00 -2.997514e+00 -3.284004e+00   \n","25%    3.124400e+04  4.655172e+00 -1.030131e+00 -9.020907e-01 -1.030516e+00   \n","50%    6.249100e+04  9.523810e+00 -1.542335e-01  1.117099e-01 -1.538916e-01   \n","75%    9.372800e+04  1.440000e+01  8.583344e-01  9.784987e-01  8.581045e-01   \n","max    1.249990e+05  2.400000e+01  2.996370e+00  2.999014e+00  2.993319e+00   \n","\n","          planet1_y     planet2_x     planet2_y     planet0_m     planet0_a  \\\n","count  5.563957e+06  4.165044e+06  4.165044e+06  5.563957e+06  5.563957e+06   \n","mean   7.291389e-02 -1.305344e-01  7.065633e-02  2.999306e+00  1.624756e+00   \n","std    1.212650e+00  1.217229e+00  1.203678e+00  1.157182e+00  5.876632e-01   \n","min   -2.998546e+00 -3.289790e+00 -2.998050e+00  1.000003e+00  1.000000e+00   \n","25%   -9.028009e-01 -1.050662e+00 -9.211662e-01  1.993948e+00  1.000000e+00   \n","50%    1.099474e-01 -1.525520e-01  1.118031e-01  2.994477e+00  1.543047e+00   \n","75%    9.783998e-01  8.762358e-01  9.912902e-01  4.005747e+00  2.020672e+00   \n","max    2.999536e+00  2.990464e+00  2.998478e+00  4.999994e+00  2.999984e+00   \n","\n","       ...     planet3_y     planet3_m     planet3_a     planet3_e  \\\n","count  ...  2.783627e+06  2.783627e+06  2.783627e+06  2.783627e+06   \n","mean   ...  6.559150e-02  2.996303e+00  1.623874e+00  9.980576e-01   \n","std    ...  1.200148e+00  1.153190e+00  5.270725e-01  5.764675e-01   \n","min    ... -2.997621e+00  1.000054e+00  1.000000e+00  9.369537e-05   \n","25%    ... -9.321272e-01  1.996853e+00  1.191548e+00  4.980967e-01   \n","50%    ...  1.067355e-01  3.001879e+00  1.535683e+00  9.955040e-01   \n","75%    ...  9.956064e-01  3.986406e+00  1.969644e+00  1.497746e+00   \n","max    ...  3.000881e+00  4.999990e+00  2.999909e+00  1.999957e+00   \n","\n","          planet4_x     planet4_y     planet4_m     planet4_a     planet4_e  \\\n","count  1.392864e+06  1.392864e+06  1.392864e+06  1.392864e+06  1.392864e+06   \n","mean  -1.276881e-01  6.519469e-02  3.002531e+00  1.625815e+00  1.001317e+00   \n","std    1.211648e+00  1.199625e+00  1.156856e+00  5.167198e-01  5.779763e-01   \n","min   -3.273603e+00 -2.998913e+00  1.000103e+00  1.000000e+00  6.720938e-05   \n","25%   -1.071974e+00 -9.394428e-01  2.004240e+00  1.215927e+00  5.032645e-01   \n","50%   -1.507184e-01  1.055276e-01  3.000454e+00  1.519040e+00  1.003118e+00   \n","75%    8.906780e-01  9.991220e-01  4.003332e+00  1.950518e+00  1.503457e+00   \n","max    2.985180e+00  2.998936e+00  4.999679e+00  2.999497e+00  1.999999e+00   \n","\n","         total_mass  \n","count  5.563957e+06  \n","mean   1.049149e+01  \n","std    3.991780e+00  \n","min    2.014597e+00  \n","25%    7.282371e+00  \n","50%    1.028205e+01  \n","75%    1.345633e+01  \n","max    2.382455e+01  \n","\n","[8 rows x 28 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["files = os.listdir(\"data\")\n","if \"planets.parquet\" not in files:\n","    with open(\"data/planets.data\") as f:\n","        data = f.read().splitlines()\n","\n","        dfs = []\n","        for idx, line in enumerate(tqdm(data)):\n","            dfs.append(line2df(line, idx))\n","        print(\"Concatenating dfs...\")\n","        df = pd.concat(dfs)\n","    df.to_parquet(\"data/planets.parquet\")\n","else:\n","    df = pd.read_parquet(\"data/planets.parquet\")\n","\n","\n","# Combine total mass of all planets into one column `planet<n>_m`\n","mass_regex = re.compile(r\"planet(\\d+)_m\")\n","mass_cols = [col for col in df.columns if mass_regex.match(col)]\n","df[\"total_mass\"] = df[mass_cols].sum(axis=1)\n","\n","# Introduce categorical columns for the number of planets choose non null columns with mass\n","df[\"n_planets\"] = df[mass_cols].notnull().sum(axis=1).astype(\"category\")\n","# Create category acceleration if the sum of plane/d_[x,y, z] is greater than 0\n","df[\"acceleration_x\"] = df[\n","    [col for col in df.columns if \"planet\" in col and \"_x\" in col]\n","].sum(axis=1)\n","# Set acceleration_x to \"increasing\" if greater than 0 else \"decreasing\"\n","df[\"acceleration_x\"] = df[\"acceleration_x\"].apply(\n","    lambda x: \"increasing\" if x > 0 else \"decreasing\"\n",")\n","df[\"acceleration_y\"] = df[\n","    [col for col in df.columns if \"planet\" in col and \"_y\" in col]\n","].sum(axis=1)\n","df[\"acceleration_y\"] = df[\"acceleration_y\"].apply(\n","    lambda x: \"increasing\" if x > 0 else \"decreasing\"\n",")\n","\n","\n","df.describe()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4RZof2SNKXkK"},"outputs":[{"data":{"text/plain":["(99999, 25001)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Get train test split at 80/20\n","train_idx = int(df.idx.max() * 0.8)\n","train_df = df.loc[df.idx < train_idx].copy()\n","test_df = df.loc[df.idx >= train_idx].copy()\n","# del df\n","train_ds = SimpleDS(train_df)\n","test_ds = SimpleDS(test_df)\n","len(train_ds), len(test_ds)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>...</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","      <th>total_mass</th>\n","      <th>n_planets</th>\n","      <th>acceleration_x</th>\n","      <th>acceleration_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>-0.274094</td>\n","      <td>1.658928</td>\n","      <td>-1.598680</td>\n","      <td>1.237278</td>\n","      <td>-0.072378</td>\n","      <td>1.334127</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.733333</td>\n","      <td>-0.810119</td>\n","      <td>1.516448</td>\n","      <td>-1.860540</td>\n","      <td>0.797326</td>\n","      <td>-0.675005</td>\n","      <td>1.164327</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1.466667</td>\n","      <td>-1.261577</td>\n","      <td>1.214381</td>\n","      <td>-2.002381</td>\n","      <td>0.305935</td>\n","      <td>-1.131812</td>\n","      <td>0.742120</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2.200000</td>\n","      <td>-1.587840</td>\n","      <td>0.791168</td>\n","      <td>-2.015313</td>\n","      <td>-0.205141</td>\n","      <td>-1.347517</td>\n","      <td>0.161522</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2.933333</td>\n","      <td>-1.762252</td>\n","      <td>0.291976</td>\n","      <td>-1.898518</td>\n","      <td>-0.702988</td>\n","      <td>-1.278262</td>\n","      <td>-0.453284</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>25000</td>\n","      <td>18.139535</td>\n","      <td>0.859903</td>\n","      <td>-0.357431</td>\n","      <td>-1.780663</td>\n","      <td>-0.841087</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>25000</td>\n","      <td>18.604651</td>\n","      <td>0.917215</td>\n","      <td>0.133881</td>\n","      <td>-1.609198</td>\n","      <td>-1.111904</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>25000</td>\n","      <td>19.069767</td>\n","      <td>0.732278</td>\n","      <td>0.590216</td>\n","      <td>-1.391311</td>\n","      <td>-1.350590</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>25000</td>\n","      <td>19.534884</td>\n","      <td>0.360838</td>\n","      <td>0.898121</td>\n","      <td>-1.132250</td>\n","      <td>-1.549225</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>25000</td>\n","      <td>20.000000</td>\n","      <td>-0.096652</td>\n","      <td>0.996967</td>\n","      <td>-0.838645</td>\n","      <td>-1.700474</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1110975 rows × 31 columns</p>\n","</div>"],"text/plain":["      idx  time_step  planet0_x  planet0_y  planet1_x  planet1_y  planet2_x  \\\n","0       0   0.000000  -0.274094   1.658928  -1.598680   1.237278  -0.072378   \n","1       0   0.733333  -0.810119   1.516448  -1.860540   0.797326  -0.675005   \n","2       0   1.466667  -1.261577   1.214381  -2.002381   0.305935  -1.131812   \n","3       0   2.200000  -1.587840   0.791168  -2.015313  -0.205141  -1.347517   \n","4       0   2.933333  -1.762252   0.291976  -1.898518  -0.702988  -1.278262   \n","..    ...        ...        ...        ...        ...        ...        ...   \n","39  25000  18.139535   0.859903  -0.357431  -1.780663  -0.841087        NaN   \n","40  25000  18.604651   0.917215   0.133881  -1.609198  -1.111904        NaN   \n","41  25000  19.069767   0.732278   0.590216  -1.391311  -1.350590        NaN   \n","42  25000  19.534884   0.360838   0.898121  -1.132250  -1.549225        NaN   \n","43  25000  20.000000  -0.096652   0.996967  -0.838645  -1.700474        NaN   \n","\n","    planet2_y  planet0_m  planet0_a  ...  planet3_e  planet4_x  planet4_y  \\\n","0    1.334127   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","1    1.164327   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","2    0.742120   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","3    0.161522   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","4   -0.453284   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","..        ...        ...        ...  ...        ...        ...        ...   \n","39        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","40        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","41        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","42        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","43        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","\n","    planet4_m  planet4_a  planet4_e  total_mass  n_planets  acceleration_x  \\\n","0         NaN        NaN        NaN   10.247159          4      decreasing   \n","1         NaN        NaN        NaN   10.247159          4      decreasing   \n","2         NaN        NaN        NaN   10.247159          4      decreasing   \n","3         NaN        NaN        NaN   10.247159          4      decreasing   \n","4         NaN        NaN        NaN   10.247159          4      decreasing   \n","..        ...        ...        ...         ...        ...             ...   \n","39        NaN        NaN        NaN    7.554701          2      decreasing   \n","40        NaN        NaN        NaN    7.554701          2      decreasing   \n","41        NaN        NaN        NaN    7.554701          2      decreasing   \n","42        NaN        NaN        NaN    7.554701          2      decreasing   \n","43        NaN        NaN        NaN    7.554701          2      decreasing   \n","\n","    acceleration_y  \n","0       increasing  \n","1       increasing  \n","2       increasing  \n","3       increasing  \n","4       decreasing  \n","..             ...  \n","39      decreasing  \n","40      decreasing  \n","41      decreasing  \n","42      decreasing  \n","43      decreasing  \n","\n","[1110975 rows x 31 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["((1110975, 31), (4452982, 31))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_df.shape, train_df.shape"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["124999"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.idx.max()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/environment/Hephaestus/hephaestus/models/simple_time_series.py:134: RuntimeWarning: invalid value encountered in cast\n","  batch = np.array(batch, dtype=np.int32)\n"]},{"data":{"text/plain":["Array([[[ 0.        ,  0.4651163 ,  0.9302326 , ...,         nan,\n","                 nan,         nan],\n","        [ 1.5600603 ,  1.689858  ,  1.7535888 , ...,         nan,\n","                 nan,         nan],\n","        [-0.854437  , -0.5143588 , -0.15420859, ...,         nan,\n","                 nan,         nan],\n","        ...,\n","        [        nan,         nan,         nan, ...,         nan,\n","                 nan,         nan],\n","        [        nan,         nan,         nan, ...,         nan,\n","                 nan,         nan],\n","        [ 6.9741225 ,  6.9741225 ,  6.9741225 , ...,         nan,\n","                 nan,         nan]]], dtype=float32)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["jnp.array([train_ds[0][0]])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def make_batch(ds: SimpleDS, start: int, length: int):\n","    numeric = []\n","    categorical = []\n","    for i in range(start, length + start):\n","        numeric.append(ds[i][0])\n","        categorical.append(ds[i][1])\n","    # print index of None values\n","    return {\"numeric\": jnp.array(numeric), \"categorical\": jnp.array(categorical)}\n","\n","\n","batch = make_batch(train_ds, 0, 4)\n","# batch"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Y4b7IkMWKXkK"},"outputs":[],"source":["# time_series_regressor = hp.simple_time_series.SimplePred(\n","#     train_ds, d_model=2048, n_heads=16 # large\n","# )\n","multiplier = 4\n","time_series_regressor = hp.simple_time_series.SimplePred(\n","    train_ds, d_model=512, n_heads=8 * multiplier\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# train_ds.reservoir_encoded"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[    0,     0,     0,     0,     0,     0,     0,     0],\n","       [ 1031, 16371, 25531,  1035,  7308,  1033,     0,     0],\n","       [  103,     0,     0,     0,     0,     0,     0,     0],\n","       [ 4774,  2509,  1035,  1049,     0,     0,     0,     0]],      dtype=int32)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# train_ds.reservoir_encoded\n","train_ds.reservoir_encoded[jnp.array([0, 1, 2, 23])]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[[         33,          33,          33,          33,\n","                  33,          33,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648],\n","        [         33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648]],\n","\n","       [[         35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          33,          33,\n","                  33,          33,          33,          33,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648],\n","        [         33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648]],\n","\n","       [[         35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          33,          33,          33,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648],\n","        [         35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648]],\n","\n","       [[         33,          33,          33,          33,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648],\n","        [         35,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          35,\n","                  35,          35,          35,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          33,\n","                  33,          33,          33,          35,\n","                  35,          35, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648, -2147483648,\n","         -2147483648, -2147483648, -2147483648]]], dtype=int32)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["batch[\"categorical\"]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["Array([1, 2, 3, 4], dtype=int32)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["test_arr = jnp.array([1.0, 2.0, 3.0, 4.0])\n","# Convert to int\n","test_arr = test_arr.astype(jnp.int32)\n","test_arr"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ic| simple_time_series.py:290 in __call__()\n","    numeric_inputs.shape: (4, 27, 59)\n","ic| simple_time_series.py:292 in __call__()- 'Here Again???'\n","ic| simple_time_series.py:526 in __call__()\n","    \"pe before tiling\": 'pe before tiling'\n","    pe.shape: (1, 59, 512, 1)\n","ic| simple_time_series.py:528 in __call__()\n","    \"pe after tiling\": 'pe after tiling'\n","    pe.shape: (4, 59, 512, 27)\n","ic| simple_time_series.py:530 in __call__()\n","    \"pe after transpose\": 'pe after transpose'\n","    pe.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:534 in __call__()\n","    \"PE Result shape\": 'PE Result shape'\n","    result.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:350 in __call__()\n","    numeric_broadcast.shape: (4, 27, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:362 in __call__()\n","    \"Masking for categorical data\": 'Masking for categorical data'\n","ic| simple_time_series.py:368 in __call__()\n","    mask_input.shape: (4, 29, 59)\n","ic| simple_time_series.py:375 in __call__()\n","    mask.shape: (4, 29, 1, 59, 59)\n","ic| simple_time_series.py:379 in __call__()\n","    tabular_data.shape: (4, 29, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:382 in __call__()\n","    \"Concatenating Embeddings\": 'Concatenating Embeddings'\n","ic| simple_time_series.py:383 in __call__()\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","    categorical_col_embeddings.shape: (4, 2, 59, 512)\n","ic| simple_time_series.py:384 in __call__()\n","    numeric_col_embeddings.dtype: dtype('float32')\n","    categorical_col_embeddings.dtype: dtype('float32')\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:447 in __call__()\n","    out.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:448 in __call__()\n","    f\"Nan values in simplePred out 1: {jnp.isnan(out).any()}\": 'Nan values in simplePred out 1: False'\n"]}],"source":["key = random.PRNGKey(0)\n","init_key, dropout_key = random.split(key)\n","vars = time_series_regressor.init(\n","    {\"params\": init_key, \"dropout\": dropout_key},\n","    batch[\"numeric\"],\n","    categorical_inputs=batch[\"categorical\"].astype(jnp.int32),\n","    deterministic=False,\n",")\n","dropout_key, original_dropout_key = random.split(dropout_key)"]},{"cell_type":"markdown","metadata":{},"source":["```\n","mask.shape=(4, 26, 1, 59, 59), attn_weights.shape=(4, 26, 16, 59, 59)\n","Mask example\n","[[0\\. 0\\. 0\\. ... 0\\. 0\\. 0.]\n"," [0\\. 1\\. 0\\. ... 0\\. 0\\. 0.]\n"," [0\\. 1\\. 1\\. ... 0\\. 0\\. 0.]\n"," ...\n"," [1\\. 1\\. 1\\. ... 1\\. 0\\. 0.]\n"," [1\\. 1\\. 1\\. ... 1\\. 1\\. 0.]\n"," [1\\. 1\\. 1\\. ... 1\\. 1\\. 1.]]\n","```\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(5563957, 31)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# ic.disable()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ic| simple_time_series.py:290 in __call__()\n","    numeric_inputs.shape: (4, 27, 59)\n","ic| simple_time_series.py:292 in __call__()- 'Here Again???'\n","ic| simple_time_series.py:526 in __call__()\n","    \"pe before tiling\": 'pe before tiling'\n","    pe.shape: (1, 59, 512, 1)\n","ic| simple_time_series.py:528 in __call__()\n","    \"pe after tiling\": 'pe after tiling'\n","    pe.shape: (4, 59, 512, 27)\n","ic| simple_time_series.py:530 in __call__()\n","    \"pe after transpose\": 'pe after transpose'\n","    pe.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:534 in __call__()\n","    \"PE Result shape\": 'PE Result shape'\n","    result.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:350 in __call__()\n","    numeric_broadcast.shape: (4, 27, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:362 in __call__()\n","    \"Masking for categorical data\": 'Masking for categorical data'\n","ic| simple_time_series.py:368 in __call__()\n","    mask_input.shape: (4, 29, 59)\n","ic| simple_time_series.py:375 in __call__()\n","    mask.shape: (4, 29, 1, 59, 59)\n","ic| simple_time_series.py:379 in __call__()\n","    tabular_data.shape: (4, 29, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:382 in __call__()\n","    \"Concatenating Embeddings\": 'Concatenating Embeddings'\n","ic| simple_time_series.py:383 in __call__()\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","    categorical_col_embeddings.shape: (4, 2, 59, 512)\n","ic| simple_time_series.py:384 in __call__()\n","    numeric_col_embeddings.dtype: dtype('float32')\n","    categorical_col_embeddings.dtype: dtype('float32')\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:447 in __call__()\n","    out.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:448 in __call__()\n","    f\"Nan values in simplePred out 1: {jnp.isnan(out).any()}\": 'Nan values in simplePred out 1: False'\n"]},{"name":"stdout","output_type":"stream","text":["(4, 29, 59, 27)\n","(4, 29, 59, 2)\n"]}],"source":["x = time_series_regressor.apply(\n","    vars,\n","    batch[\"numeric\"],\n","    batch[\"categorical\"].astype(jnp.int32),\n","    deterministic=False,\n","    rngs={\"dropout\": dropout_key},\n",")\n","print(x.get(\"numeric_out\").shape)\n","# Check if categorical input is None and print None or it's shape\n","print(x.get(\"categorical_out\").shape if x.get(\"categorical_out\") is not None else None)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# time_series_regressor.tabulate(\n","#     {\"params\": init_key, \"dropout\": dropout_key},\n","#     batch[\"numeric\"],\n","#     console_kwargs={\"force_jupyter\": True, \"width\": 120},\n","# )"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory of custom: 84.73 MB with 21,182,749 parameters\n"]}],"source":["def calculate_memory_footprint(params):\n","    \"\"\"Calculate total memory footprint of JAX model parameters and total\n","    number of parameters.\"\"\"\n","    total_bytes = 0\n","    # Flatten the parameter tree structure into a list of arrays\n","    flat_params, _ = tree_flatten(params)\n","    for param in flat_params:\n","        # Calculate bytes: number of elements * size of each element\n","        bytes_per_param = param.size * param.dtype.itemsize\n","        total_bytes += bytes_per_param\n","    return total_bytes\n","\n","\n","def count_parameters(params):\n","    return sum(jnp.prod(jnp.array(p.shape)) for p in jax.tree_util.tree_leaves(params))\n","\n","\n","mem = calculate_memory_footprint(vars)\n","total_params = count_parameters(vars)\n","\n","\n","print(f\"Memory of custom: {mem / 1e6:.2f} MB with {total_params:,} parameters\")"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4dd64f565fcf4b259ef24944493477bf","25ce5408138f4cb28e163f1fdffdee5f","47793d3155614c8cbd7d3337dcb2f895","f9ec11073e484927a4cc1ee2e3da132f","62e750769d364ab2b80d5b9646b10ea6","8b35a70a3b9e4f3b87cf2a7280439ac6","0e26d28846fb449789510e4748c01c6a","f8093c8ddeec4c55ac6cc5f8f7df30bf","4151c7353de54909aa9deecbe8c1e1e1","9ced4485d5c641eda90ab0634e0691d3","6f5ca39406174a4fb1bee9eb1e35fccb","5e15315a77864badafe48c2baf31b030","dfd9dd713862479bba73b6c0a12a1902","88be535ce5a945f4979fe72d9f086365","31d37adf891a4da68675945509051210","4da9993585914618a35d8d5382fef850","acee2c1ed91e44188d5ca40bddace4b1","cc57eeb92d32434ca82b7c3f669865d1","f8382d8bbb7f42f6a0f4d4028203615f","851b29291123491a821b1ce8088ca785","055681c8159b4b6c8104d4e06279803c","9f5e5843559b4f9e8f3440ebd85743f8","a317a54aa1a349f490e388aacb2d1e4d","c470a61e692a4459988f63f0024f7eac","5edd903b07594d128ded9b4844835159","2ac0cceac38e43adb00a10b778fad2df","c7f61bdee3ca4ca0a3f7d021aa558deb","70c7b641da5c4b82bbd5b2e1750f3b39","462d9e93a94f44868fec1ece82f0a241","4bc81f6d94394d7f90e070d8b11a7059","d3bc58d04d5f42a5a24bd467a9569e01","ddb1791795134ac0a754748f9793c214","d95aea2b915b44f38b5090ee186abafd","01ca2dcb14e647dfb1e68750ca6de39c","a51aa7b827db4f768dce6315dbebf379","634935ff0a6b4d65b72f87359d9f82fc","09b63c98bee543dfb557a007d50c41d1","dc4a8a3b0a8b4ef49dcd6269a1b32e14","5f1fb4d40e154e27baa0d4f330df540e","948787e6434f419a86d9d7da831e2572","e4de75777bba4d72b61936baf3d84cbb","0481743e80634f7a8e718fb528950e54","2fb36a08ca1540228919af722727572c","3bd47d84fac442d4bcf49dceeb699d45"]},"executionInfo":{"elapsed":841688,"status":"ok","timestamp":1708904334771,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"RIXu3GkdYzNA","outputId":"dee6137d-c096-4df6-fbb4-baa3764d359e"},"outputs":[{"name":"stderr","output_type":"stream","text":["ic| simple_time_series.py:290 in __call__()\n","    numeric_inputs.shape: (4, 27, 59)\n"]},{"name":"stderr","output_type":"stream","text":["ic| simple_time_series.py:292 in __call__()- 'Here Again???'\n","ic| simple_time_series.py:526 in __call__()\n","    \"pe before tiling\": 'pe before tiling'\n","    pe.shape: (1, 59, 512, 1)\n","ic| simple_time_series.py:528 in __call__()\n","    \"pe after tiling\": 'pe after tiling'\n","    pe.shape: (4, 59, 512, 27)\n","ic| simple_time_series.py:530 in __call__()\n","    \"pe after transpose\": 'pe after transpose'\n","    pe.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:534 in __call__()\n","    \"PE Result shape\": 'PE Result shape'\n","    result.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:350 in __call__()\n","    numeric_broadcast.shape: (4, 27, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:362 in __call__()\n","    \"Masking for categorical data\": 'Masking for categorical data'\n","ic| simple_time_series.py:368 in __call__()\n","    mask_input.shape: (4, 29, 59)\n","ic| simple_time_series.py:375 in __call__()\n","    mask.shape: (4, 29, 1, 59, 59)\n","ic| simple_time_series.py:379 in __call__()\n","    tabular_data.shape: (4, 29, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| simple_time_series.py:382 in __call__()\n","    \"Concatenating Embeddings\": 'Concatenating Embeddings'\n","ic| simple_time_series.py:383 in __call__()\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","    categorical_col_embeddings.shape: (4, 2, 59, 512)\n","ic| simple_time_series.py:384 in __call__()\n","    numeric_col_embeddings.dtype: dtype('float32')\n","    categorical_col_embeddings.dtype: dtype('float32')\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:182 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:447 in __call__()\n","    out.shape: (4, 29, 59, 512)\n","ic| simple_time_series.py:448 in __call__()\n","    f\"Nan values in simplePred out 1: {jnp.isnan(out).any()}\": 'Nan values in simplePred out 1: False'\n"]}],"source":["mts_root_key = random.PRNGKey(44)\n","mts_main_key, ts_params_key, ts_data_key = random.split(mts_root_key, 3)\n","\n","mask_data = False\n","\n","\n","def clip_gradients(gradients, max_norm):\n","    total_norm = jnp.sqrt(sum(jnp.sum(jnp.square(grad)) for grad in gradients.values()))\n","    scale = max_norm / (total_norm + 1e-6)\n","    clipped_gradients = jax.tree_map(\n","        lambda grad: jnp.where(total_norm > max_norm, grad * scale, grad), gradients\n","    )\n","    return clipped_gradients\n","\n","\n","def add_time_shifts(inputs: jnp.array, outputs: jnp.array) -> jnp.array:\n","    inputs_offset = 1\n","    inputs = inputs[:, :, inputs_offset:]\n","    tmp_null = jnp.full((inputs.shape[0], inputs.shape[1], inputs_offset), jnp.nan)\n","    inputs = jnp.concatenate([inputs, tmp_null], axis=2)\n","    nan_mask = jnp.isnan(inputs)\n","    inputs = jnp.where(nan_mask, jnp.zeros_like(inputs), inputs)\n","\n","    outputs = jnp.where(nan_mask, jnp.zeros_like(outputs), outputs)\n","\n","    return inputs, outputs, nan_mask\n","\n","\n","def numeric_loss(inputs, outputs):\n","    inputs, outputs, nan_mask = add_time_shifts(inputs, outputs)\n","    # TODO make loss SSL for values greater than 0.5 and MSE for values less than 0.5\n","    raw_loss = jnp.abs(outputs - inputs)\n","    masked_loss = jnp.where(nan_mask, 0.0, raw_loss)\n","    loss = masked_loss.sum() / (~nan_mask).sum()\n","    return loss\n","\n","\n","def categorical_loss(inputs, outputs):\n","    inputs, outputs, nan_mask = add_time_shifts(inputs, outputs)\n","\n","    raw_loss = optax.squared_error(outputs, inputs)\n","    masked_loss = jnp.where(nan_mask, 0.0, raw_loss).mean()\n","    return masked_loss\n","\n","\n","def base_loss(inputs, outputs):\n","    numeric = numeric_loss(inputs[\"numeric\"], outputs[\"numeric_out\"])\n","    categorical = categorical_loss(inputs[\"categorical\"], outputs[\"categorical_out\"])\n","    return numeric + categorical\n","\n","\n","# def base_loss(inputs, outputs):\n","#     # Remove the first value and add a jnp.nan to the end\n","#     # inputs = inputs * 3\n","#     inputs_offset = 1\n","#     inputs = inputs[:, :, inputs_offset:]\n","#     print(f\"Inputs shape: {inputs.shape=}\")\n","#     # Add a jnp.nan to the end\n","#     temp_null = jnp.full((inputs.shape[0], inputs.shape[1], inputs_offset), jnp.nan)\n","#     inputs = jnp.concatenate([inputs, temp_null], axis=2)\n","#     print(f\"Inputs shape after addition: {inputs.shape=}\")\n","#     nan_mask = jnp.isnan(inputs)\n","#     inputs = jnp.where(nan_mask, jnp.zeros_like(inputs), inputs)\n","\n","#     # outputs = outputs[:, :, :-inputs_offset]\n","#     outputs = jnp.where(nan_mask, jnp.zeros_like(outputs), outputs)\n","\n","#     # raw_loss = optax.squared_error(outputs, inputs)\n","#     # compute manually\n","#     # raw_loss = jnp.square(outputs - inputs)\n","#     # Abs loss\n","#     raw_loss = jnp.abs(outputs - inputs)\n","#     masked_loss = jnp.where(nan_mask, 0.0, raw_loss)\n","#     loss = masked_loss.sum() / (~nan_mask).sum()\n","\n","#     return loss\n","\n","\n","def calculate_loss(params, state, inputs, dropout_key, mask_data: bool = True):\n","    outputs = state.apply_fn(\n","        {\"params\": params},\n","        # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","        numeric_inputs=inputs[\"numeric\"],\n","        categorical_inputs=inputs[\"categorical\"].astype(jnp.int32),\n","        rngs={\"dropout\": dropout_key},\n","        deterministic=False,\n","        mask_data=mask_data,\n","    )\n","    loss = base_loss(inputs, outputs)\n","    # Create mask for nan inputs\n","\n","    return loss\n","\n","\n","@jax.jit\n","def train_step(state: train_state.TrainState, batch, base_key, mask_data=True):\n","    dropout_key, mask_key, new_key = jax.random.split(\n","        base_key, 3\n","    )  # TODO Figure out mask key\n","\n","    def calculate_loss_with_mask(params):\n","        return calculate_loss(params, state, batch, dropout_key, mask_data=True)\n","\n","    def calculate_loss_without_mask(params):\n","        return calculate_loss(params, state, batch, dropout_key, mask_data=False)\n","\n","    def loss_fn(params):\n","        return jax.lax.cond(\n","            mask_data,\n","            lambda _: calculate_loss_with_mask(params),\n","            lambda _: calculate_loss_without_mask(params),\n","            operand=None,\n","        )\n","\n","    # def loss_fn(params):\n","    #     return calculate_loss(params, state, batch, dropout_key, mask_data=mask_data)\n","\n","    grad_fn = jax.value_and_grad(loss_fn)\n","\n","    # (loss, individual_losses), grad = grad_fn(state.params)\n","    loss, grad = grad_fn(state.params)\n","    # grad = replace_nans(grad)\n","    # grad = clip_gradients(grad, 1.0)\n","    state = state.apply_gradients(grads=grad)\n","\n","    return state, loss, new_key\n","\n","\n","def evaluate(params, state, inputs, mask_data: bool = True):\n","    outputs = state.apply_fn(\n","        {\"params\": params},\n","        # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","        inputs,\n","        deterministic=True,\n","        mask_data=mask_data,\n","    )\n","    loss = base_loss(inputs, outputs)\n","    return loss\n","\n","\n","@jax.jit\n","def eval_step(state: train_state.TrainState, batch, base_key, mask_data=True):\n","    mask_key, dropout_key, new_key = jax.random.split(base_key, 3)\n","\n","    def calculate_loss_with_mask(params):\n","        return calculate_loss(params, state, batch, dropout_key, mask_data=True)\n","\n","    def calculate_loss_without_mask(params):\n","        return calculate_loss(params, state, batch, dropout_key, mask_data=False)\n","\n","    def loss_fn(params):\n","        return jax.lax.cond(\n","            mask_data,\n","            lambda _: calculate_loss_with_mask(params),\n","            lambda _: calculate_loss_without_mask(params),\n","            operand=None,\n","        )\n","\n","    # def loss_fn(params):\n","    #     return evaluate(params, state, batch, mask_data=mask_data)\n","\n","    # (loss, individual_losses), grad = grad_fn(state.params)\n","    loss = loss_fn(state.params)\n","    return loss, new_key\n","\n","\n","def create_train_state(model, prng, batch, lr):\n","    init_key, dropout_key = random.split(prng)\n","    params = model.init(\n","        {\"params\": init_key, \"dropout\": dropout_key},\n","        batch[\"numeric\"],\n","        batch[\"categorical\"],\n","        deterministic=False,\n","    )\n","    # optimizer = optax.chain(optax.adam(lr))\n","    optimizer = optax.chain(optax.clip_by_global_norm(0.4), optax.adam(lr))\n","    # optimizer_state = optimizer.init(params)\n","    return train_state.TrainState.create(\n","        apply_fn=model.apply,\n","        params=params[\"params\"],\n","        tx=optimizer,\n","        # tx_state=optimizer_state,\n","    )\n","\n","\n","batch_size = 2\n","# batch = train_ds[0]\n","# state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)\n","state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a9a6098eb754ce2acc1de24034f3b28","version_major":2,"version_minor":0},"text/plain":["epochs for runs/2024-08-13T02:02:24BERT_Embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce2b4533b8d64436b4f487d909715862","version_major":2,"version_minor":0},"text/plain":["batches:   0%|          | 0/6250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'flax.training.train_state.TrainState'>\n"]},{"name":"stderr","output_type":"stream","text":["/home/ubuntu/environment/Hephaestus/hephaestus/models/simple_time_series.py:134: RuntimeWarning: invalid value encountered in cast\n","  batch = np.array(batch, dtype=np.int32)\n"]},{"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 16) + inhomogeneous part.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(train_data_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatches\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# for i in trange(len(pre_train) // batch_size, leave=False):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# for i in trange(len(pre_train) // batch_size //10, leave=False):\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# batch = make_batch(train_ds, i[0], 4)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     state, loss, base_key \u001b[38;5;241m=\u001b[39m train_step(\n\u001b[0;32m---> 32\u001b[0m         state, \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m, base_key, mask_data\u001b[38;5;241m=\u001b[39mMASK_DATA\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39misnan(loss):\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNan Value in loss, stopping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2174\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   2167\u001b[0m out: ArrayLike\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(leaf, Array) \u001b[38;5;28;01mfor\u001b[39;00m leaf \u001b[38;5;129;01min\u001b[39;00m leaves):\n\u001b[1;32m   2170\u001b[0m   \u001b[38;5;66;03m# TODO(jakevdp): falling back to numpy here fails to overflow for lists\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m   \u001b[38;5;66;03m# containing large integers; see discussion in\u001b[39;00m\n\u001b[1;32m   2172\u001b[0m   \u001b[38;5;66;03m# https://github.com/google/jax/pull/6047. More correct would be to call\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m   \u001b[38;5;66;03m# coerce_to_array on each leaf, but this may have performance implications.\u001b[39;00m\n\u001b[0;32m-> 2174\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, Array):\n\u001b[1;32m   2176\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39maval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 16) + inhomogeneous part."]}],"source":["writer_name = \"BERT_Embeddings\"\n","\n","writer_time = dt.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n","model_name = writer_time + writer_name\n","train_summary_writer = SummaryWriter(\"runs/\" + model_name)\n","\n","MASK_DATA = True\n","\n","test_set_key = random.PRNGKey(4454)\n","\n","batch_size = 16\n","train_data_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","test_data_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n","\n","# train_data_loader = DataLoader(train_ds, batch_size=256 // 2, shuffle=True)\n","# test_data_loader = DataLoader(test_ds, batch_size=256 // 2, shuffle=True)\n","\n","batch_count = 0\n","base_key = random.PRNGKey(42)\n","\n","# Disable IC for training\n","max_iters = 200\n","ic.disable()\n","for j in trange(1, desc=f\"epochs for {train_summary_writer.log_dir}\"):\n","    # arrs = train_data_loader()\n","    for i in tqdm(train_data_loader, leave=False, desc=\"batches\"):\n","        # for i in trange(len(pre_train) // batch_size, leave=False):\n","        # for i in trange(len(pre_train) // batch_size //10, leave=False):\n","        # batch = make_batch(train_ds, i[0], 4)\n","        print(f\"{type(state)}\")\n","        state, loss, base_key = train_step(\n","            state, jnp.array(i), base_key, mask_data=MASK_DATA\n","        )\n","        if jnp.isnan(loss):\n","            raise ValueError(\"Nan Value in loss, stopping\")\n","        batch_count += 1\n","\n","        if batch_count % 1 == 0:\n","            train_summary_writer.add_scalar(\n","                \"loss/loss\", np.array(loss.item()), batch_count\n","            )\n","        if batch_count % 10 == 0:\n","            test_loss, base_key = eval_step(\n","                state,\n","                jnp.array(next(iter(test_data_loader))),\n","                base_key,\n","                mask_data=MASK_DATA,\n","            )\n","            train_summary_writer.add_scalar(\n","                \"loss/test_loss\", np.array(test_loss.item()), batch_count\n","            )\n","            train_summary_writer.flush()\n","        # if batch_count > 200:\n","        #     break\n","        if batch_count > max_iters:\n","            break\n","\n","train_summary_writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import orbax.checkpoint\n","from flax.training import orbax_utils\n","\n","# Save the model\n","ckpt_dir = f\"ckpts/{model_name}/\"\n","# make absolute path\n","ckpt_dir = os.path.abspath(ckpt_dir)\n","\n","# if os.path.exists(ckpt_dir):\n","#     shutil.rmtree(ckpt_dir)\n","\n","ckpt = {\"state\": state, \"step\": batch_count}\n","# Save to disk\n","orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n","save_args = orbax_utils.save_args_from_target(ckpt)\n","orbax_checkpointer.save(ckpt_dir, ckpt, save_args=save_args)\n","\n","new_state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)\n","# Load from disk\n","ckpt1 = orbax_checkpointer.restore(ckpt_dir)\n","new_state = new_state.replace(params=ckpt1[\"state\"][\"params\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_name = \"2024-06-13T03:10:09MAE_Loss_Large\"\n","ckpt_dir = f\"ckpts/{model_name}/\"\n","# make absolute path\n","ckpt_dir = os.path.abspath(ckpt_dir)\n","new_state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)\n","# Load from disk\n","orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n","\n","ckpt1 = orbax_checkpointer.restore(ckpt_dir)\n","new_state = new_state.replace(params=ckpt1[\"state\"][\"params\"])\n","# state = new_state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def return_results(state, dataset, idx=0, mask_start: int = None):\n","    inputs = dataset[idx]\n","    if mask_start:\n","        inputs = inputs[:, :mask_start]\n","    inputs = jnp.array([inputs])\n","    outputs = state.apply_fn(\n","        {\"params\": state.params},\n","        # hp.mask_tensor(jnp.array([train_ds[0]]), dataset, prng_key=key),\n","        inputs,\n","        deterministic=True,\n","        mask_data=MASK_DATA,\n","    )\n","    return outputs, inputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mask_data = False\n","MASK_DATA = True\n","\n","\n","def show_results_df(state, base_df, dataset, idx: int = 0, mask_start: int = None):\n","    outputs, inputs = return_results(state, dataset, idx=idx, mask_start=mask_start)\n","\n","    outputs = jnp.squeeze(outputs)\n","    df_pred = pd.DataFrame(outputs.T)\n","    df_pred.columns = base_df.columns[1:]\n","\n","    inputs = jnp.squeeze(inputs)\n","    df_actual_masked = pd.DataFrame(inputs.T)\n","    df_actual_masked.columns = base_df.columns[1:]\n","    # remove the first row to match the prediction\n","    # df_actual_masked = df_actual_masked.iloc[1:].reset_index()\n","    diff_df = df_pred - df_actual_masked\n","\n","    inputs_no_mask = jnp.array([dataset[idx]])\n","    df_no_mask = pd.DataFrame(jnp.squeeze(inputs_no_mask).T)\n","    df_no_mask.columns = base_df.columns[1:]\n","    # df_no_mask = df_no_mask.iloc[1:].reset_index()  # rm first row\n","    diff_df_no_mask = df_pred - df_no_mask\n","    return {\n","        \"pred\": df_pred,\n","        \"actual_masked\": df_actual_masked,\n","        \"actual_no_mask\": df_no_mask,\n","        \"diff_masked\": diff_df,\n","        \"diff_no_mask\": diff_df_no_mask,\n","    }\n","\n","\n","res = show_results_df(new_state, train_df, train_ds, idx=0, mask_start=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_heatmap(df, title):\n","    \"\"\"Shows heatmap for a dataframe\n","    excludes all columns that are only nan and all rows that are only nan\"\"\"\n","\n","    df = df.dropna(axis=1, how=\"all\")\n","    df = df.dropna(axis=0, how=\"all\")\n","    plt.figure(figsize=(15, 10))\n","    cmap = sns.diverging_palette(220, 20, as_cmap=True)\n","    sns.heatmap(df, cmap=cmap, center=0, annot=True, fmt=\".2f\")\n","    plt.title(title)\n","    plt.show()\n","\n","\n","show_heatmap(res[\"diff_masked\"], \"Diff Masked\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_heatmap(res[\"diff_no_mask\"].head(14), \"Diff Masked\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_key = random.PRNGKey(4454)\n","x = jax.random.normal(test_key, (4, 26, 59, 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["no_mask_out = state.apply_fn(\n","    {\"params\": state.params},\n","    # jnp.array([test_ds[0][:10, :]]),\n","    jnp.array([test_ds[0][:, :10]]),\n","    deterministic=True,\n","    mask_data=True,\n",")\n","mask_out = state.apply_fn(\n","    {\"params\": state.params},\n","    jnp.array([test_ds[0][:, :20]]),\n","    deterministic=True,\n","    mask_data=True,\n",")\n","mask_out_df = pd.DataFrame(jnp.squeeze(mask_out).T)\n","mask_out_df.columns = test_df.columns[1:]\n","no_mask_out_df = pd.DataFrame(jnp.squeeze(no_mask_out).T)\n","no_mask_out_df.columns = test_df.columns[1:]\n","\n","test_diff = mask_out_df - no_mask_out_df\n","test_diff"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_planets(df_pred: pd.DataFrame, df_actual: pd.DataFrame, column: str, offset=0):\n","    plt.figure(figsize=(15, 10))\n","    plt.plot(df_pred[column], label=\"Autogregressive\")\n","    plt.plot(df_actual[column], label=\"Actual\")\n","    plt.title(f\"{column} Predictions\")\n","    plt.legend()\n","    # Show ticks and grid lines every 1 step\n","    plt.xticks(np.arange(0, len(df_pred), 1))\n","    plt.grid()\n","    # add black line at 0 on the y axis to show the difference\n","    plt.axhline(0, color=\"black\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def auto_regressive_predictions(\n","    state: train_state.TrainState, inputs: jnp.ndarray\n",") -> np.ndarray:\n","    # get the first row that contains all nan vales\n","    # if nan_rows_start >= stop_idx:\n","    #     return inputs\n","    nan_columns = jnp.isnan(inputs).all(axis=1)\n","    outputs = state.apply_fn(\n","        {\"params\": state.params},\n","        jnp.array([inputs]),\n","        # jnp.array([inputs]),\n","        deterministic=True,\n","        mask_data=MASK_DATA,\n","    )\n","    outputs = jnp.squeeze(outputs)\n","    final_row = np.array(outputs[:, -1])\n","    final_row = final_row[:, None]\n","    inputs = jnp.concatenate([inputs, final_row], axis=1)\n","    inputs = np.array(inputs)\n","    inputs[nan_columns] = np.nan\n","    return inputs\n","    # return auto_regressive_predictions(state, inputs, stop_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_inputs = test_ds[300]\n","inputs_test = base_inputs[:, :10]\n","print(inputs_test.shape)\n","for i in trange(21):\n","    inputs_test = auto_regressive_predictions(state, inputs_test)\n","\n","# x = auto_regressive_predictions(state, test_ds[0], 10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_auto = pd.DataFrame(inputs_test.T)\n","df_actual = pd.DataFrame(base_inputs.T)\n","df_auto.columns = train_df.columns[1:]\n","df_actual.columns = train_df.columns[1:]\n","df_diff = df_auto - df_actual\n","\n","# Drop rows that are all nan\n","df_diff = df_diff.dropna(axis=0, how=\"all\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_planets(df_auto, df_actual, \"time_step\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_planets(df_auto, df_actual, \"planet3_x\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# inputs = jnp.array(next(iter(test_data_loader)))\n","inputs_test = make_batch(test_ds, 0, 1)\n","\n","outputs = new_state.apply_fn(\n","    {\"params\": state.params},\n","    # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","    inputs_test,\n","    deterministic=True,\n","    mask_data=True,\n",")\n","df_actual = pd.DataFrame(jnp.squeeze(inputs_test).T)\n","df_actual.columns = test_df.columns[1:]\n","\n","df_pred = pd.DataFrame(jnp.squeeze(outputs).T)\n","df_pred.columns = test_df.columns[1:]\n","plot_planets(df_pred, df_actual, \"time_step\")\n","plot_planets(df_pred, df_actual, \"planet2_y\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputs_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_heatmap(df_diff, \"Auto Regressive Predictions\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot planet0_x from df_auto and df_actual\n","\n","\n","res = show_results_df(state, train_df, train_ds, idx=299, mask_start=20)\n","plot_planets(res[\"pred\"], res[\"actual_masked\"], \"planet2_y\", offset=0)\n","# plot_planets(df_auto, df_actual, \"planet2_y\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot planet0_x from df_auto and df_actual\n","res = show_results_df(state, train_df, train_ds, idx=20, mask_start=20)\n","plot_planets(res[\"pred\"], res[\"actual_no_mask\"], \"planet1_y\", offset=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res = show_results_df(state, train_df, test_ds, idx=0, mask_start=30)\n","\n","plot_planets(res[\"pred\"], res[\"actual_masked\"], \"planet2_x\", offset=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, key = eval_step(state, jnp.array(next(iter(test_data_loader))), base_key)\n","loss, key"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP1swsXnq2jqt/Hz4IBTZm2","gpuType":"V100","machine_shape":"hm","mount_file_id":"1zHmvVqlKJh0x9vjCRSkYKkko5buvMMEd","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01ca2dcb14e647dfb1e68750ca6de39c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a51aa7b827db4f768dce6315dbebf379","IPY_MODEL_634935ff0a6b4d65b72f87359d9f82fc","IPY_MODEL_09b63c98bee543dfb557a007d50c41d1"],"layout":"IPY_MODEL_dc4a8a3b0a8b4ef49dcd6269a1b32e14"}},"0481743e80634f7a8e718fb528950e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"055681c8159b4b6c8104d4e06279803c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b63c98bee543dfb557a007d50c41d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb36a08ca1540228919af722727572c","placeholder":"​","style":"IPY_MODEL_3bd47d84fac442d4bcf49dceeb699d45","value":" 807/807 [04:29&lt;00:00,  3.10it/s]"}},"0e26d28846fb449789510e4748c01c6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ce5408138f4cb28e163f1fdffdee5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b35a70a3b9e4f3b87cf2a7280439ac6","placeholder":"​","style":"IPY_MODEL_0e26d28846fb449789510e4748c01c6a","value":"100%"}},"2ac0cceac38e43adb00a10b778fad2df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddb1791795134ac0a754748f9793c214","placeholder":"​","style":"IPY_MODEL_d95aea2b915b44f38b5090ee186abafd","value":" 807/807 [04:31&lt;00:00,  2.80it/s]"}},"2fb36a08ca1540228919af722727572c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d37adf891a4da68675945509051210":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_055681c8159b4b6c8104d4e06279803c","placeholder":"​","style":"IPY_MODEL_9f5e5843559b4f9e8f3440ebd85743f8","value":" 807/807 [04:52&lt;00:00,  3.03it/s]"}},"3bd47d84fac442d4bcf49dceeb699d45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4151c7353de54909aa9deecbe8c1e1e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"462d9e93a94f44868fec1ece82f0a241":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47793d3155614c8cbd7d3337dcb2f895":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8093c8ddeec4c55ac6cc5f8f7df30bf","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4151c7353de54909aa9deecbe8c1e1e1","value":3}},"4bc81f6d94394d7f90e070d8b11a7059":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da9993585914618a35d8d5382fef850":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4dd64f565fcf4b259ef24944493477bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25ce5408138f4cb28e163f1fdffdee5f","IPY_MODEL_47793d3155614c8cbd7d3337dcb2f895","IPY_MODEL_f9ec11073e484927a4cc1ee2e3da132f"],"layout":"IPY_MODEL_62e750769d364ab2b80d5b9646b10ea6"}},"5e15315a77864badafe48c2baf31b030":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd9dd713862479bba73b6c0a12a1902","IPY_MODEL_88be535ce5a945f4979fe72d9f086365","IPY_MODEL_31d37adf891a4da68675945509051210"],"layout":"IPY_MODEL_4da9993585914618a35d8d5382fef850"}},"5edd903b07594d128ded9b4844835159":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bc81f6d94394d7f90e070d8b11a7059","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3bc58d04d5f42a5a24bd467a9569e01","value":807}},"5f1fb4d40e154e27baa0d4f330df540e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e750769d364ab2b80d5b9646b10ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"634935ff0a6b4d65b72f87359d9f82fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4de75777bba4d72b61936baf3d84cbb","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0481743e80634f7a8e718fb528950e54","value":807}},"6f5ca39406174a4fb1bee9eb1e35fccb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70c7b641da5c4b82bbd5b2e1750f3b39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851b29291123491a821b1ce8088ca785":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88be535ce5a945f4979fe72d9f086365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8382d8bbb7f42f6a0f4d4028203615f","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_851b29291123491a821b1ce8088ca785","value":807}},"8b35a70a3b9e4f3b87cf2a7280439ac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"948787e6434f419a86d9d7da831e2572":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ced4485d5c641eda90ab0634e0691d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f5e5843559b4f9e8f3440ebd85743f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a317a54aa1a349f490e388aacb2d1e4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c470a61e692a4459988f63f0024f7eac","IPY_MODEL_5edd903b07594d128ded9b4844835159","IPY_MODEL_2ac0cceac38e43adb00a10b778fad2df"],"layout":"IPY_MODEL_c7f61bdee3ca4ca0a3f7d021aa558deb"}},"a51aa7b827db4f768dce6315dbebf379":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f1fb4d40e154e27baa0d4f330df540e","placeholder":"​","style":"IPY_MODEL_948787e6434f419a86d9d7da831e2572","value":"100%"}},"acee2c1ed91e44188d5ca40bddace4b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c470a61e692a4459988f63f0024f7eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c7b641da5c4b82bbd5b2e1750f3b39","placeholder":"​","style":"IPY_MODEL_462d9e93a94f44868fec1ece82f0a241","value":"100%"}},"c7f61bdee3ca4ca0a3f7d021aa558deb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cc57eeb92d32434ca82b7c3f669865d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3bc58d04d5f42a5a24bd467a9569e01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d95aea2b915b44f38b5090ee186abafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc4a8a3b0a8b4ef49dcd6269a1b32e14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ddb1791795134ac0a754748f9793c214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd9dd713862479bba73b6c0a12a1902":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acee2c1ed91e44188d5ca40bddace4b1","placeholder":"​","style":"IPY_MODEL_cc57eeb92d32434ca82b7c3f669865d1","value":"100%"}},"e4de75777bba4d72b61936baf3d84cbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8093c8ddeec4c55ac6cc5f8f7df30bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8382d8bbb7f42f6a0f4d4028203615f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9ec11073e484927a4cc1ee2e3da132f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ced4485d5c641eda90ab0634e0691d3","placeholder":"​","style":"IPY_MODEL_6f5ca39406174a4fb1bee9eb1e35fccb","value":" 3/3 [13:53&lt;00:00, 275.36s/it]"}}}}},"nbformat":4,"nbformat_minor":0}
