{"cells":[{"cell_type":"markdown","metadata":{"id":"trbcfMV6vked"},"source":["<https://github.com/PolymathicAI/xVal>\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"yKsx1R26dLGC"},"outputs":[],"source":["import os\n","\n","os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Jqmm_5s9KXkI"},"outputs":[],"source":["import icecream\n","from icecream import ic\n","\n","icecream.install()\n","ic_disable = False  # Global variable to disable ic\n","if ic_disable:\n","    ic.disable()\n","ic.configureOutput(includeContext=True, contextAbsPath=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18045,"status":"ok","timestamp":1708903436762,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"oSKniUdxtiTd","outputId":"49871258-6ef7-4956-ad3b-90af827f7253"},"outputs":[],"source":["import ast\n","import re\n","from flax.struct import dataclass\n","from datetime import datetime as dt\n","from torch.utils.data import DataLoader\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import hephaestus as hp\n","import jax\n","import jax.numpy as jnp\n","import numpy as np\n","import optax\n","from flax.training import orbax_utils\n","import orbax.checkpoint\n","import orbax\n","import pandas as pd\n","from flax.training import train_state\n","from icecream import ic\n","from jax import random\n","from jax.tree_util import tree_flatten\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.notebook import tqdm, trange\n","from hephaestus.models.time_series_decoder import SimpleDS\n","\n","pd.options.mode.copy_on_write = True"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'bias'), ('pooler', 'dense', 'kernel')}\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["(3, 768)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import FlaxBertModel, BertTokenizerFast\n","import jax.numpy as jnp\n","\n","# Load pre-trained BERT model and tokenizer\n","model_name = \"bert-base-uncased\"\n","model = FlaxBertModel.from_pretrained(model_name)\n","tokenizer = BertTokenizerFast.from_pretrained(model_name)\n","\n","# Get the embeddings matrix\n","embeddings = model.params[\"embeddings\"][\"word_embeddings\"][\"embedding\"]\n","\n","# Now you can access specific embeddings like this:\n","# For example, to get embeddings for tokens 23, 293, and 993:\n","selected_embeddings = jnp.take(embeddings, jnp.array([23, 293, 993]), axis=0)\n","\n","# If you want to get embeddings for specific words:\n","words = [\"hello\", \"world\", \"example\"]\n","tokens = tokenizer.convert_tokens_to_ids(words)\n","word_embeddings = jnp.take(embeddings, jnp.array(tokens), axis=0)\n","word_embeddings.shape"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(3, 768)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["embeddings[jnp.array([23, 293, 993])].shape"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def line2df(line, idx):\n","    data_rows = []\n","    line = ast.literal_eval(line)\n","    for i, time_step in enumerate(line[\"data\"]):\n","        row = {\"time_step\": i}\n","        # Add position data for each planet\n","        for j, position in enumerate(time_step):\n","            row[f\"planet{j}_x\"] = position[0]\n","            row[f\"planet{j}_y\"] = position[1]\n","        data_rows.append(row)\n","\n","    df = pd.DataFrame(data_rows)\n","    description = line.pop(\"description\")\n","    step_size = description.pop(\"stepsize\")\n","    for k, v in description.items():\n","        for k_prop, v_prop in v.items():\n","            df[f\"{k}_{k_prop}\"] = v_prop\n","    df[\"time_step\"] = df[\"time_step\"] * step_size\n","    df.insert(0, \"idx\", idx)\n","\n","    return df"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>...</th>\n","      <th>planet3_y</th>\n","      <th>planet3_m</th>\n","      <th>planet3_a</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","      <th>total_mass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>4.165044e+06</td>\n","      <td>4.165044e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>5.563957e+06</td>\n","      <td>...</td>\n","      <td>2.783627e+06</td>\n","      <td>2.783627e+06</td>\n","      <td>2.783627e+06</td>\n","      <td>2.783627e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>1.392864e+06</td>\n","      <td>5.563957e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>6.248635e+04</td>\n","      <td>9.748911e+00</td>\n","      <td>-1.339198e-01</td>\n","      <td>7.391138e-02</td>\n","      <td>-1.340140e-01</td>\n","      <td>7.291389e-02</td>\n","      <td>-1.305344e-01</td>\n","      <td>7.065633e-02</td>\n","      <td>2.999306e+00</td>\n","      <td>1.624756e+00</td>\n","      <td>...</td>\n","      <td>6.559150e-02</td>\n","      <td>2.996303e+00</td>\n","      <td>1.623874e+00</td>\n","      <td>9.980576e-01</td>\n","      <td>-1.276881e-01</td>\n","      <td>6.519469e-02</td>\n","      <td>3.002531e+00</td>\n","      <td>1.625815e+00</td>\n","      <td>1.001317e+00</td>\n","      <td>1.049149e+01</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.607949e+04</td>\n","      <td>5.993534e+00</td>\n","      <td>1.228071e+00</td>\n","      <td>1.213232e+00</td>\n","      <td>1.227950e+00</td>\n","      <td>1.212650e+00</td>\n","      <td>1.217229e+00</td>\n","      <td>1.203678e+00</td>\n","      <td>1.157182e+00</td>\n","      <td>5.876632e-01</td>\n","      <td>...</td>\n","      <td>1.200148e+00</td>\n","      <td>1.153190e+00</td>\n","      <td>5.270725e-01</td>\n","      <td>5.764675e-01</td>\n","      <td>1.211648e+00</td>\n","      <td>1.199625e+00</td>\n","      <td>1.156856e+00</td>\n","      <td>5.167198e-01</td>\n","      <td>5.779763e-01</td>\n","      <td>3.991780e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-3.294763e+00</td>\n","      <td>-2.997514e+00</td>\n","      <td>-3.284004e+00</td>\n","      <td>-2.998546e+00</td>\n","      <td>-3.289790e+00</td>\n","      <td>-2.998050e+00</td>\n","      <td>1.000003e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>...</td>\n","      <td>-2.997621e+00</td>\n","      <td>1.000054e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>9.369537e-05</td>\n","      <td>-3.273603e+00</td>\n","      <td>-2.998913e+00</td>\n","      <td>1.000103e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>6.720938e-05</td>\n","      <td>2.014597e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.124400e+04</td>\n","      <td>4.655172e+00</td>\n","      <td>-1.030131e+00</td>\n","      <td>-9.020907e-01</td>\n","      <td>-1.030516e+00</td>\n","      <td>-9.028009e-01</td>\n","      <td>-1.050662e+00</td>\n","      <td>-9.211662e-01</td>\n","      <td>1.993948e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>...</td>\n","      <td>-9.321272e-01</td>\n","      <td>1.996853e+00</td>\n","      <td>1.191548e+00</td>\n","      <td>4.980967e-01</td>\n","      <td>-1.071974e+00</td>\n","      <td>-9.394428e-01</td>\n","      <td>2.004240e+00</td>\n","      <td>1.215927e+00</td>\n","      <td>5.032645e-01</td>\n","      <td>7.282371e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>6.249100e+04</td>\n","      <td>9.523810e+00</td>\n","      <td>-1.542335e-01</td>\n","      <td>1.117099e-01</td>\n","      <td>-1.538916e-01</td>\n","      <td>1.099474e-01</td>\n","      <td>-1.525520e-01</td>\n","      <td>1.118031e-01</td>\n","      <td>2.994477e+00</td>\n","      <td>1.543047e+00</td>\n","      <td>...</td>\n","      <td>1.067355e-01</td>\n","      <td>3.001879e+00</td>\n","      <td>1.535683e+00</td>\n","      <td>9.955040e-01</td>\n","      <td>-1.507184e-01</td>\n","      <td>1.055276e-01</td>\n","      <td>3.000454e+00</td>\n","      <td>1.519040e+00</td>\n","      <td>1.003118e+00</td>\n","      <td>1.028205e+01</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>9.372800e+04</td>\n","      <td>1.440000e+01</td>\n","      <td>8.583344e-01</td>\n","      <td>9.784987e-01</td>\n","      <td>8.581045e-01</td>\n","      <td>9.783998e-01</td>\n","      <td>8.762358e-01</td>\n","      <td>9.912902e-01</td>\n","      <td>4.005747e+00</td>\n","      <td>2.020672e+00</td>\n","      <td>...</td>\n","      <td>9.956064e-01</td>\n","      <td>3.986406e+00</td>\n","      <td>1.969644e+00</td>\n","      <td>1.497746e+00</td>\n","      <td>8.906780e-01</td>\n","      <td>9.991220e-01</td>\n","      <td>4.003332e+00</td>\n","      <td>1.950518e+00</td>\n","      <td>1.503457e+00</td>\n","      <td>1.345633e+01</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.249990e+05</td>\n","      <td>2.400000e+01</td>\n","      <td>2.996370e+00</td>\n","      <td>2.999014e+00</td>\n","      <td>2.993319e+00</td>\n","      <td>2.999536e+00</td>\n","      <td>2.990464e+00</td>\n","      <td>2.998478e+00</td>\n","      <td>4.999994e+00</td>\n","      <td>2.999984e+00</td>\n","      <td>...</td>\n","      <td>3.000881e+00</td>\n","      <td>4.999990e+00</td>\n","      <td>2.999909e+00</td>\n","      <td>1.999957e+00</td>\n","      <td>2.985180e+00</td>\n","      <td>2.998936e+00</td>\n","      <td>4.999679e+00</td>\n","      <td>2.999497e+00</td>\n","      <td>1.999999e+00</td>\n","      <td>2.382455e+01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 28 columns</p>\n","</div>"],"text/plain":["                idx     time_step     planet0_x     planet0_y     planet1_x  \\\n","count  5.563957e+06  5.563957e+06  5.563957e+06  5.563957e+06  5.563957e+06   \n","mean   6.248635e+04  9.748911e+00 -1.339198e-01  7.391138e-02 -1.340140e-01   \n","std    3.607949e+04  5.993534e+00  1.228071e+00  1.213232e+00  1.227950e+00   \n","min    0.000000e+00  0.000000e+00 -3.294763e+00 -2.997514e+00 -3.284004e+00   \n","25%    3.124400e+04  4.655172e+00 -1.030131e+00 -9.020907e-01 -1.030516e+00   \n","50%    6.249100e+04  9.523810e+00 -1.542335e-01  1.117099e-01 -1.538916e-01   \n","75%    9.372800e+04  1.440000e+01  8.583344e-01  9.784987e-01  8.581045e-01   \n","max    1.249990e+05  2.400000e+01  2.996370e+00  2.999014e+00  2.993319e+00   \n","\n","          planet1_y     planet2_x     planet2_y     planet0_m     planet0_a  \\\n","count  5.563957e+06  4.165044e+06  4.165044e+06  5.563957e+06  5.563957e+06   \n","mean   7.291389e-02 -1.305344e-01  7.065633e-02  2.999306e+00  1.624756e+00   \n","std    1.212650e+00  1.217229e+00  1.203678e+00  1.157182e+00  5.876632e-01   \n","min   -2.998546e+00 -3.289790e+00 -2.998050e+00  1.000003e+00  1.000000e+00   \n","25%   -9.028009e-01 -1.050662e+00 -9.211662e-01  1.993948e+00  1.000000e+00   \n","50%    1.099474e-01 -1.525520e-01  1.118031e-01  2.994477e+00  1.543047e+00   \n","75%    9.783998e-01  8.762358e-01  9.912902e-01  4.005747e+00  2.020672e+00   \n","max    2.999536e+00  2.990464e+00  2.998478e+00  4.999994e+00  2.999984e+00   \n","\n","       ...     planet3_y     planet3_m     planet3_a     planet3_e  \\\n","count  ...  2.783627e+06  2.783627e+06  2.783627e+06  2.783627e+06   \n","mean   ...  6.559150e-02  2.996303e+00  1.623874e+00  9.980576e-01   \n","std    ...  1.200148e+00  1.153190e+00  5.270725e-01  5.764675e-01   \n","min    ... -2.997621e+00  1.000054e+00  1.000000e+00  9.369537e-05   \n","25%    ... -9.321272e-01  1.996853e+00  1.191548e+00  4.980967e-01   \n","50%    ...  1.067355e-01  3.001879e+00  1.535683e+00  9.955040e-01   \n","75%    ...  9.956064e-01  3.986406e+00  1.969644e+00  1.497746e+00   \n","max    ...  3.000881e+00  4.999990e+00  2.999909e+00  1.999957e+00   \n","\n","          planet4_x     planet4_y     planet4_m     planet4_a     planet4_e  \\\n","count  1.392864e+06  1.392864e+06  1.392864e+06  1.392864e+06  1.392864e+06   \n","mean  -1.276881e-01  6.519469e-02  3.002531e+00  1.625815e+00  1.001317e+00   \n","std    1.211648e+00  1.199625e+00  1.156856e+00  5.167198e-01  5.779763e-01   \n","min   -3.273603e+00 -2.998913e+00  1.000103e+00  1.000000e+00  6.720938e-05   \n","25%   -1.071974e+00 -9.394428e-01  2.004240e+00  1.215927e+00  5.032645e-01   \n","50%   -1.507184e-01  1.055276e-01  3.000454e+00  1.519040e+00  1.003118e+00   \n","75%    8.906780e-01  9.991220e-01  4.003332e+00  1.950518e+00  1.503457e+00   \n","max    2.985180e+00  2.998936e+00  4.999679e+00  2.999497e+00  1.999999e+00   \n","\n","         total_mass  \n","count  5.563957e+06  \n","mean   1.049149e+01  \n","std    3.991780e+00  \n","min    2.014597e+00  \n","25%    7.282371e+00  \n","50%    1.028205e+01  \n","75%    1.345633e+01  \n","max    2.382455e+01  \n","\n","[8 rows x 28 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["files = os.listdir(\"data\")\n","if \"planets.parquet\" not in files:\n","    with open(\"data/planets.data\") as f:\n","        data = f.read().splitlines()\n","\n","        dfs = []\n","        for idx, line in enumerate(tqdm(data)):\n","            dfs.append(line2df(line, idx))\n","        print(\"Concatenating dfs...\")\n","        df = pd.concat(dfs)\n","    df.to_parquet(\"data/planets.parquet\")\n","else:\n","    df = pd.read_parquet(\"data/planets.parquet\")\n","\n","\n","# Combine total mass of all planets into one column `planet<n>_m`\n","mass_regex = re.compile(r\"planet(\\d+)_m\")\n","mass_cols = [col for col in df.columns if mass_regex.match(col)]\n","df[\"total_mass\"] = df[mass_cols].sum(axis=1)\n","\n","# Introduce categorical columns for the number of planets choose non null columns with mass\n","df[\"n_planets\"] = df[mass_cols].notnull().sum(axis=1).astype(\"category\")\n","# Create category acceleration if the sum of plane/d_[x,y, z] is greater than 0\n","df[\"acceleration_x\"] = df[\n","    [col for col in df.columns if \"planet\" in col and \"_x\" in col]\n","].sum(axis=1)\n","# Set acceleration_x to \"increasing\" if greater than 0 else \"decreasing\"\n","df[\"acceleration_x\"] = df[\"acceleration_x\"].apply(\n","    lambda x: \"increasing\" if x > 0 else \"decreasing\"\n",")\n","df[\"acceleration_y\"] = df[\n","    [col for col in df.columns if \"planet\" in col and \"_y\" in col]\n","].sum(axis=1)\n","df[\"acceleration_y\"] = df[\"acceleration_y\"].apply(\n","    lambda x: \"increasing\" if x > 0 else \"decreasing\"\n",")\n","\n","\n","df.describe()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"4RZof2SNKXkK"},"outputs":[{"data":{"text/plain":["(99999, 25001)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Get train test split at 80/20\n","train_idx = int(df.idx.max() * 0.8)\n","train_df = df.loc[df.idx < train_idx].copy()\n","test_df = df.loc[df.idx >= train_idx].copy()\n","# del df\n","train_ds = SimpleDS(train_df)\n","test_ds = SimpleDS(test_df)\n","len(train_ds), len(test_ds)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>...</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","      <th>total_mass</th>\n","      <th>n_planets</th>\n","      <th>acceleration_x</th>\n","      <th>acceleration_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>-0.274094</td>\n","      <td>1.658928</td>\n","      <td>-1.598680</td>\n","      <td>1.237278</td>\n","      <td>-0.072378</td>\n","      <td>1.334127</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.733333</td>\n","      <td>-0.810119</td>\n","      <td>1.516448</td>\n","      <td>-1.860540</td>\n","      <td>0.797326</td>\n","      <td>-0.675005</td>\n","      <td>1.164327</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1.466667</td>\n","      <td>-1.261577</td>\n","      <td>1.214381</td>\n","      <td>-2.002381</td>\n","      <td>0.305935</td>\n","      <td>-1.131812</td>\n","      <td>0.742120</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2.200000</td>\n","      <td>-1.587840</td>\n","      <td>0.791168</td>\n","      <td>-2.015313</td>\n","      <td>-0.205141</td>\n","      <td>-1.347517</td>\n","      <td>0.161522</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>increasing</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2.933333</td>\n","      <td>-1.762252</td>\n","      <td>0.291976</td>\n","      <td>-1.898518</td>\n","      <td>-0.702988</td>\n","      <td>-1.278262</td>\n","      <td>-0.453284</td>\n","      <td>3.092371</td>\n","      <td>1.67039</td>\n","      <td>...</td>\n","      <td>0.265969</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.247159</td>\n","      <td>4</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>25000</td>\n","      <td>18.139535</td>\n","      <td>0.859903</td>\n","      <td>-0.357431</td>\n","      <td>-1.780663</td>\n","      <td>-0.841087</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>25000</td>\n","      <td>18.604651</td>\n","      <td>0.917215</td>\n","      <td>0.133881</td>\n","      <td>-1.609198</td>\n","      <td>-1.111904</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>25000</td>\n","      <td>19.069767</td>\n","      <td>0.732278</td>\n","      <td>0.590216</td>\n","      <td>-1.391311</td>\n","      <td>-1.350590</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>25000</td>\n","      <td>19.534884</td>\n","      <td>0.360838</td>\n","      <td>0.898121</td>\n","      <td>-1.132250</td>\n","      <td>-1.549225</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>25000</td>\n","      <td>20.000000</td>\n","      <td>-0.096652</td>\n","      <td>0.996967</td>\n","      <td>-0.838645</td>\n","      <td>-1.700474</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.983244</td>\n","      <td>1.00000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7.554701</td>\n","      <td>2</td>\n","      <td>decreasing</td>\n","      <td>decreasing</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1110975 rows × 31 columns</p>\n","</div>"],"text/plain":["      idx  time_step  planet0_x  planet0_y  planet1_x  planet1_y  planet2_x  \\\n","0       0   0.000000  -0.274094   1.658928  -1.598680   1.237278  -0.072378   \n","1       0   0.733333  -0.810119   1.516448  -1.860540   0.797326  -0.675005   \n","2       0   1.466667  -1.261577   1.214381  -2.002381   0.305935  -1.131812   \n","3       0   2.200000  -1.587840   0.791168  -2.015313  -0.205141  -1.347517   \n","4       0   2.933333  -1.762252   0.291976  -1.898518  -0.702988  -1.278262   \n","..    ...        ...        ...        ...        ...        ...        ...   \n","39  25000  18.139535   0.859903  -0.357431  -1.780663  -0.841087        NaN   \n","40  25000  18.604651   0.917215   0.133881  -1.609198  -1.111904        NaN   \n","41  25000  19.069767   0.732278   0.590216  -1.391311  -1.350590        NaN   \n","42  25000  19.534884   0.360838   0.898121  -1.132250  -1.549225        NaN   \n","43  25000  20.000000  -0.096652   0.996967  -0.838645  -1.700474        NaN   \n","\n","    planet2_y  planet0_m  planet0_a  ...  planet3_e  planet4_x  planet4_y  \\\n","0    1.334127   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","1    1.164327   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","2    0.742120   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","3    0.161522   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","4   -0.453284   3.092371    1.67039  ...   0.265969        NaN        NaN   \n","..        ...        ...        ...  ...        ...        ...        ...   \n","39        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","40        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","41        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","42        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","43        NaN   2.983244    1.00000  ...        NaN        NaN        NaN   \n","\n","    planet4_m  planet4_a  planet4_e  total_mass  n_planets  acceleration_x  \\\n","0         NaN        NaN        NaN   10.247159          4      decreasing   \n","1         NaN        NaN        NaN   10.247159          4      decreasing   \n","2         NaN        NaN        NaN   10.247159          4      decreasing   \n","3         NaN        NaN        NaN   10.247159          4      decreasing   \n","4         NaN        NaN        NaN   10.247159          4      decreasing   \n","..        ...        ...        ...         ...        ...             ...   \n","39        NaN        NaN        NaN    7.554701          2      decreasing   \n","40        NaN        NaN        NaN    7.554701          2      decreasing   \n","41        NaN        NaN        NaN    7.554701          2      decreasing   \n","42        NaN        NaN        NaN    7.554701          2      decreasing   \n","43        NaN        NaN        NaN    7.554701          2      decreasing   \n","\n","    acceleration_y  \n","0       increasing  \n","1       increasing  \n","2       increasing  \n","3       increasing  \n","4       decreasing  \n","..             ...  \n","39      decreasing  \n","40      decreasing  \n","41      decreasing  \n","42      decreasing  \n","43      decreasing  \n","\n","[1110975 rows x 31 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["((1110975, 31), (4452982, 31))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_df.shape, train_df.shape"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["124999"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.idx.max()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[[ 0.        ,  0.4651163 ,  0.9302326 , ...,         nan,\n","                 nan,         nan],\n","        [ 1.5600603 ,  1.689858  ,  1.7535888 , ...,         nan,\n","                 nan,         nan],\n","        [-0.854437  , -0.5143588 , -0.15420859, ...,         nan,\n","                 nan,         nan],\n","        ...,\n","        [        nan,         nan,         nan, ...,         nan,\n","                 nan,         nan],\n","        [        nan,         nan,         nan, ...,         nan,\n","                 nan,         nan],\n","        [ 6.9741225 ,  6.9741225 ,  6.9741225 , ...,         nan,\n","                 nan,         nan]]], dtype=float32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["jnp.array([train_ds[0][0]])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def make_batch(ds: SimpleDS, start: int, length: int):\n","    numeric = []\n","    categorical = []\n","    for i in range(start, length + start):\n","        numeric.append(ds[i][0])\n","        categorical.append(ds[i][1])\n","    # print index of None values\n","    return {\"numeric\": jnp.array(numeric), \"categorical\": jnp.array(categorical)}\n","\n","\n","batch = make_batch(train_ds, 0, 4)\n","# batch"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Y4b7IkMWKXkK"},"outputs":[],"source":["# time_series_regressor = hp.simple_time_series.SimplePred(\n","#     train_ds, d_model=2048, n_heads=16 # large\n","# )\n","multiplier = 4\n","time_series_regressor = hp.time_series_decoder.SimplePred(\n","    train_ds, d_model=512, n_heads=8 * multiplier\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# train_ds.reservoir_encoded"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[    0,     0,     0,     0,     0,     0,     0,     0],\n","       [ 1031, 16371, 25531,  1035,  7308,  1033,     0,     0],\n","       [  103,     0,     0,     0,     0,     0,     0,     0],\n","       [ 4774,  2509,  1035,  1049,     0,     0,     0,     0]],      dtype=int32)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# train_ds.reservoir_encoded\n","train_ds.reservoir_encoded[jnp.array([0, 1, 2, 23])]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[[33., 33., 33., 33., 33., 33., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 33.,\n","         33., 33., 33., 33., 33., 33., 33., 33., nan, nan, nan, nan,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","        [33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n","         33., 33., 33., 33., 33., 33., 33., 33., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., nan, nan, nan, nan,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n","\n","       [[35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 33., 33.,\n","         33., 33., 33., 33., nan, nan, nan, nan, nan, nan, nan],\n","        [33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n","         33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n","         33., 33., 33., 33., 33., 33., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., nan, nan, nan, nan, nan, nan, nan]],\n","\n","       [[35., 35., 35., 35., 35., 35., 35., 35., 35., 33., 33., 33.,\n","         33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n","         33., 33., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 33., 33., 33.,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","        [35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 33., 33., 33., 33., 33., 33., 33., 33., 33., 33.,\n","         33., 33., 33., 33., 33., 33., 33., 33., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n","\n","       [[33., 33., 33., 33., 35., 35., 35., 35., 35., 35., 35., 35.,\n","         35., 35., 35., 33., 33., 33., 33., 33., 33., 33., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 35., 35., 35., nan, nan,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","        [35., 33., 33., 33., 33., 33., 33., 33., 35., 35., 35., 35.,\n","         35., 35., 35., 35., 35., 35., 35., 33., 33., 33., 33., 33.,\n","         33., 33., 33., 33., 33., 33., 33., 35., 35., 35., nan, nan,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],      dtype=float32)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["batch[\"categorical\"]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["Array([1, 2, 3, 4], dtype=int32)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["test_arr = jnp.array([1.0, 2.0, 3.0, 4.0])\n","# Convert to int\n","test_arr = test_arr.astype(jnp.int32)\n","test_arr"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ic| time_series_decoder.py:294 in __call__()\n","    numeric_inputs.shape: (4, 27, 59)\n","ic| time_series_decoder.py:296 in __call__()- 'Here Again???'\n","ic| time_series_decoder.py:551 in __call__()\n","    \"pe before tiling\": 'pe before tiling'\n","    pe.shape: (1, 59, 512, 1)\n","ic| time_series_decoder.py:553 in __call__()\n","    \"pe after tiling\": 'pe after tiling'\n","    pe.shape: (4, 59, 512, 27)\n","ic| time_series_decoder.py:555 in __call__()\n","    \"pe after transpose\": 'pe after transpose'\n","    pe.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:559 in __call__()\n","    \"PE Result shape\": 'PE Result shape'\n","    result.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:354 in __call__()\n","    numeric_broadcast.shape: (4, 27, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:366 in __call__()\n","    \"Masking for categorical data\": 'Masking for categorical data'\n","ic| time_series_decoder.py:372 in __call__()\n","    mask_input.shape: (4, 29, 59)\n","ic| time_series_decoder.py:379 in __call__()\n","    mask.shape: (4, 29, 1, 59, 59)\n","ic| time_series_decoder.py:383 in __call__()\n","    tabular_data.shape: (4, 29, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:386 in __call__()\n","    \"Concatenating Embeddings\": 'Concatenating Embeddings'\n","ic| time_series_decoder.py:387 in __call__()\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","    categorical_col_embeddings.shape: (4, 2, 59, 512)\n","ic| time_series_decoder.py:388 in __call__()\n","    numeric_col_embeddings.dtype: dtype('float32')\n","    categorical_col_embeddings.dtype: dtype('float32')\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:451 in __call__()\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:452 in __call__()\n","    f\"Nan values in simplePred out 1: {jnp.isnan(out).any()}\": 'Nan values in simplePred out 1: False'\n","ic| time_series_decoder.py:458 in __call__()\n","    numeric_out.shape: (4, 59, 14848)\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:472 in __call__()\n","    \"has categorical inputs\": 'has categorical inputs'\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:474 in __call__()\n","    \"After swap\": 'After swap'\n","    categorical_out.shape: (4, 59, 29, 512)\n","ic| time_series_decoder.py:478 in __call__()\n","    \"After reshape\": 'After reshape'\n","    categorical_out.shape: (4, 59, 14848)\n","ic| time_series_decoder.py:491 in __call__()\n","    numeric_out.shape: (4, 27, 59)\n","    categorical_out.shape: (4, 59, 2)\n","ic| time_series_decoder.py:493 in __call__()\n","    \"after swap\": 'after swap'\n","    numeric_out.shape: (4, 27, 59)\n","    categorical_out.shape: (4, 2, 59)\n"]}],"source":["key = random.PRNGKey(0)\n","init_key, dropout_key = random.split(key)\n","vars = time_series_regressor.init(\n","    {\"params\": init_key, \"dropout\": dropout_key},\n","    batch[\"numeric\"],\n","    categorical_inputs=batch[\"categorical\"].astype(jnp.int32),\n","    deterministic=False,\n",")\n","dropout_key, original_dropout_key = random.split(dropout_key)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["(5563957, 31)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# ic.disable()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ic| time_series_decoder.py:294 in __call__()\n","    numeric_inputs.shape: (4, 27, 59)\n","ic| time_series_decoder.py:296 in __call__()- 'Here Again???'\n","ic| time_series_decoder.py:551 in __call__()\n","    \"pe before tiling\": 'pe before tiling'\n","    pe.shape: (1, 59, 512, 1)\n","ic| time_series_decoder.py:553 in __call__()\n","    \"pe after tiling\": 'pe after tiling'\n","    pe.shape: (4, 59, 512, 27)\n","ic| time_series_decoder.py:555 in __call__()\n","    \"pe after transpose\": 'pe after transpose'\n","    pe.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:559 in __call__()\n","    \"PE Result shape\": 'PE Result shape'\n","    result.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:354 in __call__()\n","    numeric_broadcast.shape: (4, 27, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:366 in __call__()\n","    \"Masking for categorical data\": 'Masking for categorical data'\n","ic| time_series_decoder.py:372 in __call__()\n","    mask_input.shape: (4, 29, 59)\n","ic| time_series_decoder.py:379 in __call__()\n","    mask.shape: (4, 29, 1, 59, 59)\n","ic| time_series_decoder.py:383 in __call__()\n","    tabular_data.shape: (4, 29, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:386 in __call__()\n","    \"Concatenating Embeddings\": 'Concatenating Embeddings'\n","ic| time_series_decoder.py:387 in __call__()\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","    categorical_col_embeddings.shape: (4, 2, 59, 512)\n","ic| time_series_decoder.py:388 in __call__()\n","    numeric_col_embeddings.dtype: dtype('float32')\n","    categorical_col_embeddings.dtype: dtype('float32')\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:451 in __call__()\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:452 in __call__()\n","    f\"Nan values in simplePred out 1: {jnp.isnan(out).any()}\": 'Nan values in simplePred out 1: False'\n","ic| time_series_decoder.py:458 in __call__()\n","    numeric_out.shape: (4, 59, 14848)\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:472 in __call__()\n","    \"has categorical inputs\": 'has categorical inputs'\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:474 in __call__()\n","    \"After swap\": 'After swap'\n","    categorical_out.shape: (4, 59, 29, 512)\n","ic| time_series_decoder.py:478 in __call__()\n","    \"After reshape\": 'After reshape'\n","    categorical_out.shape: (4, 59, 14848)\n","ic| time_series_decoder.py:491 in __call__()\n","    numeric_out.shape: (4, 27, 59)\n","    categorical_out.shape: (4, 59, 2)\n","ic| time_series_decoder.py:493 in __call__()\n","    \"after swap\": 'after swap'\n","    numeric_out.shape: (4, 27, 59)\n","    categorical_out.shape: (4, 2, 59)\n"]},{"name":"stdout","output_type":"stream","text":["(4, 27, 59)\n","(4, 2, 59)\n"]}],"source":["x = time_series_regressor.apply(\n","    vars,\n","    batch[\"numeric\"],\n","    batch[\"categorical\"].astype(jnp.int32),\n","    deterministic=False,\n","    rngs={\"dropout\": dropout_key},\n",")\n","print(x.get(\"numeric_out\").shape)\n","# Check if categorical input is None and print None or it's shape\n","print(x.get(\"categorical_out\").shape if x.get(\"categorical_out\") is not None else None)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["2"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["len(train_ds.categorical_indices)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# time_series_regressor.tabulate(\n","#     {\"params\": init_key, \"dropout\": dropout_key},\n","#     batch[\"numeric\"],\n","#     console_kwargs={\"force_jupyter\": True, \"width\": 120},\n","# )"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory of custom: 202.17 MB with 50,542,877 parameters\n"]}],"source":["def calculate_memory_footprint(params):\n","    \"\"\"Calculate total memory footprint of JAX model parameters and total\n","    number of parameters.\"\"\"\n","    total_bytes = 0\n","    # Flatten the parameter tree structure into a list of arrays\n","    flat_params, _ = tree_flatten(params)\n","    for param in flat_params:\n","        # Calculate bytes: number of elements * size of each element\n","        bytes_per_param = param.size * param.dtype.itemsize\n","        total_bytes += bytes_per_param\n","    return total_bytes\n","\n","\n","def count_parameters(params):\n","    return sum(jnp.prod(jnp.array(p.shape)) for p in jax.tree_util.tree_leaves(params))\n","\n","\n","mem = calculate_memory_footprint(vars)\n","total_params = count_parameters(vars)\n","\n","\n","print(f\"Memory of custom: {mem / 1e6:.2f} MB with {total_params:,} parameters\")"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4dd64f565fcf4b259ef24944493477bf","25ce5408138f4cb28e163f1fdffdee5f","47793d3155614c8cbd7d3337dcb2f895","f9ec11073e484927a4cc1ee2e3da132f","62e750769d364ab2b80d5b9646b10ea6","8b35a70a3b9e4f3b87cf2a7280439ac6","0e26d28846fb449789510e4748c01c6a","f8093c8ddeec4c55ac6cc5f8f7df30bf","4151c7353de54909aa9deecbe8c1e1e1","9ced4485d5c641eda90ab0634e0691d3","6f5ca39406174a4fb1bee9eb1e35fccb","5e15315a77864badafe48c2baf31b030","dfd9dd713862479bba73b6c0a12a1902","88be535ce5a945f4979fe72d9f086365","31d37adf891a4da68675945509051210","4da9993585914618a35d8d5382fef850","acee2c1ed91e44188d5ca40bddace4b1","cc57eeb92d32434ca82b7c3f669865d1","f8382d8bbb7f42f6a0f4d4028203615f","851b29291123491a821b1ce8088ca785","055681c8159b4b6c8104d4e06279803c","9f5e5843559b4f9e8f3440ebd85743f8","a317a54aa1a349f490e388aacb2d1e4d","c470a61e692a4459988f63f0024f7eac","5edd903b07594d128ded9b4844835159","2ac0cceac38e43adb00a10b778fad2df","c7f61bdee3ca4ca0a3f7d021aa558deb","70c7b641da5c4b82bbd5b2e1750f3b39","462d9e93a94f44868fec1ece82f0a241","4bc81f6d94394d7f90e070d8b11a7059","d3bc58d04d5f42a5a24bd467a9569e01","ddb1791795134ac0a754748f9793c214","d95aea2b915b44f38b5090ee186abafd","01ca2dcb14e647dfb1e68750ca6de39c","a51aa7b827db4f768dce6315dbebf379","634935ff0a6b4d65b72f87359d9f82fc","09b63c98bee543dfb557a007d50c41d1","dc4a8a3b0a8b4ef49dcd6269a1b32e14","5f1fb4d40e154e27baa0d4f330df540e","948787e6434f419a86d9d7da831e2572","e4de75777bba4d72b61936baf3d84cbb","0481743e80634f7a8e718fb528950e54","2fb36a08ca1540228919af722727572c","3bd47d84fac442d4bcf49dceeb699d45"]},"executionInfo":{"elapsed":841688,"status":"ok","timestamp":1708904334771,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"RIXu3GkdYzNA","outputId":"dee6137d-c096-4df6-fbb4-baa3764d359e"},"outputs":[{"name":"stderr","output_type":"stream","text":["ic| time_series_decoder.py:294 in __call__()\n","    numeric_inputs.shape: (4, 27, 59)\n","ic| time_series_decoder.py:296 in __call__()- 'Here Again???'\n","ic| time_series_decoder.py:551 in __call__()\n","    \"pe before tiling\": 'pe before tiling'\n","    pe.shape: (1, 59, 512, 1)\n","ic| time_series_decoder.py:553 in __call__()\n","    \"pe after tiling\": 'pe after tiling'\n","    pe.shape: (4, 59, 512, 27)\n","ic| time_series_decoder.py:555 in __call__()\n","    \"pe after transpose\": 'pe after transpose'\n","    pe.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:559 in __call__()\n","    \"PE Result shape\": 'PE Result shape'\n","    result.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:354 in __call__()\n","    numeric_broadcast.shape: (4, 27, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:366 in __call__()\n","    \"Masking for categorical data\": 'Masking for categorical data'\n","ic| time_series_decoder.py:372 in __call__()\n","    mask_input.shape: (4, 29, 59)\n","ic| time_series_decoder.py:379 in __call__()\n","    mask.shape: (4, 29, 1, 59, 59)\n","ic| time_series_decoder.py:383 in __call__()\n","    tabular_data.shape: (4, 29, 59, 512)\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","ic| time_series_decoder.py:386 in __call__()\n","    \"Concatenating Embeddings\": 'Concatenating Embeddings'\n","ic| time_series_decoder.py:387 in __call__()\n","    numeric_col_embeddings.shape: (4, 27, 59, 512)\n","    categorical_col_embeddings.shape: (4, 2, 59, 512)\n","ic| time_series_decoder.py:388 in __call__()\n","    numeric_col_embeddings.dtype: dtype('float32')\n","    categorical_col_embeddings.dtype: dtype('float32')\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:186 in __call__()\n","    \"Query shapes 222222\": 'Query shapes 222222'\n","    q.shape: (4, 29, 59, 512)\n","    k.shape: (4, 29, 59, 512)\n","    v.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:451 in __call__()\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:452 in __call__()\n","    f\"Nan values in simplePred out 1: {jnp.isnan(out).any()}\": 'Nan values in simplePred out 1: False'\n","ic| time_series_decoder.py:458 in __call__()\n","    numeric_out.shape: (4, 59, 14848)\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:472 in __call__()\n","    \"has categorical inputs\": 'has categorical inputs'\n","    out.shape: (4, 29, 59, 512)\n","ic| time_series_decoder.py:474 in __call__()\n","    \"After swap\": 'After swap'\n","    categorical_out.shape: (4, 59, 29, 512)\n","ic| time_series_decoder.py:478 in __call__()\n","    \"After reshape\": 'After reshape'\n","    categorical_out.shape: (4, 59, 14848)\n","ic| time_series_decoder.py:491 in __call__()\n","    numeric_out.shape: (4, 27, 59)\n","    categorical_out.shape: (4, 59, 2)\n","ic| time_series_decoder.py:493 in __call__()\n","    \"after swap\": 'after swap'\n","    numeric_out.shape: (4, 27, 59)\n","    categorical_out.shape: (4, 2, 59)\n"]}],"source":["mts_root_key = random.PRNGKey(44)\n","mts_main_key, ts_params_key, ts_data_key = random.split(mts_root_key, 3)\n","\n","mask_data = False\n","\n","\n","def clip_gradients(gradients, max_norm):\n","    total_norm = jnp.sqrt(sum(jnp.sum(jnp.square(grad)) for grad in gradients.values()))\n","    scale = max_norm / (total_norm + 1e-6)\n","    clipped_gradients = jax.tree_map(\n","        lambda grad: jnp.where(total_norm > max_norm, grad * scale, grad), gradients\n","    )\n","    return clipped_gradients\n","\n","\n","def add_time_shifts(inputs: jnp.array, outputs: jnp.array) -> jnp.array:\n","    inputs_offset = 1\n","    inputs = inputs[:, :, inputs_offset:]\n","    tmp_null = jnp.full((inputs.shape[0], inputs.shape[1], inputs_offset), jnp.nan)\n","    inputs = jnp.concatenate([inputs, tmp_null], axis=2)\n","    nan_mask = jnp.isnan(inputs)\n","    inputs = jnp.where(nan_mask, jnp.zeros_like(inputs), inputs)\n","    print(f\"{outputs.shape=}, {inputs.shape=}\")\n","    outputs = jnp.where(nan_mask, jnp.zeros_like(outputs), outputs)\n","\n","    return inputs, outputs, nan_mask\n","\n","\n","def numeric_loss(inputs, outputs):\n","    inputs, outputs, nan_mask = add_time_shifts(inputs, outputs)\n","    # TODO make loss SSL for values greater than 0.5 and MSE for values less than 0.5\n","    raw_loss = jnp.abs(outputs - inputs)\n","    masked_loss = jnp.where(nan_mask, 0.0, raw_loss)\n","    loss = masked_loss.sum() / (~nan_mask).sum()\n","    return loss\n","\n","\n","def categorical_loss(inputs, outputs):\n","    inputs, outputs, nan_mask = add_time_shifts(inputs, outputs)\n","\n","    raw_loss = optax.squared_error(outputs, inputs)\n","    masked_loss = jnp.where(nan_mask, 0.0, raw_loss).mean()\n","    return masked_loss\n","\n","\n","def base_loss(\n","    numeric_inputs,\n","    categorical_inputs,\n","    outputs,\n","):\n","    numeric_out = outputs[\"numeric_out\"]\n","    categorical_out = outputs[\"categorical_out\"]\n","    print(\"Base Loss\", numeric_inputs.shape, numeric_out.shape)\n","    numeric = numeric_loss(numeric_inputs, numeric_out)\n","    categorical = categorical_loss(categorical_inputs, categorical_out)\n","    return numeric + categorical\n","\n","\n","def base_loss_old(inputs, outputs):\n","    \"\"\"TODO HERE IS THE SHIT\"\"\"\n","    # Remove the first value and add a jnp.nan to the end\n","    # inputs = inputs * 3\n","    inputs_offset = 1\n","    inputs = inputs[:, :, inputs_offset:]\n","    print(f\"Inputs shape: {inputs.shape=}\")\n","    # Add a jnp.nan to the end\n","    temp_null = jnp.full((inputs.shape[0], inputs.shape[1], inputs_offset), jnp.nan)\n","    inputs = jnp.concatenate([inputs, temp_null], axis=2)\n","    print(f\"Inputs shape after addition: {inputs.shape=}\")\n","    nan_mask = jnp.isnan(inputs)\n","    inputs = jnp.where(nan_mask, jnp.zeros_like(inputs), inputs)\n","\n","    # outputs = outputs[:, :, :-inputs_offset]\n","    outputs = jnp.where(nan_mask, jnp.zeros_like(outputs), outputs)\n","\n","    # raw_loss = optax.squared_error(outputs, inputs)\n","    # compute manually\n","    # raw_loss = jnp.square(outputs - inputs)\n","    # Abs loss\n","    raw_loss = jnp.abs(outputs - inputs)\n","    masked_loss = jnp.where(nan_mask, 0.0, raw_loss)\n","    loss = masked_loss.sum() / (~nan_mask).sum()\n","\n","    return loss\n","\n","\n","def calculate_loss(\n","    params,\n","    state,\n","    numeric_inputs,\n","    categorical_inputs,\n","    dropout_key,\n","    mask_data: bool = True,\n","):\n","    outputs = state.apply_fn(\n","        {\"params\": params},\n","        # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","        numeric_inputs=numeric_inputs,\n","        categorical_inputs=categorical_inputs.astype(jnp.int32),\n","        rngs={\"dropout\": dropout_key},\n","        deterministic=False,\n","        mask_data=mask_data,\n","    )\n","    loss = base_loss(\n","        numeric_inputs=numeric_inputs,\n","        categorical_inputs=categorical_inputs,\n","        outputs=outputs,\n","    )\n","    # Create mask for nan inputs\n","\n","    return loss\n","\n","\n","@jax.jit\n","def train_step(\n","    state: train_state.TrainState,\n","    numeric_inputs,\n","    categorical_inputs,\n","    base_key,\n","    # mask_data=True,\n","):\n","    # print(\"In train step\")\n","    dropout_key, mask_key, new_key = jax.random.split(\n","        base_key, 3\n","    )  # TODO Figure out mask key\n","    # print(\"Making masks\")\n","    # numeric_inputs = batch[\"numeric\"]\n","    # categorical_inputs = batch[\"categorical\"]\n","    # print(\"Made masks\")\n","\n","    def calculate_loss_with_mask(params):\n","        return calculate_loss(\n","            params,\n","            state,\n","            numeric_inputs=numeric_inputs,\n","            categorical_inputs=categorical_inputs,\n","            dropout_key=dropout_key,\n","            mask_data=True,\n","        )\n","\n","    def loss_fn(params):\n","        return calculate_loss_with_mask(params)\n","\n","    # def calculate_loss_without_mask(params):\n","    #     return calculate_loss(params, state, batch, dropout_key, mask_data=False)\n","\n","    # def loss_fn(params):\n","    #     return jax.lax.cond(\n","    #         mask_data,\n","    #         lambda _: calculate_loss_with_mask(params),\n","    #         lambda _: calculate_loss_without_mask(params),\n","    #         operand=None,\n","    #     )\n","\n","    # def loss_fn(params):\n","    #     return calculate_loss(params, state, batch, dropout_key, mask_data=mask_data)\n","\n","    grad_fn = jax.value_and_grad(loss_fn)\n","\n","    # (loss, individual_losses), grad = grad_fn(state.params)\n","    loss, grad = grad_fn(state.params)\n","    # grad = replace_nans(grad)\n","    # grad = clip_gradients(grad, 1.0)\n","    state = state.apply_gradients(grads=grad)\n","\n","    return state, loss, new_key\n","\n","\n","def evaluate(params, state, inputs, mask_data: bool = True):\n","    outputs = state.apply_fn(\n","        {\"params\": params},\n","        # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","        inputs,\n","        deterministic=True,\n","        mask_data=mask_data,\n","    )\n","    loss = base_loss(inputs, outputs)\n","    return loss\n","\n","\n","@jax.jit\n","def eval_step(\n","    state: train_state.TrainState, numeric_inputs, categorical_inputs, base_key\n","):\n","    # mask_data=True\n","    mask_key, dropout_key, new_key = jax.random.split(base_key, 3)\n","\n","    def calculate_loss_with_mask(params):\n","        return calculate_loss(\n","            params,\n","            state,\n","            numeric_inputs=numeric_inputs,\n","            categorical_inputs=categorical_inputs,\n","            dropout_key=dropout_key,\n","            mask_data=True,\n","        )\n","\n","    def calculate_loss_without_mask(params):\n","        return calculate_loss(\n","            params, state=state, batch=batch, dropout_key=dropout_key, mask_data=False\n","        )\n","\n","    def loss_fn(params):\n","        return calculate_loss_with_mask(params)\n","\n","    # TODO Reimplement this...\n","    # def loss_fn(params):\n","    #     return jax.lax.cond(\n","    #         mask_data,\n","    #         lambda _: calculate_loss_with_mask(params),\n","    #         lambda _: calculate_loss_without_mask(params),\n","    #         operand=None,\n","    #     )\n","\n","    # def loss_fn(params):\n","    #     return evaluate(params, state, batch, mask_data=mask_data)\n","\n","    # (loss, individual_losses), grad = grad_fn(state.params)\n","    loss = loss_fn(state.params)\n","    return loss, new_key\n","\n","\n","def create_train_state(model, prng, batch, lr):\n","    init_key, dropout_key = random.split(prng)\n","    params = model.init(\n","        {\"params\": init_key, \"dropout\": dropout_key},\n","        batch[\"numeric\"],\n","        batch[\"categorical\"],\n","        deterministic=False,\n","    )\n","    # optimizer = optax.chain(optax.adam(lr))\n","    optimizer = optax.chain(optax.clip_by_global_norm(0.4), optax.adam(lr))\n","    # optimizer_state = optimizer.init(params)\n","    return train_state.TrainState.create(\n","        apply_fn=model.apply,\n","        params=params[\"params\"],\n","        tx=optimizer,\n","        # tx_state=optimizer_state,\n","    )\n","\n","\n","batch_size = 2\n","# batch = train_ds[0]\n","# state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)\n","state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffcbbabad6444360b10cf991131293f1","version_major":2,"version_minor":0},"text/plain":["epochs for runs/2024-08-31T21:36:49BERT_Embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"482ea35ed0fb4d5b8c66d71cba65ff10","version_major":2,"version_minor":0},"text/plain":["batches:   0%|          | 0/6250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Base Loss (16, 27, 59) (16, 27, 59)\n","outputs.shape=(16, 27, 59), inputs.shape=(16, 27, 59)\n","outputs.shape=(16, 2, 59), inputs.shape=(16, 2, 59)\n","Base Loss (16, 27, 59) (16, 27, 59)\n","outputs.shape=(16, 27, 59), inputs.shape=(16, 27, 59)\n","outputs.shape=(16, 2, 59), inputs.shape=(16, 2, 59)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 30\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_summary_writer\u001b[38;5;241m.\u001b[39mlog_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# arrs = train_data_loader()\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(train_data_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatches\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# for i in trange(len(pre_train) // batch_size, leave=False):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# for i in trange(len(pre_train) // batch_size //10, leave=False):\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# batch = make_batch(train_ds, i[0], 4)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m         state, loss, base_key \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mask_data=MASK_DATA,\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39misnan(loss):\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNan Value in loss, stopping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["writer_name = \"BERT_Embeddings\"\n","\n","writer_time = dt.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n","model_name = writer_time + writer_name\n","train_summary_writer = SummaryWriter(\"runs/\" + model_name)\n","\n","MASK_DATA = True\n","\n","test_set_key = random.PRNGKey(4454)\n","\n","batch_size = 16\n","train_data_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","test_data_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n","\n","# train_data_loader = DataLoader(train_ds, batch_size=256 // 2, shuffle=True)\n","# test_data_loader = DataLoader(test_ds, batch_size=256 // 2, shuffle=True)\n","\n","batch_count = 0\n","base_key = random.PRNGKey(42)\n","\n","# Disable IC for training\n","max_iters = 200\n","ic.disable()\n","for j in trange(1, desc=f\"epochs for {train_summary_writer.log_dir}\"):\n","    # arrs = train_data_loader()\n","    for i in tqdm(train_data_loader, leave=False, desc=\"batches\"):\n","        # for i in trange(len(pre_train) // batch_size, leave=False):\n","        # for i in trange(len(pre_train) // batch_size //10, leave=False):\n","        # batch = make_batch(train_ds, i[0], 4)\n","        state, loss, base_key = train_step(\n","            state,\n","            jnp.array(i[0]),\n","            jnp.array(i[1]),\n","            base_key,\n","            # mask_data=MASK_DATA,\n","        )\n","        if jnp.isnan(loss):\n","            raise ValueError(\"Nan Value in loss, stopping\")\n","        batch_count += 1\n","\n","        if batch_count % 1 == 0:\n","            train_summary_writer.add_scalar(\n","                \"loss/loss\", np.array(loss.item()), batch_count\n","            )\n","        if batch_count % 10 == 0:\n","            numeric_eval, categorical_eval = next(iter(test_data_loader))\n","            test_loss, base_key = eval_step(\n","                state,\n","                jnp.array(numeric_eval),\n","                jnp.array(categorical_eval),\n","                base_key,\n","                # mask_data=MASK_DATA,\n","            )\n","            train_summary_writer.add_scalar(\n","                \"loss/test_loss\", np.array(test_loss.item()), batch_count\n","            )\n","            train_summary_writer.flush()\n","        # if batch_count > 200:\n","        #     break\n","        if batch_count > max_iters:\n","            break\n","\n","train_summary_writer.close()"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.        ,  0.46511628,  0.93023256, ...,         nan,\n","                nan,         nan],\n","       [ 1.56006022,  1.68985799,  1.75358875, ...,         nan,\n","                nan,         nan],\n","       [-0.85443699, -0.5143588 , -0.15420858, ...,         nan,\n","                nan,         nan],\n","       ...,\n","       [        nan,         nan,         nan, ...,         nan,\n","                nan,         nan],\n","       [        nan,         nan,         nan, ...,         nan,\n","                nan,         nan],\n","       [ 6.97412249,  6.97412249,  6.97412249, ...,         nan,\n","                nan,         nan]])"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["train_ds[0][0]"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["{'numeric_out': Array([[[11.181038  , 11.140583  , 11.101066  , ..., 11.32562   ,\n","          11.382234  , 11.41336   ],\n","         [ 0.22009788,  0.21450125,  0.20456655, ...,  0.15386526,\n","           0.16100045,  0.15643792],\n","         [-0.517749  , -0.5040334 , -0.49248892, ..., -0.59351164,\n","          -0.5940318 , -0.5888521 ],\n","         ...,\n","         [ 1.9436795 ,  1.9312918 ,  1.9221929 , ...,  1.9567974 ,\n","           1.9659095 ,  1.9736373 ],\n","         [ 0.02335496,  0.02150651,  0.02871914, ...,  0.08315714,\n","           0.08081253,  0.08272083],\n","         [11.387409  , 11.367141  , 11.331749  , ..., 11.304806  ,\n","          11.29361   , 11.277805  ]]], dtype=float32),\n"," 'categorical_out': Array([[[35.3297  , 35.280807, 35.214005, 35.156345, 35.131405,\n","          35.14735 , 35.364372, 35.36472 , 35.332634, 35.293766,\n","          35.28131 , 35.294548, 35.324776, 35.352848, 35.359005,\n","          35.33747 , 35.311523, 35.280212, 35.24819 , 35.238476,\n","          35.266136, 35.264027, 35.25621 , 35.249374, 35.27304 ,\n","          35.296345, 35.310444, 35.304966, 35.294525, 35.28793 ,\n","          35.287968, 35.313988, 35.34281 , 35.348   , 35.319965,\n","          35.081596, 35.04786 , 35.037354, 35.04594 , 35.047592,\n","          35.04668 , 35.044315, 35.045364, 35.0652  , 35.129066,\n","          35.14499 , 35.167145, 35.187553, 35.21263 , 35.21402 ,\n","          35.206604, 35.17773 , 35.129375, 35.10682 , 35.12909 ,\n","          35.172073, 35.211567, 35.230953, 35.20747 ],\n","         [38.67775 , 38.62966 , 38.56596 , 38.512997, 38.49517 ,\n","          38.505684, 38.52454 , 38.511936, 38.466885, 38.417633,\n","          38.395172, 38.400208, 38.418846, 38.44383 , 38.455257,\n","          38.444336, 38.423035, 38.39119 , 38.35565 , 38.344166,\n","          38.456398, 38.45838 , 38.462208, 38.469513, 38.50404 ,\n","          38.54361 , 38.569897, 38.561436, 38.52881 , 38.497406,\n","          38.485664, 38.516575, 38.559315, 38.584835, 38.568703,\n","          38.512493, 38.45739 , 38.420773, 38.41316 , 38.414295,\n","          38.421715, 38.432255, 38.44581 , 38.479927, 38.438686,\n","          38.463924, 38.491028, 38.510746, 38.532887, 38.536015,\n","          38.533108, 38.504272, 38.44959 , 38.424885, 38.449062,\n","          38.501205, 38.558136, 38.590786, 38.563404]]], dtype=float32)}"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["state.apply_fn(\n","    {\"params\": state.params},\n","    # jnp.array(i[0]),\n","    # jnp.array(i[1]),\n","    jnp.array([train_ds[0][0]]),\n","    jnp.array([train_ds[0][1]]),\n","    deterministic=True,\n","    mask_data=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ckpt = {\"model\": state, \"step\": batch_count}\n","\n","\n","checkpoint_dir = f\"checkpoints/{model_name}\"\n","checkpoint_dir = os.path.abspath(checkpoint_dir)\n","\n","# os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n","save_args = orbax_utils.save_args_from_target(ckpt)\n","orbax_checkpointer.save(checkpoint_dir, ckpt, save_args=save_args)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/kailukowiak/Hephaestus/.venv/lib/python3.10/site-packages/orbax/checkpoint/type_handlers.py:1552: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n","  warnings.warn(\n"]}],"source":["new_checkpoint = orbax_checkpointer.restore(checkpoint_dir)\n","new_state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)\n","new_state = new_state.replace(params=new_checkpoint[\"model\"][\"params\"])"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["'numeric_out'"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["numeric_inputs, categorical_inputs = train_ds[0]\n","numeric_inputs = jnp.array([numeric_inputs])\n","categorical_inputs = jnp.array([categorical_inputs])\n","numeric_out, categorical_out = state.apply_fn(\n","    {\"params\": state.params},\n","    # jnp.array(i[0]),\n","    # jnp.array(i[1]),\n","    numeric_inputs,\n","    categorical_inputs,\n","    deterministic=True,\n","    mask_data=False,\n",")\n","numeric_out"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting results\n"]},{"data":{"text/plain":["Array([[[36.12317 , 36.047028, 35.95711 , 35.88954 , 35.857315,\n","         35.866478, 36.01963 , 36.027714, 36.007008, 35.98618 ,\n","         35.985733, 36.00666 , 36.03651 , 36.057316, 36.04742 ,\n","         36.02263 , 35.992283, 35.962803, 35.935192, 35.915043,\n","         35.901955, 35.8892  , 35.87702 , 35.864693, 35.87282 ,\n","         35.886154, 35.89364 , 35.88587 , 35.881737, 35.879517,\n","         35.88059 , 35.89406 , 35.910313, 35.909245, 35.880554,\n","         35.68208 , 35.64167 , 35.620308, 35.61562 , 35.60777 ,\n","         35.59563 , 35.577515, 35.56537 , 35.577145, 35.555386,\n","         35.571976, 35.594948, 35.613667, 35.638573, 35.63228 ,\n","         35.61675 , 35.589813, 35.54513 , 35.525276, 35.54861 ,\n","         35.592075, 35.627785, 35.64456 , 35.621185],\n","        [39.11205 , 39.05336 , 38.982082, 38.928215, 38.907085,\n","         38.91555 , 38.94078 , 38.947823, 38.92335 , 38.898895,\n","         38.899143, 38.929794, 38.97196 , 39.00206 , 39.004402,\n","         38.99353 , 38.973038, 38.942234, 38.911713, 38.89261 ,\n","         38.95279 , 38.957596, 38.963253, 38.968693, 38.992313,\n","         39.028675, 39.05975 , 39.063625, 39.050453, 39.02988 ,\n","         39.02516 , 39.04954 , 39.086384, 39.106964, 39.093315,\n","         39.043404, 38.981647, 38.936447, 38.91655 , 38.91307 ,\n","         38.913795, 38.908867, 38.91203 , 38.943806, 38.84618 ,\n","         38.869396, 38.893894, 38.91097 , 38.934532, 38.92734 ,\n","         38.912937, 38.88377 , 38.83576 , 38.81393 , 38.8405  ,\n","         38.89302 , 38.946   , 38.974506, 38.947277]]], dtype=float32)"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["@dataclass\n","class Results:\n","    numeric_out: jnp.array\n","    categorical_out: jnp.array\n","    numeric_inputs: jnp.array\n","    categorical_inputs: jnp.array\n","\n","\n","def return_results(state, dataset, idx=0, mask_start: int = None):\n","    numeric_inputs, categorical_inputs = dataset[idx]\n","    if mask_start:\n","        print(\"Masking\")\n","        numeric_inputs = numeric_inputs[:, :mask_start]\n","        categorical_inputs = categorical_inputs[:, :mask_start]\n","    numeric_inputs = jnp.array([numeric_inputs])\n","    categorical_inputs = jnp.array([categorical_inputs])\n","    print(\"Getting results\")\n","    out = state.apply_fn(\n","        {\"params\": state.params},\n","        # hp.mask_tensor(jnp.array([train_ds[0]]), dataset, prng_key=key),\n","        numeric_inputs=numeric_inputs,\n","        categorical_inputs=categorical_inputs,\n","        deterministic=True,\n","        mask_data=MASK_DATA,\n","    )\n","    numeric_out, categorical_out = out[\"numeric_out\"], out[\"categorical_out\"]\n","    return Results(numeric_out, categorical_out, numeric_inputs, categorical_inputs)\n","\n","\n","x = return_results(state, train_ds, 0)\n","x.categorical_out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>planet0_e</th>\n","      <th>...</th>\n","      <th>planet3_y</th>\n","      <th>planet3_m</th>\n","      <th>planet3_a</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","      <th>total_mass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9.756296</td>\n","      <td>0.111494</td>\n","      <td>-0.117593</td>\n","      <td>0.388406</td>\n","      <td>-0.463551</td>\n","      <td>-0.329284</td>\n","      <td>0.918282</td>\n","      <td>2.694641</td>\n","      <td>1.768598</td>\n","      <td>1.029188</td>\n","      <td>...</td>\n","      <td>0.161583</td>\n","      <td>3.442658</td>\n","      <td>1.673402</td>\n","      <td>1.106791</td>\n","      <td>-0.159440</td>\n","      <td>0.221506</td>\n","      <td>3.307631</td>\n","      <td>1.792369</td>\n","      <td>-0.087887</td>\n","      <td>11.798042</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9.642425</td>\n","      <td>0.111467</td>\n","      <td>-0.088864</td>\n","      <td>0.424417</td>\n","      <td>-0.436392</td>\n","      <td>-0.369885</td>\n","      <td>0.922729</td>\n","      <td>2.668303</td>\n","      <td>1.765564</td>\n","      <td>1.019210</td>\n","      <td>...</td>\n","      <td>0.189700</td>\n","      <td>3.484208</td>\n","      <td>1.689074</td>\n","      <td>1.099275</td>\n","      <td>-0.155131</td>\n","      <td>0.212693</td>\n","      <td>3.311567</td>\n","      <td>1.767895</td>\n","      <td>-0.100261</td>\n","      <td>11.788279</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9.631383</td>\n","      <td>0.094130</td>\n","      <td>-0.077061</td>\n","      <td>0.409449</td>\n","      <td>-0.441680</td>\n","      <td>-0.384776</td>\n","      <td>0.933448</td>\n","      <td>2.669973</td>\n","      <td>1.756892</td>\n","      <td>1.007583</td>\n","      <td>...</td>\n","      <td>0.203880</td>\n","      <td>3.494935</td>\n","      <td>1.709868</td>\n","      <td>1.105471</td>\n","      <td>-0.157640</td>\n","      <td>0.217382</td>\n","      <td>3.304543</td>\n","      <td>1.767284</td>\n","      <td>-0.090635</td>\n","      <td>11.758847</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9.642579</td>\n","      <td>0.083382</td>\n","      <td>-0.073815</td>\n","      <td>0.389726</td>\n","      <td>-0.447586</td>\n","      <td>-0.399162</td>\n","      <td>0.940623</td>\n","      <td>2.676741</td>\n","      <td>1.763083</td>\n","      <td>1.002725</td>\n","      <td>...</td>\n","      <td>0.214067</td>\n","      <td>3.492521</td>\n","      <td>1.723492</td>\n","      <td>1.111457</td>\n","      <td>-0.156890</td>\n","      <td>0.221923</td>\n","      <td>3.306988</td>\n","      <td>1.774342</td>\n","      <td>-0.079743</td>\n","      <td>11.731918</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9.683665</td>\n","      <td>0.078874</td>\n","      <td>-0.077024</td>\n","      <td>0.371988</td>\n","      <td>-0.454990</td>\n","      <td>-0.408621</td>\n","      <td>0.939697</td>\n","      <td>2.691235</td>\n","      <td>1.775649</td>\n","      <td>1.005562</td>\n","      <td>...</td>\n","      <td>0.220003</td>\n","      <td>3.482205</td>\n","      <td>1.726036</td>\n","      <td>1.120321</td>\n","      <td>-0.158326</td>\n","      <td>0.219783</td>\n","      <td>3.311317</td>\n","      <td>1.787016</td>\n","      <td>-0.068445</td>\n","      <td>11.721029</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>9.756283</td>\n","      <td>0.078238</td>\n","      <td>-0.085264</td>\n","      <td>0.359003</td>\n","      <td>-0.463114</td>\n","      <td>-0.403548</td>\n","      <td>0.926282</td>\n","      <td>2.705736</td>\n","      <td>1.784645</td>\n","      <td>1.016066</td>\n","      <td>...</td>\n","      <td>0.222133</td>\n","      <td>3.471570</td>\n","      <td>1.719362</td>\n","      <td>1.134419</td>\n","      <td>-0.161319</td>\n","      <td>0.211063</td>\n","      <td>3.312743</td>\n","      <td>1.800762</td>\n","      <td>-0.062613</td>\n","      <td>11.731183</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>9.834229</td>\n","      <td>0.039231</td>\n","      <td>-0.096377</td>\n","      <td>0.313503</td>\n","      <td>-0.488958</td>\n","      <td>-0.429806</td>\n","      <td>0.896166</td>\n","      <td>2.716848</td>\n","      <td>1.766870</td>\n","      <td>1.032279</td>\n","      <td>...</td>\n","      <td>0.234209</td>\n","      <td>3.469087</td>\n","      <td>1.736159</td>\n","      <td>1.158088</td>\n","      <td>-0.182317</td>\n","      <td>0.201927</td>\n","      <td>3.317343</td>\n","      <td>1.810741</td>\n","      <td>-0.046254</td>\n","      <td>11.741310</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9.912541</td>\n","      <td>0.033579</td>\n","      <td>-0.115894</td>\n","      <td>0.308875</td>\n","      <td>-0.498878</td>\n","      <td>-0.415747</td>\n","      <td>0.876612</td>\n","      <td>2.723068</td>\n","      <td>1.756351</td>\n","      <td>1.044910</td>\n","      <td>...</td>\n","      <td>0.223370</td>\n","      <td>3.470561</td>\n","      <td>1.729179</td>\n","      <td>1.164564</td>\n","      <td>-0.192987</td>\n","      <td>0.186054</td>\n","      <td>3.322382</td>\n","      <td>1.823186</td>\n","      <td>-0.047983</td>\n","      <td>11.749603</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9.965851</td>\n","      <td>0.025361</td>\n","      <td>-0.127683</td>\n","      <td>0.303464</td>\n","      <td>-0.507985</td>\n","      <td>-0.404321</td>\n","      <td>0.864334</td>\n","      <td>2.725231</td>\n","      <td>1.746316</td>\n","      <td>1.052034</td>\n","      <td>...</td>\n","      <td>0.215764</td>\n","      <td>3.475831</td>\n","      <td>1.730870</td>\n","      <td>1.164768</td>\n","      <td>-0.202951</td>\n","      <td>0.174030</td>\n","      <td>3.327143</td>\n","      <td>1.833158</td>\n","      <td>-0.051014</td>\n","      <td>11.741024</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10.004771</td>\n","      <td>0.014708</td>\n","      <td>-0.132921</td>\n","      <td>0.295094</td>\n","      <td>-0.518791</td>\n","      <td>-0.397724</td>\n","      <td>0.854481</td>\n","      <td>2.724352</td>\n","      <td>1.741161</td>\n","      <td>1.053080</td>\n","      <td>...</td>\n","      <td>0.211820</td>\n","      <td>3.483894</td>\n","      <td>1.743762</td>\n","      <td>1.163029</td>\n","      <td>-0.210169</td>\n","      <td>0.171736</td>\n","      <td>3.330570</td>\n","      <td>1.842648</td>\n","      <td>-0.051750</td>\n","      <td>11.726444</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10.054481</td>\n","      <td>0.004202</td>\n","      <td>-0.138002</td>\n","      <td>0.280989</td>\n","      <td>-0.532468</td>\n","      <td>-0.396076</td>\n","      <td>0.843011</td>\n","      <td>2.729487</td>\n","      <td>1.739254</td>\n","      <td>1.051361</td>\n","      <td>...</td>\n","      <td>0.210750</td>\n","      <td>3.483602</td>\n","      <td>1.757669</td>\n","      <td>1.165971</td>\n","      <td>-0.212167</td>\n","      <td>0.171992</td>\n","      <td>3.337460</td>\n","      <td>1.854687</td>\n","      <td>-0.048122</td>\n","      <td>11.717472</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10.128205</td>\n","      <td>-0.002163</td>\n","      <td>-0.147673</td>\n","      <td>0.262265</td>\n","      <td>-0.546801</td>\n","      <td>-0.393524</td>\n","      <td>0.827394</td>\n","      <td>2.742252</td>\n","      <td>1.737634</td>\n","      <td>1.049979</td>\n","      <td>...</td>\n","      <td>0.208218</td>\n","      <td>3.473380</td>\n","      <td>1.764063</td>\n","      <td>1.176326</td>\n","      <td>-0.213590</td>\n","      <td>0.167850</td>\n","      <td>3.346634</td>\n","      <td>1.867018</td>\n","      <td>-0.042469</td>\n","      <td>11.715409</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>10.211940</td>\n","      <td>-0.003711</td>\n","      <td>-0.167340</td>\n","      <td>0.247674</td>\n","      <td>-0.558159</td>\n","      <td>-0.387738</td>\n","      <td>0.804596</td>\n","      <td>2.752827</td>\n","      <td>1.727468</td>\n","      <td>1.054226</td>\n","      <td>...</td>\n","      <td>0.199522</td>\n","      <td>3.458915</td>\n","      <td>1.759690</td>\n","      <td>1.190864</td>\n","      <td>-0.218334</td>\n","      <td>0.153046</td>\n","      <td>3.350565</td>\n","      <td>1.876129</td>\n","      <td>-0.033440</td>\n","      <td>11.708584</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>10.287135</td>\n","      <td>-0.000390</td>\n","      <td>-0.187011</td>\n","      <td>0.235436</td>\n","      <td>-0.568484</td>\n","      <td>-0.382594</td>\n","      <td>0.779450</td>\n","      <td>2.757721</td>\n","      <td>1.710817</td>\n","      <td>1.066002</td>\n","      <td>...</td>\n","      <td>0.186098</td>\n","      <td>3.443736</td>\n","      <td>1.749649</td>\n","      <td>1.207009</td>\n","      <td>-0.226819</td>\n","      <td>0.133579</td>\n","      <td>3.348134</td>\n","      <td>1.879982</td>\n","      <td>-0.027948</td>\n","      <td>11.693165</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>10.333243</td>\n","      <td>0.007632</td>\n","      <td>-0.206475</td>\n","      <td>0.227407</td>\n","      <td>-0.577726</td>\n","      <td>-0.377134</td>\n","      <td>0.764717</td>\n","      <td>2.755137</td>\n","      <td>1.691972</td>\n","      <td>1.080234</td>\n","      <td>...</td>\n","      <td>0.168181</td>\n","      <td>3.427496</td>\n","      <td>1.740807</td>\n","      <td>1.216025</td>\n","      <td>-0.238319</td>\n","      <td>0.110928</td>\n","      <td>3.342039</td>\n","      <td>1.877778</td>\n","      <td>-0.028740</td>\n","      <td>11.664354</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>10.353424</td>\n","      <td>0.011600</td>\n","      <td>-0.223014</td>\n","      <td>0.220719</td>\n","      <td>-0.581623</td>\n","      <td>-0.378523</td>\n","      <td>0.757319</td>\n","      <td>2.744922</td>\n","      <td>1.676334</td>\n","      <td>1.091269</td>\n","      <td>...</td>\n","      <td>0.148749</td>\n","      <td>3.409430</td>\n","      <td>1.741939</td>\n","      <td>1.216585</td>\n","      <td>-0.246941</td>\n","      <td>0.094295</td>\n","      <td>3.339249</td>\n","      <td>1.870306</td>\n","      <td>-0.030401</td>\n","      <td>11.637510</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>10.359763</td>\n","      <td>0.011776</td>\n","      <td>-0.233161</td>\n","      <td>0.213262</td>\n","      <td>-0.586010</td>\n","      <td>-0.380133</td>\n","      <td>0.757170</td>\n","      <td>2.735311</td>\n","      <td>1.672473</td>\n","      <td>1.096194</td>\n","      <td>...</td>\n","      <td>0.137159</td>\n","      <td>3.394276</td>\n","      <td>1.753116</td>\n","      <td>1.210295</td>\n","      <td>-0.253153</td>\n","      <td>0.087236</td>\n","      <td>3.338704</td>\n","      <td>1.863561</td>\n","      <td>-0.029353</td>\n","      <td>11.617447</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>10.366893</td>\n","      <td>0.011021</td>\n","      <td>-0.239804</td>\n","      <td>0.205665</td>\n","      <td>-0.590088</td>\n","      <td>-0.376583</td>\n","      <td>0.759454</td>\n","      <td>2.735012</td>\n","      <td>1.680628</td>\n","      <td>1.095701</td>\n","      <td>...</td>\n","      <td>0.135110</td>\n","      <td>3.387762</td>\n","      <td>1.769836</td>\n","      <td>1.201651</td>\n","      <td>-0.254408</td>\n","      <td>0.086715</td>\n","      <td>3.340148</td>\n","      <td>1.860135</td>\n","      <td>-0.026115</td>\n","      <td>11.613968</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>10.386587</td>\n","      <td>0.006753</td>\n","      <td>-0.246090</td>\n","      <td>0.195723</td>\n","      <td>-0.596185</td>\n","      <td>-0.370029</td>\n","      <td>0.758422</td>\n","      <td>2.740706</td>\n","      <td>1.690435</td>\n","      <td>1.095682</td>\n","      <td>...</td>\n","      <td>0.141339</td>\n","      <td>3.390239</td>\n","      <td>1.791952</td>\n","      <td>1.195546</td>\n","      <td>-0.255834</td>\n","      <td>0.087192</td>\n","      <td>3.342037</td>\n","      <td>1.864263</td>\n","      <td>-0.025652</td>\n","      <td>11.622781</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>10.424723</td>\n","      <td>0.000095</td>\n","      <td>-0.255589</td>\n","      <td>0.184132</td>\n","      <td>-0.602759</td>\n","      <td>-0.360283</td>\n","      <td>0.752336</td>\n","      <td>2.746751</td>\n","      <td>1.692863</td>\n","      <td>1.100326</td>\n","      <td>...</td>\n","      <td>0.147520</td>\n","      <td>3.395726</td>\n","      <td>1.811731</td>\n","      <td>1.194371</td>\n","      <td>-0.256958</td>\n","      <td>0.083332</td>\n","      <td>3.344118</td>\n","      <td>1.871536</td>\n","      <td>-0.026830</td>\n","      <td>11.633387</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>10.493871</td>\n","      <td>-0.006184</td>\n","      <td>-0.335821</td>\n","      <td>0.169101</td>\n","      <td>-0.685076</td>\n","      <td>-0.321175</td>\n","      <td>0.702586</td>\n","      <td>2.753883</td>\n","      <td>1.698268</td>\n","      <td>1.114775</td>\n","      <td>...</td>\n","      <td>0.122840</td>\n","      <td>3.398537</td>\n","      <td>1.825974</td>\n","      <td>1.187909</td>\n","      <td>-0.266339</td>\n","      <td>0.046119</td>\n","      <td>3.340821</td>\n","      <td>1.881117</td>\n","      <td>0.001614</td>\n","      <td>11.619360</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>10.535874</td>\n","      <td>-0.002844</td>\n","      <td>-0.352441</td>\n","      <td>0.170785</td>\n","      <td>-0.691038</td>\n","      <td>-0.310225</td>\n","      <td>0.690091</td>\n","      <td>2.751545</td>\n","      <td>1.687000</td>\n","      <td>1.119032</td>\n","      <td>...</td>\n","      <td>0.119971</td>\n","      <td>3.404015</td>\n","      <td>1.830267</td>\n","      <td>1.190343</td>\n","      <td>-0.271498</td>\n","      <td>0.036825</td>\n","      <td>3.338252</td>\n","      <td>1.897118</td>\n","      <td>0.004693</td>\n","      <td>11.607647</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>10.573253</td>\n","      <td>0.000189</td>\n","      <td>-0.370548</td>\n","      <td>0.168376</td>\n","      <td>-0.701408</td>\n","      <td>-0.304228</td>\n","      <td>0.676348</td>\n","      <td>2.747375</td>\n","      <td>1.677231</td>\n","      <td>1.118229</td>\n","      <td>...</td>\n","      <td>0.111491</td>\n","      <td>3.404531</td>\n","      <td>1.828502</td>\n","      <td>1.187270</td>\n","      <td>-0.273487</td>\n","      <td>0.025137</td>\n","      <td>3.338519</td>\n","      <td>1.911361</td>\n","      <td>0.010009</td>\n","      <td>11.589188</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>10.613429</td>\n","      <td>0.000975</td>\n","      <td>-0.391077</td>\n","      <td>0.159469</td>\n","      <td>-0.715011</td>\n","      <td>-0.301180</td>\n","      <td>0.660263</td>\n","      <td>2.748916</td>\n","      <td>1.676463</td>\n","      <td>1.113405</td>\n","      <td>...</td>\n","      <td>0.101140</td>\n","      <td>3.402304</td>\n","      <td>1.824892</td>\n","      <td>1.177941</td>\n","      <td>-0.273669</td>\n","      <td>0.012224</td>\n","      <td>3.346262</td>\n","      <td>1.924750</td>\n","      <td>0.015972</td>\n","      <td>11.580968</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>10.657950</td>\n","      <td>0.000895</td>\n","      <td>-0.407662</td>\n","      <td>0.157778</td>\n","      <td>-0.726334</td>\n","      <td>-0.296667</td>\n","      <td>0.646915</td>\n","      <td>2.759237</td>\n","      <td>1.688264</td>\n","      <td>1.115313</td>\n","      <td>...</td>\n","      <td>0.092241</td>\n","      <td>3.403651</td>\n","      <td>1.823712</td>\n","      <td>1.171896</td>\n","      <td>-0.278723</td>\n","      <td>0.002313</td>\n","      <td>3.355863</td>\n","      <td>1.937627</td>\n","      <td>0.020179</td>\n","      <td>11.595188</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>10.715808</td>\n","      <td>-0.004354</td>\n","      <td>-0.420984</td>\n","      <td>0.153577</td>\n","      <td>-0.736009</td>\n","      <td>-0.287477</td>\n","      <td>0.633743</td>\n","      <td>2.776116</td>\n","      <td>1.702448</td>\n","      <td>1.118484</td>\n","      <td>...</td>\n","      <td>0.083184</td>\n","      <td>3.404926</td>\n","      <td>1.825569</td>\n","      <td>1.173307</td>\n","      <td>-0.285238</td>\n","      <td>-0.008278</td>\n","      <td>3.359182</td>\n","      <td>1.949551</td>\n","      <td>0.024896</td>\n","      <td>11.616941</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>10.779866</td>\n","      <td>-0.010202</td>\n","      <td>-0.428068</td>\n","      <td>0.145717</td>\n","      <td>-0.741182</td>\n","      <td>-0.277794</td>\n","      <td>0.619894</td>\n","      <td>2.793273</td>\n","      <td>1.706228</td>\n","      <td>1.123158</td>\n","      <td>...</td>\n","      <td>0.075167</td>\n","      <td>3.403131</td>\n","      <td>1.826015</td>\n","      <td>1.185155</td>\n","      <td>-0.287956</td>\n","      <td>-0.018651</td>\n","      <td>3.356585</td>\n","      <td>1.955965</td>\n","      <td>0.030958</td>\n","      <td>11.627634</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>10.831671</td>\n","      <td>-0.010166</td>\n","      <td>-0.427398</td>\n","      <td>0.147309</td>\n","      <td>-0.738770</td>\n","      <td>-0.265946</td>\n","      <td>0.607919</td>\n","      <td>2.804194</td>\n","      <td>1.697919</td>\n","      <td>1.130293</td>\n","      <td>...</td>\n","      <td>0.068527</td>\n","      <td>3.394292</td>\n","      <td>1.822662</td>\n","      <td>1.205148</td>\n","      <td>-0.283373</td>\n","      <td>-0.028215</td>\n","      <td>3.350988</td>\n","      <td>1.950238</td>\n","      <td>0.041725</td>\n","      <td>11.616830</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>10.864298</td>\n","      <td>-0.004123</td>\n","      <td>-0.420688</td>\n","      <td>0.156008</td>\n","      <td>-0.734462</td>\n","      <td>-0.251895</td>\n","      <td>0.598791</td>\n","      <td>2.804423</td>\n","      <td>1.681306</td>\n","      <td>1.140833</td>\n","      <td>...</td>\n","      <td>0.063929</td>\n","      <td>3.381821</td>\n","      <td>1.816970</td>\n","      <td>1.227827</td>\n","      <td>-0.277034</td>\n","      <td>-0.034635</td>\n","      <td>3.341517</td>\n","      <td>1.937601</td>\n","      <td>0.056242</td>\n","      <td>11.590745</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>10.876637</td>\n","      <td>0.010244</td>\n","      <td>-0.415203</td>\n","      <td>0.167177</td>\n","      <td>-0.731466</td>\n","      <td>-0.238137</td>\n","      <td>0.599947</td>\n","      <td>2.797249</td>\n","      <td>1.667668</td>\n","      <td>1.150033</td>\n","      <td>...</td>\n","      <td>0.062276</td>\n","      <td>3.368155</td>\n","      <td>1.808168</td>\n","      <td>1.243586</td>\n","      <td>-0.272128</td>\n","      <td>-0.036743</td>\n","      <td>3.334567</td>\n","      <td>1.921485</td>\n","      <td>0.072882</td>\n","      <td>11.558176</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>10.888511</td>\n","      <td>0.029160</td>\n","      <td>-0.418721</td>\n","      <td>0.171266</td>\n","      <td>-0.735102</td>\n","      <td>-0.226862</td>\n","      <td>0.602662</td>\n","      <td>2.789844</td>\n","      <td>1.662825</td>\n","      <td>1.151368</td>\n","      <td>...</td>\n","      <td>0.062029</td>\n","      <td>3.356306</td>\n","      <td>1.799809</td>\n","      <td>1.248729</td>\n","      <td>-0.271512</td>\n","      <td>-0.037394</td>\n","      <td>3.332269</td>\n","      <td>1.909478</td>\n","      <td>0.082055</td>\n","      <td>11.531352</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>10.910684</td>\n","      <td>0.041150</td>\n","      <td>-0.430933</td>\n","      <td>0.167436</td>\n","      <td>-0.746067</td>\n","      <td>-0.218468</td>\n","      <td>0.603989</td>\n","      <td>2.788896</td>\n","      <td>1.667008</td>\n","      <td>1.150569</td>\n","      <td>...</td>\n","      <td>0.063291</td>\n","      <td>3.354337</td>\n","      <td>1.799456</td>\n","      <td>1.246073</td>\n","      <td>-0.278961</td>\n","      <td>-0.038335</td>\n","      <td>3.332938</td>\n","      <td>1.906116</td>\n","      <td>0.082638</td>\n","      <td>11.528112</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>10.941707</td>\n","      <td>0.042056</td>\n","      <td>-0.445742</td>\n","      <td>0.159395</td>\n","      <td>-0.760663</td>\n","      <td>-0.208497</td>\n","      <td>0.602139</td>\n","      <td>2.796626</td>\n","      <td>1.670328</td>\n","      <td>1.149469</td>\n","      <td>...</td>\n","      <td>0.067238</td>\n","      <td>3.360163</td>\n","      <td>1.806383</td>\n","      <td>1.242846</td>\n","      <td>-0.291242</td>\n","      <td>-0.039308</td>\n","      <td>3.330750</td>\n","      <td>1.911204</td>\n","      <td>0.078195</td>\n","      <td>11.551170</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>10.981738</td>\n","      <td>0.036219</td>\n","      <td>-0.460377</td>\n","      <td>0.148732</td>\n","      <td>-0.777061</td>\n","      <td>-0.195633</td>\n","      <td>0.596640</td>\n","      <td>2.807140</td>\n","      <td>1.667237</td>\n","      <td>1.148375</td>\n","      <td>...</td>\n","      <td>0.072734</td>\n","      <td>3.366371</td>\n","      <td>1.817106</td>\n","      <td>1.243973</td>\n","      <td>-0.302552</td>\n","      <td>-0.042701</td>\n","      <td>3.327193</td>\n","      <td>1.920079</td>\n","      <td>0.072110</td>\n","      <td>11.576574</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>11.024633</td>\n","      <td>0.028652</td>\n","      <td>-0.468319</td>\n","      <td>0.141327</td>\n","      <td>-0.793471</td>\n","      <td>-0.184173</td>\n","      <td>0.588916</td>\n","      <td>2.817762</td>\n","      <td>1.658991</td>\n","      <td>1.147594</td>\n","      <td>...</td>\n","      <td>0.071772</td>\n","      <td>3.367978</td>\n","      <td>1.826873</td>\n","      <td>1.251175</td>\n","      <td>-0.308755</td>\n","      <td>-0.048012</td>\n","      <td>3.323429</td>\n","      <td>1.927287</td>\n","      <td>0.069970</td>\n","      <td>11.588572</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>11.053309</td>\n","      <td>0.076335</td>\n","      <td>-0.469697</td>\n","      <td>0.188997</td>\n","      <td>-0.786622</td>\n","      <td>-0.118672</td>\n","      <td>0.591525</td>\n","      <td>2.819122</td>\n","      <td>1.670880</td>\n","      <td>1.146686</td>\n","      <td>...</td>\n","      <td>0.044796</td>\n","      <td>3.361044</td>\n","      <td>1.809715</td>\n","      <td>1.249894</td>\n","      <td>-0.285442</td>\n","      <td>-0.041745</td>\n","      <td>3.324740</td>\n","      <td>1.926048</td>\n","      <td>0.045208</td>\n","      <td>11.594237</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>11.052724</td>\n","      <td>0.080466</td>\n","      <td>-0.459745</td>\n","      <td>0.203038</td>\n","      <td>-0.788217</td>\n","      <td>-0.110839</td>\n","      <td>0.594645</td>\n","      <td>2.822836</td>\n","      <td>1.669411</td>\n","      <td>1.151698</td>\n","      <td>...</td>\n","      <td>0.043032</td>\n","      <td>3.360636</td>\n","      <td>1.808634</td>\n","      <td>1.258228</td>\n","      <td>-0.277942</td>\n","      <td>-0.041912</td>\n","      <td>3.318938</td>\n","      <td>1.921183</td>\n","      <td>0.054692</td>\n","      <td>11.580998</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>11.039133</td>\n","      <td>0.090461</td>\n","      <td>-0.453882</td>\n","      <td>0.219936</td>\n","      <td>-0.785818</td>\n","      <td>-0.103054</td>\n","      <td>0.599404</td>\n","      <td>2.823700</td>\n","      <td>1.673670</td>\n","      <td>1.159900</td>\n","      <td>...</td>\n","      <td>0.045257</td>\n","      <td>3.364832</td>\n","      <td>1.806605</td>\n","      <td>1.260664</td>\n","      <td>-0.269339</td>\n","      <td>-0.039234</td>\n","      <td>3.316880</td>\n","      <td>1.913528</td>\n","      <td>0.064134</td>\n","      <td>11.570732</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>11.023933</td>\n","      <td>0.099767</td>\n","      <td>-0.455002</td>\n","      <td>0.228466</td>\n","      <td>-0.783074</td>\n","      <td>-0.095817</td>\n","      <td>0.605433</td>\n","      <td>2.827296</td>\n","      <td>1.678838</td>\n","      <td>1.167330</td>\n","      <td>...</td>\n","      <td>0.051220</td>\n","      <td>3.375269</td>\n","      <td>1.806299</td>\n","      <td>1.256053</td>\n","      <td>-0.263770</td>\n","      <td>-0.035358</td>\n","      <td>3.315902</td>\n","      <td>1.909386</td>\n","      <td>0.072016</td>\n","      <td>11.567806</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>11.010516</td>\n","      <td>0.104571</td>\n","      <td>-0.460974</td>\n","      <td>0.229562</td>\n","      <td>-0.778569</td>\n","      <td>-0.093273</td>\n","      <td>0.609912</td>\n","      <td>2.833842</td>\n","      <td>1.679925</td>\n","      <td>1.173959</td>\n","      <td>...</td>\n","      <td>0.058495</td>\n","      <td>3.390148</td>\n","      <td>1.808114</td>\n","      <td>1.246321</td>\n","      <td>-0.262969</td>\n","      <td>-0.029777</td>\n","      <td>3.314613</td>\n","      <td>1.911836</td>\n","      <td>0.077370</td>\n","      <td>11.574859</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>11.007500</td>\n","      <td>0.105741</td>\n","      <td>-0.468284</td>\n","      <td>0.227913</td>\n","      <td>-0.773141</td>\n","      <td>-0.091495</td>\n","      <td>0.609644</td>\n","      <td>2.840399</td>\n","      <td>1.674336</td>\n","      <td>1.179589</td>\n","      <td>...</td>\n","      <td>0.063274</td>\n","      <td>3.402721</td>\n","      <td>1.811294</td>\n","      <td>1.238081</td>\n","      <td>-0.265476</td>\n","      <td>-0.024981</td>\n","      <td>3.311666</td>\n","      <td>1.918703</td>\n","      <td>0.079540</td>\n","      <td>11.585199</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>11.001488</td>\n","      <td>0.106723</td>\n","      <td>-0.471716</td>\n","      <td>0.232278</td>\n","      <td>-0.764795</td>\n","      <td>-0.096851</td>\n","      <td>0.603591</td>\n","      <td>2.844887</td>\n","      <td>1.665309</td>\n","      <td>1.185021</td>\n","      <td>...</td>\n","      <td>0.058633</td>\n","      <td>3.409636</td>\n","      <td>1.813871</td>\n","      <td>1.233525</td>\n","      <td>-0.269311</td>\n","      <td>-0.024142</td>\n","      <td>3.313024</td>\n","      <td>1.918164</td>\n","      <td>0.081660</td>\n","      <td>11.592970</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>11.000058</td>\n","      <td>0.111300</td>\n","      <td>-0.469456</td>\n","      <td>0.246800</td>\n","      <td>-0.754169</td>\n","      <td>-0.106814</td>\n","      <td>0.596095</td>\n","      <td>2.842320</td>\n","      <td>1.665608</td>\n","      <td>1.189289</td>\n","      <td>...</td>\n","      <td>0.049707</td>\n","      <td>3.411926</td>\n","      <td>1.815347</td>\n","      <td>1.235402</td>\n","      <td>-0.271293</td>\n","      <td>-0.025307</td>\n","      <td>3.315896</td>\n","      <td>1.914138</td>\n","      <td>0.082192</td>\n","      <td>11.597723</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>11.004821</td>\n","      <td>0.119751</td>\n","      <td>-0.465670</td>\n","      <td>0.262990</td>\n","      <td>-0.739827</td>\n","      <td>-0.121094</td>\n","      <td>0.595669</td>\n","      <td>2.833978</td>\n","      <td>1.673060</td>\n","      <td>1.190747</td>\n","      <td>...</td>\n","      <td>0.041731</td>\n","      <td>3.409000</td>\n","      <td>1.810350</td>\n","      <td>1.239682</td>\n","      <td>-0.268982</td>\n","      <td>-0.027601</td>\n","      <td>3.321379</td>\n","      <td>1.909356</td>\n","      <td>0.083591</td>\n","      <td>11.599966</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>11.038255</td>\n","      <td>0.121047</td>\n","      <td>-0.456484</td>\n","      <td>0.247018</td>\n","      <td>-0.709609</td>\n","      <td>-0.143388</td>\n","      <td>0.614267</td>\n","      <td>2.840136</td>\n","      <td>1.638871</td>\n","      <td>1.166416</td>\n","      <td>...</td>\n","      <td>0.056492</td>\n","      <td>3.390563</td>\n","      <td>1.819215</td>\n","      <td>1.264343</td>\n","      <td>-0.286855</td>\n","      <td>-0.009801</td>\n","      <td>3.316600</td>\n","      <td>1.930856</td>\n","      <td>0.078674</td>\n","      <td>11.544859</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>11.029929</td>\n","      <td>0.110521</td>\n","      <td>-0.458257</td>\n","      <td>0.244791</td>\n","      <td>-0.712968</td>\n","      <td>-0.151103</td>\n","      <td>0.631170</td>\n","      <td>2.836820</td>\n","      <td>1.649546</td>\n","      <td>1.155827</td>\n","      <td>...</td>\n","      <td>0.061793</td>\n","      <td>3.389631</td>\n","      <td>1.818559</td>\n","      <td>1.267536</td>\n","      <td>-0.280435</td>\n","      <td>-0.002844</td>\n","      <td>3.315846</td>\n","      <td>1.934984</td>\n","      <td>0.079190</td>\n","      <td>11.537869</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>11.022539</td>\n","      <td>0.095520</td>\n","      <td>-0.467311</td>\n","      <td>0.236238</td>\n","      <td>-0.720502</td>\n","      <td>-0.150316</td>\n","      <td>0.645515</td>\n","      <td>2.838491</td>\n","      <td>1.652120</td>\n","      <td>1.143949</td>\n","      <td>...</td>\n","      <td>0.072990</td>\n","      <td>3.391204</td>\n","      <td>1.820038</td>\n","      <td>1.268549</td>\n","      <td>-0.277635</td>\n","      <td>0.008551</td>\n","      <td>3.312557</td>\n","      <td>1.946128</td>\n","      <td>0.080810</td>\n","      <td>11.529119</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>11.025313</td>\n","      <td>0.083017</td>\n","      <td>-0.477401</td>\n","      <td>0.226571</td>\n","      <td>-0.731792</td>\n","      <td>-0.142516</td>\n","      <td>0.651643</td>\n","      <td>2.842170</td>\n","      <td>1.645830</td>\n","      <td>1.132404</td>\n","      <td>...</td>\n","      <td>0.082841</td>\n","      <td>3.395634</td>\n","      <td>1.819225</td>\n","      <td>1.268833</td>\n","      <td>-0.280563</td>\n","      <td>0.020917</td>\n","      <td>3.311939</td>\n","      <td>1.961513</td>\n","      <td>0.085238</td>\n","      <td>11.520260</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>11.038430</td>\n","      <td>0.077268</td>\n","      <td>-0.480644</td>\n","      <td>0.224476</td>\n","      <td>-0.738041</td>\n","      <td>-0.129216</td>\n","      <td>0.645516</td>\n","      <td>2.841241</td>\n","      <td>1.637264</td>\n","      <td>1.122438</td>\n","      <td>...</td>\n","      <td>0.086214</td>\n","      <td>3.402581</td>\n","      <td>1.814928</td>\n","      <td>1.272817</td>\n","      <td>-0.289162</td>\n","      <td>0.027952</td>\n","      <td>3.315116</td>\n","      <td>1.974906</td>\n","      <td>0.088843</td>\n","      <td>11.515942</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>11.041409</td>\n","      <td>0.077209</td>\n","      <td>-0.472210</td>\n","      <td>0.228493</td>\n","      <td>-0.745112</td>\n","      <td>-0.120562</td>\n","      <td>0.636627</td>\n","      <td>2.836343</td>\n","      <td>1.633046</td>\n","      <td>1.116214</td>\n","      <td>...</td>\n","      <td>0.087292</td>\n","      <td>3.415396</td>\n","      <td>1.816016</td>\n","      <td>1.278142</td>\n","      <td>-0.299589</td>\n","      <td>0.027237</td>\n","      <td>3.320492</td>\n","      <td>1.975981</td>\n","      <td>0.090918</td>\n","      <td>11.512766</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>11.036157</td>\n","      <td>0.081979</td>\n","      <td>-0.460431</td>\n","      <td>0.233741</td>\n","      <td>-0.748021</td>\n","      <td>-0.117668</td>\n","      <td>0.632097</td>\n","      <td>2.834088</td>\n","      <td>1.631323</td>\n","      <td>1.118590</td>\n","      <td>...</td>\n","      <td>0.085423</td>\n","      <td>3.426866</td>\n","      <td>1.818974</td>\n","      <td>1.283497</td>\n","      <td>-0.311277</td>\n","      <td>0.018299</td>\n","      <td>3.330370</td>\n","      <td>1.964707</td>\n","      <td>0.090737</td>\n","      <td>11.520797</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>11.016481</td>\n","      <td>0.084629</td>\n","      <td>-0.450888</td>\n","      <td>0.231736</td>\n","      <td>-0.745453</td>\n","      <td>-0.120245</td>\n","      <td>0.631658</td>\n","      <td>2.831135</td>\n","      <td>1.632045</td>\n","      <td>1.126483</td>\n","      <td>...</td>\n","      <td>0.083220</td>\n","      <td>3.436983</td>\n","      <td>1.825531</td>\n","      <td>1.285155</td>\n","      <td>-0.313991</td>\n","      <td>0.009366</td>\n","      <td>3.336943</td>\n","      <td>1.948788</td>\n","      <td>0.083558</td>\n","      <td>11.533869</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>10.978574</td>\n","      <td>0.081341</td>\n","      <td>-0.446907</td>\n","      <td>0.222161</td>\n","      <td>-0.739301</td>\n","      <td>-0.127203</td>\n","      <td>0.638671</td>\n","      <td>2.827518</td>\n","      <td>1.632670</td>\n","      <td>1.136541</td>\n","      <td>...</td>\n","      <td>0.082796</td>\n","      <td>3.439613</td>\n","      <td>1.834812</td>\n","      <td>1.277359</td>\n","      <td>-0.310919</td>\n","      <td>0.002667</td>\n","      <td>3.337470</td>\n","      <td>1.935478</td>\n","      <td>0.078962</td>\n","      <td>11.539758</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>10.949354</td>\n","      <td>0.077658</td>\n","      <td>-0.452810</td>\n","      <td>0.207588</td>\n","      <td>-0.731759</td>\n","      <td>-0.134060</td>\n","      <td>0.644320</td>\n","      <td>2.826278</td>\n","      <td>1.625080</td>\n","      <td>1.141736</td>\n","      <td>...</td>\n","      <td>0.085870</td>\n","      <td>3.434703</td>\n","      <td>1.840766</td>\n","      <td>1.265498</td>\n","      <td>-0.303748</td>\n","      <td>-0.002100</td>\n","      <td>3.337245</td>\n","      <td>1.925775</td>\n","      <td>0.077672</td>\n","      <td>11.534260</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>10.946258</td>\n","      <td>0.077257</td>\n","      <td>-0.464537</td>\n","      <td>0.198228</td>\n","      <td>-0.726907</td>\n","      <td>-0.140829</td>\n","      <td>0.644318</td>\n","      <td>2.826966</td>\n","      <td>1.613066</td>\n","      <td>1.145625</td>\n","      <td>...</td>\n","      <td>0.085454</td>\n","      <td>3.423399</td>\n","      <td>1.841852</td>\n","      <td>1.251997</td>\n","      <td>-0.301121</td>\n","      <td>-0.005746</td>\n","      <td>3.337797</td>\n","      <td>1.921505</td>\n","      <td>0.078807</td>\n","      <td>11.528986</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>10.965899</td>\n","      <td>0.083096</td>\n","      <td>-0.476139</td>\n","      <td>0.199387</td>\n","      <td>-0.727597</td>\n","      <td>-0.145205</td>\n","      <td>0.636861</td>\n","      <td>2.827150</td>\n","      <td>1.602401</td>\n","      <td>1.147705</td>\n","      <td>...</td>\n","      <td>0.082643</td>\n","      <td>3.415139</td>\n","      <td>1.840212</td>\n","      <td>1.244846</td>\n","      <td>-0.301560</td>\n","      <td>-0.007357</td>\n","      <td>3.339961</td>\n","      <td>1.923196</td>\n","      <td>0.078159</td>\n","      <td>11.527802</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>11.009599</td>\n","      <td>0.094163</td>\n","      <td>-0.482747</td>\n","      <td>0.207441</td>\n","      <td>-0.733083</td>\n","      <td>-0.138400</td>\n","      <td>0.625964</td>\n","      <td>2.826295</td>\n","      <td>1.599145</td>\n","      <td>1.143528</td>\n","      <td>...</td>\n","      <td>0.081928</td>\n","      <td>3.412627</td>\n","      <td>1.838577</td>\n","      <td>1.250534</td>\n","      <td>-0.301047</td>\n","      <td>-0.008725</td>\n","      <td>3.338483</td>\n","      <td>1.931470</td>\n","      <td>0.073621</td>\n","      <td>11.522825</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>11.062696</td>\n","      <td>0.101983</td>\n","      <td>-0.481753</td>\n","      <td>0.211877</td>\n","      <td>-0.742278</td>\n","      <td>-0.121902</td>\n","      <td>0.618239</td>\n","      <td>2.827648</td>\n","      <td>1.601620</td>\n","      <td>1.134048</td>\n","      <td>...</td>\n","      <td>0.089845</td>\n","      <td>3.412918</td>\n","      <td>1.837101</td>\n","      <td>1.264779</td>\n","      <td>-0.295438</td>\n","      <td>-0.009225</td>\n","      <td>3.335769</td>\n","      <td>1.940473</td>\n","      <td>0.070728</td>\n","      <td>11.513244</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>11.095201</td>\n","      <td>0.098130</td>\n","      <td>-0.477134</td>\n","      <td>0.204583</td>\n","      <td>-0.750930</td>\n","      <td>-0.103282</td>\n","      <td>0.619845</td>\n","      <td>2.835486</td>\n","      <td>1.606048</td>\n","      <td>1.125910</td>\n","      <td>...</td>\n","      <td>0.102274</td>\n","      <td>3.411939</td>\n","      <td>1.833802</td>\n","      <td>1.277521</td>\n","      <td>-0.284785</td>\n","      <td>-0.007864</td>\n","      <td>3.331666</td>\n","      <td>1.949742</td>\n","      <td>0.073321</td>\n","      <td>11.498028</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>59 rows × 27 columns</p>\n","</div>"],"text/plain":["    time_step  planet0_x  planet0_y  planet1_x  planet1_y  planet2_x  \\\n","0    9.756296   0.111494  -0.117593   0.388406  -0.463551  -0.329284   \n","1    9.642425   0.111467  -0.088864   0.424417  -0.436392  -0.369885   \n","2    9.631383   0.094130  -0.077061   0.409449  -0.441680  -0.384776   \n","3    9.642579   0.083382  -0.073815   0.389726  -0.447586  -0.399162   \n","4    9.683665   0.078874  -0.077024   0.371988  -0.454990  -0.408621   \n","5    9.756283   0.078238  -0.085264   0.359003  -0.463114  -0.403548   \n","6    9.834229   0.039231  -0.096377   0.313503  -0.488958  -0.429806   \n","7    9.912541   0.033579  -0.115894   0.308875  -0.498878  -0.415747   \n","8    9.965851   0.025361  -0.127683   0.303464  -0.507985  -0.404321   \n","9   10.004771   0.014708  -0.132921   0.295094  -0.518791  -0.397724   \n","10  10.054481   0.004202  -0.138002   0.280989  -0.532468  -0.396076   \n","11  10.128205  -0.002163  -0.147673   0.262265  -0.546801  -0.393524   \n","12  10.211940  -0.003711  -0.167340   0.247674  -0.558159  -0.387738   \n","13  10.287135  -0.000390  -0.187011   0.235436  -0.568484  -0.382594   \n","14  10.333243   0.007632  -0.206475   0.227407  -0.577726  -0.377134   \n","15  10.353424   0.011600  -0.223014   0.220719  -0.581623  -0.378523   \n","16  10.359763   0.011776  -0.233161   0.213262  -0.586010  -0.380133   \n","17  10.366893   0.011021  -0.239804   0.205665  -0.590088  -0.376583   \n","18  10.386587   0.006753  -0.246090   0.195723  -0.596185  -0.370029   \n","19  10.424723   0.000095  -0.255589   0.184132  -0.602759  -0.360283   \n","20  10.493871  -0.006184  -0.335821   0.169101  -0.685076  -0.321175   \n","21  10.535874  -0.002844  -0.352441   0.170785  -0.691038  -0.310225   \n","22  10.573253   0.000189  -0.370548   0.168376  -0.701408  -0.304228   \n","23  10.613429   0.000975  -0.391077   0.159469  -0.715011  -0.301180   \n","24  10.657950   0.000895  -0.407662   0.157778  -0.726334  -0.296667   \n","25  10.715808  -0.004354  -0.420984   0.153577  -0.736009  -0.287477   \n","26  10.779866  -0.010202  -0.428068   0.145717  -0.741182  -0.277794   \n","27  10.831671  -0.010166  -0.427398   0.147309  -0.738770  -0.265946   \n","28  10.864298  -0.004123  -0.420688   0.156008  -0.734462  -0.251895   \n","29  10.876637   0.010244  -0.415203   0.167177  -0.731466  -0.238137   \n","30  10.888511   0.029160  -0.418721   0.171266  -0.735102  -0.226862   \n","31  10.910684   0.041150  -0.430933   0.167436  -0.746067  -0.218468   \n","32  10.941707   0.042056  -0.445742   0.159395  -0.760663  -0.208497   \n","33  10.981738   0.036219  -0.460377   0.148732  -0.777061  -0.195633   \n","34  11.024633   0.028652  -0.468319   0.141327  -0.793471  -0.184173   \n","35  11.053309   0.076335  -0.469697   0.188997  -0.786622  -0.118672   \n","36  11.052724   0.080466  -0.459745   0.203038  -0.788217  -0.110839   \n","37  11.039133   0.090461  -0.453882   0.219936  -0.785818  -0.103054   \n","38  11.023933   0.099767  -0.455002   0.228466  -0.783074  -0.095817   \n","39  11.010516   0.104571  -0.460974   0.229562  -0.778569  -0.093273   \n","40  11.007500   0.105741  -0.468284   0.227913  -0.773141  -0.091495   \n","41  11.001488   0.106723  -0.471716   0.232278  -0.764795  -0.096851   \n","42  11.000058   0.111300  -0.469456   0.246800  -0.754169  -0.106814   \n","43  11.004821   0.119751  -0.465670   0.262990  -0.739827  -0.121094   \n","44  11.038255   0.121047  -0.456484   0.247018  -0.709609  -0.143388   \n","45  11.029929   0.110521  -0.458257   0.244791  -0.712968  -0.151103   \n","46  11.022539   0.095520  -0.467311   0.236238  -0.720502  -0.150316   \n","47  11.025313   0.083017  -0.477401   0.226571  -0.731792  -0.142516   \n","48  11.038430   0.077268  -0.480644   0.224476  -0.738041  -0.129216   \n","49  11.041409   0.077209  -0.472210   0.228493  -0.745112  -0.120562   \n","50  11.036157   0.081979  -0.460431   0.233741  -0.748021  -0.117668   \n","51  11.016481   0.084629  -0.450888   0.231736  -0.745453  -0.120245   \n","52  10.978574   0.081341  -0.446907   0.222161  -0.739301  -0.127203   \n","53  10.949354   0.077658  -0.452810   0.207588  -0.731759  -0.134060   \n","54  10.946258   0.077257  -0.464537   0.198228  -0.726907  -0.140829   \n","55  10.965899   0.083096  -0.476139   0.199387  -0.727597  -0.145205   \n","56  11.009599   0.094163  -0.482747   0.207441  -0.733083  -0.138400   \n","57  11.062696   0.101983  -0.481753   0.211877  -0.742278  -0.121902   \n","58  11.095201   0.098130  -0.477134   0.204583  -0.750930  -0.103282   \n","\n","    planet2_y  planet0_m  planet0_a  planet0_e  ...  planet3_y  planet3_m  \\\n","0    0.918282   2.694641   1.768598   1.029188  ...   0.161583   3.442658   \n","1    0.922729   2.668303   1.765564   1.019210  ...   0.189700   3.484208   \n","2    0.933448   2.669973   1.756892   1.007583  ...   0.203880   3.494935   \n","3    0.940623   2.676741   1.763083   1.002725  ...   0.214067   3.492521   \n","4    0.939697   2.691235   1.775649   1.005562  ...   0.220003   3.482205   \n","5    0.926282   2.705736   1.784645   1.016066  ...   0.222133   3.471570   \n","6    0.896166   2.716848   1.766870   1.032279  ...   0.234209   3.469087   \n","7    0.876612   2.723068   1.756351   1.044910  ...   0.223370   3.470561   \n","8    0.864334   2.725231   1.746316   1.052034  ...   0.215764   3.475831   \n","9    0.854481   2.724352   1.741161   1.053080  ...   0.211820   3.483894   \n","10   0.843011   2.729487   1.739254   1.051361  ...   0.210750   3.483602   \n","11   0.827394   2.742252   1.737634   1.049979  ...   0.208218   3.473380   \n","12   0.804596   2.752827   1.727468   1.054226  ...   0.199522   3.458915   \n","13   0.779450   2.757721   1.710817   1.066002  ...   0.186098   3.443736   \n","14   0.764717   2.755137   1.691972   1.080234  ...   0.168181   3.427496   \n","15   0.757319   2.744922   1.676334   1.091269  ...   0.148749   3.409430   \n","16   0.757170   2.735311   1.672473   1.096194  ...   0.137159   3.394276   \n","17   0.759454   2.735012   1.680628   1.095701  ...   0.135110   3.387762   \n","18   0.758422   2.740706   1.690435   1.095682  ...   0.141339   3.390239   \n","19   0.752336   2.746751   1.692863   1.100326  ...   0.147520   3.395726   \n","20   0.702586   2.753883   1.698268   1.114775  ...   0.122840   3.398537   \n","21   0.690091   2.751545   1.687000   1.119032  ...   0.119971   3.404015   \n","22   0.676348   2.747375   1.677231   1.118229  ...   0.111491   3.404531   \n","23   0.660263   2.748916   1.676463   1.113405  ...   0.101140   3.402304   \n","24   0.646915   2.759237   1.688264   1.115313  ...   0.092241   3.403651   \n","25   0.633743   2.776116   1.702448   1.118484  ...   0.083184   3.404926   \n","26   0.619894   2.793273   1.706228   1.123158  ...   0.075167   3.403131   \n","27   0.607919   2.804194   1.697919   1.130293  ...   0.068527   3.394292   \n","28   0.598791   2.804423   1.681306   1.140833  ...   0.063929   3.381821   \n","29   0.599947   2.797249   1.667668   1.150033  ...   0.062276   3.368155   \n","30   0.602662   2.789844   1.662825   1.151368  ...   0.062029   3.356306   \n","31   0.603989   2.788896   1.667008   1.150569  ...   0.063291   3.354337   \n","32   0.602139   2.796626   1.670328   1.149469  ...   0.067238   3.360163   \n","33   0.596640   2.807140   1.667237   1.148375  ...   0.072734   3.366371   \n","34   0.588916   2.817762   1.658991   1.147594  ...   0.071772   3.367978   \n","35   0.591525   2.819122   1.670880   1.146686  ...   0.044796   3.361044   \n","36   0.594645   2.822836   1.669411   1.151698  ...   0.043032   3.360636   \n","37   0.599404   2.823700   1.673670   1.159900  ...   0.045257   3.364832   \n","38   0.605433   2.827296   1.678838   1.167330  ...   0.051220   3.375269   \n","39   0.609912   2.833842   1.679925   1.173959  ...   0.058495   3.390148   \n","40   0.609644   2.840399   1.674336   1.179589  ...   0.063274   3.402721   \n","41   0.603591   2.844887   1.665309   1.185021  ...   0.058633   3.409636   \n","42   0.596095   2.842320   1.665608   1.189289  ...   0.049707   3.411926   \n","43   0.595669   2.833978   1.673060   1.190747  ...   0.041731   3.409000   \n","44   0.614267   2.840136   1.638871   1.166416  ...   0.056492   3.390563   \n","45   0.631170   2.836820   1.649546   1.155827  ...   0.061793   3.389631   \n","46   0.645515   2.838491   1.652120   1.143949  ...   0.072990   3.391204   \n","47   0.651643   2.842170   1.645830   1.132404  ...   0.082841   3.395634   \n","48   0.645516   2.841241   1.637264   1.122438  ...   0.086214   3.402581   \n","49   0.636627   2.836343   1.633046   1.116214  ...   0.087292   3.415396   \n","50   0.632097   2.834088   1.631323   1.118590  ...   0.085423   3.426866   \n","51   0.631658   2.831135   1.632045   1.126483  ...   0.083220   3.436983   \n","52   0.638671   2.827518   1.632670   1.136541  ...   0.082796   3.439613   \n","53   0.644320   2.826278   1.625080   1.141736  ...   0.085870   3.434703   \n","54   0.644318   2.826966   1.613066   1.145625  ...   0.085454   3.423399   \n","55   0.636861   2.827150   1.602401   1.147705  ...   0.082643   3.415139   \n","56   0.625964   2.826295   1.599145   1.143528  ...   0.081928   3.412627   \n","57   0.618239   2.827648   1.601620   1.134048  ...   0.089845   3.412918   \n","58   0.619845   2.835486   1.606048   1.125910  ...   0.102274   3.411939   \n","\n","    planet3_a  planet3_e  planet4_x  planet4_y  planet4_m  planet4_a  \\\n","0    1.673402   1.106791  -0.159440   0.221506   3.307631   1.792369   \n","1    1.689074   1.099275  -0.155131   0.212693   3.311567   1.767895   \n","2    1.709868   1.105471  -0.157640   0.217382   3.304543   1.767284   \n","3    1.723492   1.111457  -0.156890   0.221923   3.306988   1.774342   \n","4    1.726036   1.120321  -0.158326   0.219783   3.311317   1.787016   \n","5    1.719362   1.134419  -0.161319   0.211063   3.312743   1.800762   \n","6    1.736159   1.158088  -0.182317   0.201927   3.317343   1.810741   \n","7    1.729179   1.164564  -0.192987   0.186054   3.322382   1.823186   \n","8    1.730870   1.164768  -0.202951   0.174030   3.327143   1.833158   \n","9    1.743762   1.163029  -0.210169   0.171736   3.330570   1.842648   \n","10   1.757669   1.165971  -0.212167   0.171992   3.337460   1.854687   \n","11   1.764063   1.176326  -0.213590   0.167850   3.346634   1.867018   \n","12   1.759690   1.190864  -0.218334   0.153046   3.350565   1.876129   \n","13   1.749649   1.207009  -0.226819   0.133579   3.348134   1.879982   \n","14   1.740807   1.216025  -0.238319   0.110928   3.342039   1.877778   \n","15   1.741939   1.216585  -0.246941   0.094295   3.339249   1.870306   \n","16   1.753116   1.210295  -0.253153   0.087236   3.338704   1.863561   \n","17   1.769836   1.201651  -0.254408   0.086715   3.340148   1.860135   \n","18   1.791952   1.195546  -0.255834   0.087192   3.342037   1.864263   \n","19   1.811731   1.194371  -0.256958   0.083332   3.344118   1.871536   \n","20   1.825974   1.187909  -0.266339   0.046119   3.340821   1.881117   \n","21   1.830267   1.190343  -0.271498   0.036825   3.338252   1.897118   \n","22   1.828502   1.187270  -0.273487   0.025137   3.338519   1.911361   \n","23   1.824892   1.177941  -0.273669   0.012224   3.346262   1.924750   \n","24   1.823712   1.171896  -0.278723   0.002313   3.355863   1.937627   \n","25   1.825569   1.173307  -0.285238  -0.008278   3.359182   1.949551   \n","26   1.826015   1.185155  -0.287956  -0.018651   3.356585   1.955965   \n","27   1.822662   1.205148  -0.283373  -0.028215   3.350988   1.950238   \n","28   1.816970   1.227827  -0.277034  -0.034635   3.341517   1.937601   \n","29   1.808168   1.243586  -0.272128  -0.036743   3.334567   1.921485   \n","30   1.799809   1.248729  -0.271512  -0.037394   3.332269   1.909478   \n","31   1.799456   1.246073  -0.278961  -0.038335   3.332938   1.906116   \n","32   1.806383   1.242846  -0.291242  -0.039308   3.330750   1.911204   \n","33   1.817106   1.243973  -0.302552  -0.042701   3.327193   1.920079   \n","34   1.826873   1.251175  -0.308755  -0.048012   3.323429   1.927287   \n","35   1.809715   1.249894  -0.285442  -0.041745   3.324740   1.926048   \n","36   1.808634   1.258228  -0.277942  -0.041912   3.318938   1.921183   \n","37   1.806605   1.260664  -0.269339  -0.039234   3.316880   1.913528   \n","38   1.806299   1.256053  -0.263770  -0.035358   3.315902   1.909386   \n","39   1.808114   1.246321  -0.262969  -0.029777   3.314613   1.911836   \n","40   1.811294   1.238081  -0.265476  -0.024981   3.311666   1.918703   \n","41   1.813871   1.233525  -0.269311  -0.024142   3.313024   1.918164   \n","42   1.815347   1.235402  -0.271293  -0.025307   3.315896   1.914138   \n","43   1.810350   1.239682  -0.268982  -0.027601   3.321379   1.909356   \n","44   1.819215   1.264343  -0.286855  -0.009801   3.316600   1.930856   \n","45   1.818559   1.267536  -0.280435  -0.002844   3.315846   1.934984   \n","46   1.820038   1.268549  -0.277635   0.008551   3.312557   1.946128   \n","47   1.819225   1.268833  -0.280563   0.020917   3.311939   1.961513   \n","48   1.814928   1.272817  -0.289162   0.027952   3.315116   1.974906   \n","49   1.816016   1.278142  -0.299589   0.027237   3.320492   1.975981   \n","50   1.818974   1.283497  -0.311277   0.018299   3.330370   1.964707   \n","51   1.825531   1.285155  -0.313991   0.009366   3.336943   1.948788   \n","52   1.834812   1.277359  -0.310919   0.002667   3.337470   1.935478   \n","53   1.840766   1.265498  -0.303748  -0.002100   3.337245   1.925775   \n","54   1.841852   1.251997  -0.301121  -0.005746   3.337797   1.921505   \n","55   1.840212   1.244846  -0.301560  -0.007357   3.339961   1.923196   \n","56   1.838577   1.250534  -0.301047  -0.008725   3.338483   1.931470   \n","57   1.837101   1.264779  -0.295438  -0.009225   3.335769   1.940473   \n","58   1.833802   1.277521  -0.284785  -0.007864   3.331666   1.949742   \n","\n","    planet4_e  total_mass  \n","0   -0.087887   11.798042  \n","1   -0.100261   11.788279  \n","2   -0.090635   11.758847  \n","3   -0.079743   11.731918  \n","4   -0.068445   11.721029  \n","5   -0.062613   11.731183  \n","6   -0.046254   11.741310  \n","7   -0.047983   11.749603  \n","8   -0.051014   11.741024  \n","9   -0.051750   11.726444  \n","10  -0.048122   11.717472  \n","11  -0.042469   11.715409  \n","12  -0.033440   11.708584  \n","13  -0.027948   11.693165  \n","14  -0.028740   11.664354  \n","15  -0.030401   11.637510  \n","16  -0.029353   11.617447  \n","17  -0.026115   11.613968  \n","18  -0.025652   11.622781  \n","19  -0.026830   11.633387  \n","20   0.001614   11.619360  \n","21   0.004693   11.607647  \n","22   0.010009   11.589188  \n","23   0.015972   11.580968  \n","24   0.020179   11.595188  \n","25   0.024896   11.616941  \n","26   0.030958   11.627634  \n","27   0.041725   11.616830  \n","28   0.056242   11.590745  \n","29   0.072882   11.558176  \n","30   0.082055   11.531352  \n","31   0.082638   11.528112  \n","32   0.078195   11.551170  \n","33   0.072110   11.576574  \n","34   0.069970   11.588572  \n","35   0.045208   11.594237  \n","36   0.054692   11.580998  \n","37   0.064134   11.570732  \n","38   0.072016   11.567806  \n","39   0.077370   11.574859  \n","40   0.079540   11.585199  \n","41   0.081660   11.592970  \n","42   0.082192   11.597723  \n","43   0.083591   11.599966  \n","44   0.078674   11.544859  \n","45   0.079190   11.537869  \n","46   0.080810   11.529119  \n","47   0.085238   11.520260  \n","48   0.088843   11.515942  \n","49   0.090918   11.512766  \n","50   0.090737   11.520797  \n","51   0.083558   11.533869  \n","52   0.078962   11.539758  \n","53   0.077672   11.534260  \n","54   0.078807   11.528986  \n","55   0.078159   11.527802  \n","56   0.073621   11.522825  \n","57   0.070728   11.513244  \n","58   0.073321   11.498028  \n","\n","[59 rows x 27 columns]"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["mask_data = False\n","MASK_DATA = True\n","\n","\n","def process_results(arr: jnp.array, col_names: list):\n","    arr = jnp.squeeze(arr)\n","    df = pd.DataFrame(arr.T)\n","    df.columns = col_names\n","    return df\n","\n","\n","def show_results_df(state, base_df, dataset, idx: int = 0, mask_start: int = None):\n","    results = return_results(state, dataset, idx=idx, mask_start=mask_start)\n","\n","    input_categorical = process_results(\n","        results.categorical_inputs, dataset.categorical_col_tokens\n","    )\n","\n","\n","process_results(x.numeric_out, train_ds.numeric_col_tokens)\n","# res = show_results_df(state, train_df, train_ds, idx=0, mask_start=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'res' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 14\u001b[0m show_heatmap(\u001b[43mres\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff_masked\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiff Masked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"]}],"source":["def show_heatmap(df, title):\n","    \"\"\"Shows heatmap for a dataframe\n","    excludes all columns that are only nan and all rows that are only nan\"\"\"\n","\n","    df = df.dropna(axis=1, how=\"all\")\n","    df = df.dropna(axis=0, how=\"all\")\n","    plt.figure(figsize=(15, 10))\n","    cmap = sns.diverging_palette(220, 20, as_cmap=True)\n","    sns.heatmap(df, cmap=cmap, center=0, annot=True, fmt=\".2f\")\n","    plt.title(title)\n","    plt.show()\n","\n","\n","show_heatmap(res[\"diff_masked\"], \"Diff Masked\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_heatmap(res[\"diff_no_mask\"].head(14), \"Diff Masked\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_key = random.PRNGKey(4454)\n","x = jax.random.normal(test_key, (4, 26, 59, 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["no_mask_out = state.apply_fn(\n","    {\"params\": state.params},\n","    # jnp.array([test_ds[0][:10, :]]),\n","    jnp.array([test_ds[0][:, :10]]),\n","    deterministic=True,\n","    mask_data=True,\n",")\n","mask_out = state.apply_fn(\n","    {\"params\": state.params},\n","    jnp.array([test_ds[0][:, :20]]),\n","    deterministic=True,\n","    mask_data=True,\n",")\n","mask_out_df = pd.DataFrame(jnp.squeeze(mask_out).T)\n","mask_out_df.columns = test_df.columns[1:]\n","no_mask_out_df = pd.DataFrame(jnp.squeeze(no_mask_out).T)\n","no_mask_out_df.columns = test_df.columns[1:]\n","\n","test_diff = mask_out_df - no_mask_out_df\n","test_diff"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_planets(df_pred: pd.DataFrame, df_actual: pd.DataFrame, column: str, offset=0):\n","    plt.figure(figsize=(15, 10))\n","    plt.plot(df_pred[column], label=\"Autogregressive\")\n","    plt.plot(df_actual[column], label=\"Actual\")\n","    plt.title(f\"{column} Predictions\")\n","    plt.legend()\n","    # Show ticks and grid lines every 1 step\n","    plt.xticks(np.arange(0, len(df_pred), 1))\n","    plt.grid()\n","    # add black line at 0 on the y axis to show the difference\n","    plt.axhline(0, color=\"black\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def auto_regressive_predictions(\n","    state: train_state.TrainState, inputs: jnp.ndarray\n",") -> np.ndarray:\n","    # get the first row that contains all nan vales\n","    # if nan_rows_start >= stop_idx:\n","    #     return inputs\n","    nan_columns = jnp.isnan(inputs).all(axis=1)\n","    outputs = state.apply_fn(\n","        {\"params\": state.params},\n","        jnp.array([inputs]),\n","        # jnp.array([inputs]),\n","        deterministic=True,\n","        mask_data=MASK_DATA,\n","    )\n","    outputs = jnp.squeeze(outputs)\n","    final_row = np.array(outputs[:, -1])\n","    final_row = final_row[:, None]\n","    inputs = jnp.concatenate([inputs, final_row], axis=1)\n","    inputs = np.array(inputs)\n","    inputs[nan_columns] = np.nan\n","    return inputs\n","    # return auto_regressive_predictions(state, inputs, stop_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_inputs = test_ds[300]\n","inputs_test = base_inputs[:, :10]\n","print(inputs_test.shape)\n","for i in trange(21):\n","    inputs_test = auto_regressive_predictions(state, inputs_test)\n","\n","# x = auto_regressive_predictions(state, test_ds[0], 10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_auto = pd.DataFrame(inputs_test.T)\n","df_actual = pd.DataFrame(base_inputs.T)\n","df_auto.columns = train_df.columns[1:]\n","df_actual.columns = train_df.columns[1:]\n","df_diff = df_auto - df_actual\n","\n","# Drop rows that are all nan\n","df_diff = df_diff.dropna(axis=0, how=\"all\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_planets(df_auto, df_actual, \"time_step\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_planets(df_auto, df_actual, \"planet3_x\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# inputs = jnp.array(next(iter(test_data_loader)))\n","inputs_test = make_batch(test_ds, 0, 1)\n","\n","outputs = new_state.apply_fn(\n","    {\"params\": state.params},\n","    # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","    inputs_test,\n","    deterministic=True,\n","    mask_data=True,\n",")\n","df_actual = pd.DataFrame(jnp.squeeze(inputs_test).T)\n","df_actual.columns = test_df.columns[1:]\n","\n","df_pred = pd.DataFrame(jnp.squeeze(outputs).T)\n","df_pred.columns = test_df.columns[1:]\n","plot_planets(df_pred, df_actual, \"time_step\")\n","plot_planets(df_pred, df_actual, \"planet2_y\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputs_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_heatmap(df_diff, \"Auto Regressive Predictions\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot planet0_x from df_auto and df_actual\n","\n","\n","res = show_results_df(state, train_df, train_ds, idx=299, mask_start=20)\n","plot_planets(res[\"pred\"], res[\"actual_masked\"], \"planet2_y\", offset=0)\n","# plot_planets(df_auto, df_actual, \"planet2_y\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot planet0_x from df_auto and df_actual\n","res = show_results_df(state, train_df, train_ds, idx=20, mask_start=20)\n","plot_planets(res[\"pred\"], res[\"actual_no_mask\"], \"planet1_y\", offset=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res = show_results_df(state, train_df, test_ds, idx=0, mask_start=30)\n","\n","plot_planets(res[\"pred\"], res[\"actual_masked\"], \"planet2_x\", offset=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss, key = eval_step(state, jnp.array(next(iter(test_data_loader))), base_key)\n","loss, key"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP1swsXnq2jqt/Hz4IBTZm2","gpuType":"V100","machine_shape":"hm","mount_file_id":"1zHmvVqlKJh0x9vjCRSkYKkko5buvMMEd","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01ca2dcb14e647dfb1e68750ca6de39c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a51aa7b827db4f768dce6315dbebf379","IPY_MODEL_634935ff0a6b4d65b72f87359d9f82fc","IPY_MODEL_09b63c98bee543dfb557a007d50c41d1"],"layout":"IPY_MODEL_dc4a8a3b0a8b4ef49dcd6269a1b32e14"}},"0481743e80634f7a8e718fb528950e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"055681c8159b4b6c8104d4e06279803c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b63c98bee543dfb557a007d50c41d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb36a08ca1540228919af722727572c","placeholder":"​","style":"IPY_MODEL_3bd47d84fac442d4bcf49dceeb699d45","value":" 807/807 [04:29&lt;00:00,  3.10it/s]"}},"0e26d28846fb449789510e4748c01c6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ce5408138f4cb28e163f1fdffdee5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b35a70a3b9e4f3b87cf2a7280439ac6","placeholder":"​","style":"IPY_MODEL_0e26d28846fb449789510e4748c01c6a","value":"100%"}},"2ac0cceac38e43adb00a10b778fad2df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddb1791795134ac0a754748f9793c214","placeholder":"​","style":"IPY_MODEL_d95aea2b915b44f38b5090ee186abafd","value":" 807/807 [04:31&lt;00:00,  2.80it/s]"}},"2fb36a08ca1540228919af722727572c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d37adf891a4da68675945509051210":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_055681c8159b4b6c8104d4e06279803c","placeholder":"​","style":"IPY_MODEL_9f5e5843559b4f9e8f3440ebd85743f8","value":" 807/807 [04:52&lt;00:00,  3.03it/s]"}},"3bd47d84fac442d4bcf49dceeb699d45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4151c7353de54909aa9deecbe8c1e1e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"462d9e93a94f44868fec1ece82f0a241":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47793d3155614c8cbd7d3337dcb2f895":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8093c8ddeec4c55ac6cc5f8f7df30bf","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4151c7353de54909aa9deecbe8c1e1e1","value":3}},"4bc81f6d94394d7f90e070d8b11a7059":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da9993585914618a35d8d5382fef850":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4dd64f565fcf4b259ef24944493477bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25ce5408138f4cb28e163f1fdffdee5f","IPY_MODEL_47793d3155614c8cbd7d3337dcb2f895","IPY_MODEL_f9ec11073e484927a4cc1ee2e3da132f"],"layout":"IPY_MODEL_62e750769d364ab2b80d5b9646b10ea6"}},"5e15315a77864badafe48c2baf31b030":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd9dd713862479bba73b6c0a12a1902","IPY_MODEL_88be535ce5a945f4979fe72d9f086365","IPY_MODEL_31d37adf891a4da68675945509051210"],"layout":"IPY_MODEL_4da9993585914618a35d8d5382fef850"}},"5edd903b07594d128ded9b4844835159":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bc81f6d94394d7f90e070d8b11a7059","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3bc58d04d5f42a5a24bd467a9569e01","value":807}},"5f1fb4d40e154e27baa0d4f330df540e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e750769d364ab2b80d5b9646b10ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"634935ff0a6b4d65b72f87359d9f82fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4de75777bba4d72b61936baf3d84cbb","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0481743e80634f7a8e718fb528950e54","value":807}},"6f5ca39406174a4fb1bee9eb1e35fccb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70c7b641da5c4b82bbd5b2e1750f3b39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851b29291123491a821b1ce8088ca785":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88be535ce5a945f4979fe72d9f086365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8382d8bbb7f42f6a0f4d4028203615f","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_851b29291123491a821b1ce8088ca785","value":807}},"8b35a70a3b9e4f3b87cf2a7280439ac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"948787e6434f419a86d9d7da831e2572":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ced4485d5c641eda90ab0634e0691d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f5e5843559b4f9e8f3440ebd85743f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a317a54aa1a349f490e388aacb2d1e4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c470a61e692a4459988f63f0024f7eac","IPY_MODEL_5edd903b07594d128ded9b4844835159","IPY_MODEL_2ac0cceac38e43adb00a10b778fad2df"],"layout":"IPY_MODEL_c7f61bdee3ca4ca0a3f7d021aa558deb"}},"a51aa7b827db4f768dce6315dbebf379":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f1fb4d40e154e27baa0d4f330df540e","placeholder":"​","style":"IPY_MODEL_948787e6434f419a86d9d7da831e2572","value":"100%"}},"acee2c1ed91e44188d5ca40bddace4b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c470a61e692a4459988f63f0024f7eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c7b641da5c4b82bbd5b2e1750f3b39","placeholder":"​","style":"IPY_MODEL_462d9e93a94f44868fec1ece82f0a241","value":"100%"}},"c7f61bdee3ca4ca0a3f7d021aa558deb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cc57eeb92d32434ca82b7c3f669865d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3bc58d04d5f42a5a24bd467a9569e01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d95aea2b915b44f38b5090ee186abafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc4a8a3b0a8b4ef49dcd6269a1b32e14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ddb1791795134ac0a754748f9793c214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd9dd713862479bba73b6c0a12a1902":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acee2c1ed91e44188d5ca40bddace4b1","placeholder":"​","style":"IPY_MODEL_cc57eeb92d32434ca82b7c3f669865d1","value":"100%"}},"e4de75777bba4d72b61936baf3d84cbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8093c8ddeec4c55ac6cc5f8f7df30bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8382d8bbb7f42f6a0f4d4028203615f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9ec11073e484927a4cc1ee2e3da132f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ced4485d5c641eda90ab0634e0691d3","placeholder":"​","style":"IPY_MODEL_6f5ca39406174a4fb1bee9eb1e35fccb","value":" 3/3 [13:53&lt;00:00, 275.36s/it]"}}}}},"nbformat":4,"nbformat_minor":0}
