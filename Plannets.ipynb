{"cells":[{"cell_type":"markdown","metadata":{"id":"trbcfMV6vked"},"source":["<https://github.com/PolymathicAI/xVal>\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"yKsx1R26dLGC"},"outputs":[],"source":["import os\n","\n","os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2102,"status":"ok","timestamp":1708903394514,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"RYm4WOeS1B8x","outputId":"a5c71de2-9597-4fcb-a9a7-b743f1a29feb"},"outputs":[{"data":{"text/plain":["{CpuDevice(id=0)}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import jax.numpy as jnp  # Oddly works in colab to set gpu\n","\n","arr = jnp.array([1, 2, 3])\n","arr.devices()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Jqmm_5s9KXkI"},"outputs":[],"source":["import icecream\n","from icecream import ic\n","\n","icecream.install()\n","ic_disable = False\n","if ic_disable:\n","    ic.disable()\n","ic.configureOutput(includeContext=True, contextAbsPath=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18045,"status":"ok","timestamp":1708903436762,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"oSKniUdxtiTd","outputId":"49871258-6ef7-4956-ad3b-90af827f7253"},"outputs":[],"source":["import os\n","import ast\n","\n","from datetime import datetime as dt\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","import hephaestus as hp\n","import jax\n","import jax.numpy as jnp\n","import numpy as np\n","import optax\n","import pandas as pd\n","from flax.training import train_state\n","from icecream import ic\n","from jax import random\n","from flax import struct\n","from jax.tree_util import tree_flatten\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.notebook import tqdm, trange\n","from hephaestus.models.simple_time_series import SimpleDS\n","\n","pd.options.mode.copy_on_write = True"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def line2df(line, idx):\n","    data_rows = []\n","    line = ast.literal_eval(line)\n","    for i, time_step in enumerate(line[\"data\"]):\n","        row = {\"time_step\": i}\n","        # Add position data for each planet\n","        for j, position in enumerate(time_step):\n","            row[f\"planet{j}_x\"] = position[0]\n","            row[f\"planet{j}_y\"] = position[1]\n","        data_rows.append(row)\n","\n","    df = pd.DataFrame(data_rows)\n","    description = line.pop(\"description\")\n","    step_size = description.pop(\"stepsize\")\n","    for k, v in description.items():\n","        for k_prop, v_prop in v.items():\n","            df[f\"{k}_{k_prop}\"] = v_prop\n","    df[\"time_step\"] = df[\"time_step\"] * step_size\n","    df.insert(0, \"idx\", idx)\n","\n","    return df"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["files = os.listdir(\"data\")\n","if \"planets.parquet\" not in files:\n","    with open(\"data/planets.data\") as f:\n","        data = f.read().splitlines()\n","\n","        dfs = []\n","        for idx, line in enumerate(tqdm(data)):\n","            dfs.append(line2df(line, idx))\n","        print(\"Concatenating dfs...\")\n","        df = pd.concat(dfs)\n","    df.to_parquet(\"data/planets.parquet\")\n","else:\n","    df = pd.read_parquet(\"data/planets.parquet\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["min     30.000000\n","mean    44.511656\n","max     59.000000\n","Name: time_step, dtype: float64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Get min, mean, and max number of time steps\n","df.groupby(\"idx\").count().time_step.agg([\"min\", \"mean\", \"max\"])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# class SimpleDS(Dataset):\n","#     def __init__(self, df, custom_attention: bool = True):\n","#         # Add nan padding to make sure all sequences are the same length\n","#         # use the idx column to group by\n","#         self.max_seq_len = df.groupby(\"idx\").count().time_step.max()\n","#         self.custom_attention = custom_attention\n","#         self.df = df\n","#         self.batch_size = self.max_seq_len\n","\n","#         self.special_tokens = [\"[PAD]\", \"[NUMERIC_MASK]\", \"[MASK]\"]\n","#         self.cat_mask = \"[MASK]\"\n","#         self.numeric_mask = \"[NUMERIC_MASK]\"\n","\n","#         self.col_tokens = [col_name for col_name in df.columns if col_name != \"idx\"]\n","\n","#         self.tokens = self.special_tokens + self.col_tokens\n","\n","#         self.token_dict = {token: i for i, token in enumerate(self.tokens)}\n","#         self.token_decoder_dict = {i: token for i, token in enumerate(self.tokens)}\n","#         self.n_tokens = len(self.tokens)\n","#         self.numeric_indices = jnp.array(\n","#             [self.tokens.index(i) for i in self.col_tokens]\n","#         )\n","\n","#         self.numeric_mask_token = self.tokens.index(self.numeric_mask)\n","\n","#     def __len__(self):\n","#         return self.df.idx.max() + 1  # probably should be max idx + 1 thanks\n","\n","#     def __getitem__(self, set_idx):\n","#         batch = self.df.loc[\n","#             self.df.idx == set_idx, [col for col in self.df.columns if col != \"idx\"]\n","#         ]\n","#         batch = np.array(batch.values)\n","#         # Add padding\n","#         batch_len, n_cols = batch.shape\n","#         pad_len = self.max_seq_len - batch_len\n","#         padding = np.full((pad_len, n_cols), jnp.nan)\n","#         batch = np.concatenate([batch, padding], axis=0)\n","#         return batch"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4RZof2SNKXkK"},"outputs":[],"source":["# Get train test split at 80/20\n","train_idx = int(df.idx.max() * 0.8)\n","train_df = df.loc[df.idx < train_idx].copy()\n","test_df = df.loc[df.idx >= train_idx].copy()\n","del df\n","train_ds = SimpleDS(train_df)\n","test_ds = SimpleDS(test_df)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def make_batch(ds: SimpleDS, start: int, length: int):\n","    data = []\n","    for i in range(start, length + start):\n","        data.append(ds[i])\n","\n","    return jnp.array(data)\n","\n","\n","batch = make_batch(train_ds, 0, 4)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Y4b7IkMWKXkK"},"outputs":[],"source":["time_series_regressor = hp.simple_time_series.SimplePred(train_ds, d_model=64 * 4)"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Incompatible shapes for broadcasting: shapes=[(4, 59, 59), (4, 59, 4, 26, 26), ()]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/util.py:287\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/util.py:280\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached\u001b[39m(_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 280\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:155\u001b[0m, in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;129m@cache\u001b[39m()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_shapes_cached\u001b[39m(\u001b[38;5;241m*\u001b[39mshapes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:171\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_shape\n","\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(4, 59, 59), (4, 59, 4, 26, 26), ()]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m init_key, dropout_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtime_series_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_key\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m dropout_key, original_dropout_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(dropout_key)\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m time_series_regressor\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mvars\u001b[39m, batch, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rngs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: dropout_key}\n\u001b[1;32m      9\u001b[0m )\n","    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/hephaestus/models/simple_time_series.py:291\u001b[0m, in \u001b[0;36mSimplePred.__call__\u001b[0;34m(self, numeric_inputs, deterministic)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m, numeric_inputs: jnp\u001b[38;5;241m.\u001b[39marray, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    289\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray:\n\u001b[1;32m    290\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     ic(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    295\u001b[0m     ic(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNan values in simplePred out 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjnp\u001b[38;5;241m.\u001b[39misnan(out)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/hephaestus/models/simple_time_series.py:255\u001b[0m, in \u001b[0;36mTimeSeriesTransformer.__call__\u001b[0;34m(self, numeric_inputs, deterministic)\u001b[0m\n\u001b[1;32m    251\u001b[0m ic(numeric_broadcast\u001b[38;5;241m.\u001b[39mshape, numeric_col_embeddings\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# ic(f\"Nan values in out positional: {jnp.isnan(numeric_broadcast).any()}\")\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# ic(\"Starting Attention\")\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# ic(numeric_broadcast.shape)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO Make this more elegant\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_ff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_broadcast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_col_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_broadcast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO differentiate this\u001b[39;49;00m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# ic(f\"Nan values in out 1st mha: {jnp.isnan(out).any()}\")\u001b[39;00m\n\u001b[1;32m    269\u001b[0m out \u001b[38;5;241m=\u001b[39m TransformerBlock(\n\u001b[1;32m    270\u001b[0m     d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m16\u001b[39m,  \u001b[38;5;66;03m# TODO Make this more elegant\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads,\n\u001b[1;32m    272\u001b[0m     d_ff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m    273\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m    274\u001b[0m )(q\u001b[38;5;241m=\u001b[39mout, k\u001b[38;5;241m=\u001b[39mout, v\u001b[38;5;241m=\u001b[39mout, deterministic\u001b[38;5;241m=\u001b[39mdeterministic, mask\u001b[38;5;241m=\u001b[39mmask)\n","    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/hephaestus/models/simple_time_series.py:90\u001b[0m, in \u001b[0;36mTransformerBlock.__call__\u001b[0;34m(self, q, k, v, deterministic, mask)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Write out the jax array to a file for more debugging\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     attention \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHeadDotProductAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqkv_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     out \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m+\u001b[39m attention\n\u001b[1;32m     96\u001b[0m     out \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm()(out)\n","    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/flax/linen/attention.py:546\u001b[0m, in \u001b[0;36mMultiHeadDotProductAttention.__call__\u001b[0;34m(self, inputs_q, inputs_k, inputs_v, inputs_kv, mask, deterministic, dropout_rng, sow_weights)\u001b[0m\n\u001b[1;32m    532\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_fn(\n\u001b[1;32m    533\u001b[0m     query,\n\u001b[1;32m    534\u001b[0m     key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m     module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    544\u001b[0m   )  \u001b[38;5;66;03m# pytype: disable=wrong-keyword-args\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 546\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm_deterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# back to the original inputs dimensions\u001b[39;00m\n\u001b[1;32m    559\u001b[0m out \u001b[38;5;241m=\u001b[39m DenseGeneral(\n\u001b[1;32m    560\u001b[0m   features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    561\u001b[0m   axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    570\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    571\u001b[0m )(x)\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/flax/linen/attention.py:198\u001b[0m, in \u001b[0;36mdot_product_attention\u001b[0;34m(query, key, value, bias, mask, broadcast_dropout, dropout_rng, dropout_rate, deterministic, dtype, precision, module)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m key\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk, v lengths must match.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# compute attention weights\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mdot_product_attention_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m  \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m  \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbroadcast_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdropout_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# return weighted sum over values for each query position\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39meinsum(\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...hqk,...khd->...qhd\u001b[39m\u001b[38;5;124m'\u001b[39m, attn_weights, value, precision\u001b[38;5;241m=\u001b[39mprecision\n\u001b[1;32m    215\u001b[0m )\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/flax/linen/attention.py:112\u001b[0m, in \u001b[0;36mdot_product_attention_weights\u001b[0;34m(query, key, bias, mask, broadcast_dropout, dropout_rng, dropout_rate, deterministic, dtype, precision, module)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m   big_neg \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mfinfo(dtype)\u001b[38;5;241m.\u001b[39mmin\n\u001b[0;32m--> 112\u001b[0m   attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_neg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# normalize the attention weights\u001b[39;00m\n\u001b[1;32m    115\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(attn_weights)\u001b[38;5;241m.\u001b[39mastype(dtype)\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1141\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(acondition, if_true, if_false, size, fill_value, condition, x, y)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize and fill_value arguments cannot be used in three-term where function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43macondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_false\u001b[49m\u001b[43m)\u001b[49m\n","    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/util.py:448\u001b[0m, in \u001b[0;36m_where\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    446\u001b[0m   condition \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mne(condition, lax\u001b[38;5;241m.\u001b[39m_zero(condition))\n\u001b[1;32m    447\u001b[0m x, y \u001b[38;5;241m=\u001b[39m promote_dtypes(x, y)\n\u001b[0;32m--> 448\u001b[0m condition_arr, x_arr, y_arr \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m   is_always_empty \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mis_empty_shape(x_arr\u001b[38;5;241m.\u001b[39mshape)\n","    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/util.py:407\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shapes \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(shapes[\u001b[38;5;241m0\u001b[39m], s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m shapes):\n\u001b[1;32m    406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [lax\u001b[38;5;241m.\u001b[39masarray(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 407\u001b[0m result_shape \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [_broadcast_to(arg, result_shape) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","File \u001b[0;32m~/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:171\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    169\u001b[0m result_shape \u001b[38;5;241m=\u001b[39m _try_broadcast_shapes(shape_list)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_shape\n","\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(4, 59, 59), (4, 59, 4, 26, 26), ()]"]}],"source":["key = random.PRNGKey(0)\n","init_key, dropout_key = random.split(key)\n","vars = time_series_regressor.init(\n","    {\"params\": init_key, \"dropout\": dropout_key}, batch, deterministic=False\n",")\n","dropout_key, original_dropout_key = random.split(dropout_key)\n","x = time_series_regressor.apply(\n","    vars, batch, deterministic=False, rngs={\"dropout\": dropout_key}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                   SimplePred Summary                                                   </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> path                  </span>┃<span style=\"font-weight: bold\"> module                </span>┃<span style=\"font-weight: bold\"> inputs                </span>┃<span style=\"font-weight: bold\"> outputs               </span>┃<span style=\"font-weight: bold\"> params               </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n","│                       │ SimplePred            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26]      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26]      │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ TimeSeriesTransformer │ deterministic: False  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ numeric_inputs:       │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26]      │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Embed                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[26]             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[26,256]       │ embedding:           │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[29,256]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">7,424 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(29.7 KB)</span>      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ PositionalEncoding    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,256]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ TransformerBlock      │ deterministic: False  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ k:                    │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,256]  │                       │                      │\n","│                       │                       │ q:                    │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ v:                    │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ MultiHeadDotProductA… │ -                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,256]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","│                       │                       │   mask: None          │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,256]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">69,904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(279.6 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68,272]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.2 KB)</span>         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ FeedForwardNetwork    │ -                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]    │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,64]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">17,472 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(69.9 KB)</span>     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ - <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64]   │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,272]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">17,680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(70.7 KB)</span>     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ -                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.2 KB)</span>         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ TransformerBlock      │ deterministic: False  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ k:                    │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ q:                    │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ v:                    │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ MultiHeadDotProductA… │ -                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","│                       │                       │   mask: None          │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,4,68] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,68,272]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">74,256 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(297.0 KB)</span>    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.2 KB)</span>         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ FeedForwardNetwork    │ -                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]    │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,64]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">17,472 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(69.9 KB)</span>     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ - <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64]   │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,64]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,272]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">17,680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(70.7 KB)</span>     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ -                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                      │\n","│                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]   │\n","│                       │                       │                       │                       │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.2 KB)</span>         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ RegressionOutputChain │ Sequential            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,1]    │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ RegressionDense1      │ Dense                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,272]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,512]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[272,512]     │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">139,776 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(559.1 KB)</span>   │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ RegressionDense2      │ Dense                 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,512]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,59,26,1]    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]     │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1]       │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ <span style=\"font-weight: bold\">513 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.1 KB)</span>         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│<span style=\"font-weight: bold\">                       </span>│<span style=\"font-weight: bold\">                       </span>│<span style=\"font-weight: bold\">                       </span>│<span style=\"font-weight: bold\">                 Total </span>│<span style=\"font-weight: bold\"> 809,889 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.2 MB)</span><span style=\"font-weight: bold\">     </span>│\n","└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────────┴──────────────────────┘\n","<span style=\"font-weight: bold\">                                                                                                                        </span>\n","<span style=\"font-weight: bold\">                                           Total Parameters: 809,889 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.2 MB)</span><span style=\"font-weight: bold\">                                           </span>\n","</pre>\n"],"text/plain":["\u001b[3m                                                   SimplePred Summary                                                   \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mpath                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams              \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n","│                       │ SimplePred            │ \u001b[2mfloat32\u001b[0m[4,59,26]      │ \u001b[2mfloat32\u001b[0m[4,59,26]      │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ TimeSeriesTransformer │ deterministic: False  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ numeric_inputs:       │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26]      │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Embed                 │ \u001b[2mint32\u001b[0m[26]             │ \u001b[2mfloat32\u001b[0m[26,256]       │ embedding:           │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[29,256]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m7,424 \u001b[0m\u001b[1;2m(29.7 KB)\u001b[0m      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ PositionalEncoding    │ \u001b[2mfloat32\u001b[0m[4,59,26,256]  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ TransformerBlock      │ deterministic: False  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ k:                    │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,256]  │                       │                      │\n","│                       │                       │ q:                    │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ v:                    │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ MultiHeadDotProductA… │ -                     │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,256]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","│                       │                       │   mask: None          │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ bias: \u001b[2mfloat32\u001b[0m[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,256]  │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ bias: \u001b[2mfloat32\u001b[0m[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[256,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m69,904 \u001b[0m\u001b[1;2m(279.6 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ bias: \u001b[2mfloat32\u001b[0m[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[4,68,272]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ scale: \u001b[2mfloat32\u001b[0m[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m544 \u001b[0m\u001b[1;2m(2.2 KB)\u001b[0m         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ FeedForwardNetwork    │ -                     │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]    │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,64]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m17,472 \u001b[0m\u001b[1;2m(69.9 KB)\u001b[0m     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ - \u001b[2mfloat32\u001b[0m[4,59,26,64] │ \u001b[2mfloat32\u001b[0m[4,59,26,64]   │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ \u001b[2mfloat32\u001b[0m[4,59,26,64]   │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[64,272]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m17,680 \u001b[0m\u001b[1;2m(70.7 KB)\u001b[0m     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ -                     │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ scale: \u001b[2mfloat32\u001b[0m[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m544 \u001b[0m\u001b[1;2m(2.2 KB)\u001b[0m         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ TransformerBlock      │ deterministic: False  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ k:                    │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ q:                    │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ v:                    │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ MultiHeadDotProductA… │ -                     │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ -                     │                       │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","│                       │                       │   mask: None          │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ bias: \u001b[2mfloat32\u001b[0m[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ bias: \u001b[2mfloat32\u001b[0m[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ bias: \u001b[2mfloat32\u001b[0m[4,68]  │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,4,68]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ DenseGeneral          │ \u001b[2mfloat32\u001b[0m[4,59,26,4,68] │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[4,68,272]    │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m74,256 \u001b[0m\u001b[1;2m(297.0 KB)\u001b[0m    │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ scale: \u001b[2mfloat32\u001b[0m[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m544 \u001b[0m\u001b[1;2m(2.2 KB)\u001b[0m         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ FeedForwardNetwork    │ -                     │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]    │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,64]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m17,472 \u001b[0m\u001b[1;2m(69.9 KB)\u001b[0m     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ - \u001b[2mfloat32\u001b[0m[4,59,26,64] │ \u001b[2mfloat32\u001b[0m[4,59,26,64]   │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dense                 │ \u001b[2mfloat32\u001b[0m[4,59,26,64]   │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[64,272]      │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m17,680 \u001b[0m\u001b[1;2m(70.7 KB)\u001b[0m     │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ Dropout               │ -                     │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                      │\n","│                       │                       │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │                       │                      │\n","│                       │                       │ - deterministic:      │                       │                      │\n","│                       │                       │ False                 │                       │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ TimeSeriesTransforme… │ LayerNorm             │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ bias: \u001b[2mfloat32\u001b[0m[272]   │\n","│                       │                       │                       │                       │ scale: \u001b[2mfloat32\u001b[0m[272]  │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m544 \u001b[0m\u001b[1;2m(2.2 KB)\u001b[0m         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ RegressionOutputChain │ Sequential            │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,1]    │                      │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ RegressionDense1      │ Dense                 │ \u001b[2mfloat32\u001b[0m[4,59,26,272]  │ \u001b[2mfloat32\u001b[0m[4,59,26,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]   │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[272,512]     │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m139,776 \u001b[0m\u001b[1;2m(559.1 KB)\u001b[0m   │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│ RegressionDense2      │ Dense                 │ \u001b[2mfloat32\u001b[0m[4,59,26,512]  │ \u001b[2mfloat32\u001b[0m[4,59,26,1]    │ bias: \u001b[2mfloat32\u001b[0m[1]     │\n","│                       │                       │                       │                       │ kernel:              │\n","│                       │                       │                       │                       │ \u001b[2mfloat32\u001b[0m[512,1]       │\n","│                       │                       │                       │                       │                      │\n","│                       │                       │                       │                       │ \u001b[1m513 \u001b[0m\u001b[1;2m(2.1 KB)\u001b[0m         │\n","├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────────┼──────────────────────┤\n","│\u001b[1m \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m809,889 \u001b[0m\u001b[1;2m(3.2 MB)\u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\n","└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────────┴──────────────────────┘\n","\u001b[1m                                                                                                                        \u001b[0m\n","\u001b[1m                                           Total Parameters: 809,889 \u001b[0m\u001b[1;2m(3.2 MB)\u001b[0m\u001b[1m                                           \u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'\\n\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["time_series_regressor.tabulate(\n","    {\"params\": init_key, \"dropout\": dropout_key},\n","    batch,\n","    console_kwargs={\"force_jupyter\": True, \"width\": 120},\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory of custom: 3.24 MB with 809,889 parameters\n"]}],"source":["def calculate_memory_footprint(params):\n","    \"\"\"Calculate total memory footprint of JAX model parameters and total\n","    number of parameters.\"\"\"\n","    total_bytes = 0\n","    # Flatten the parameter tree structure into a list of arrays\n","    flat_params, _ = tree_flatten(params)\n","    for param in flat_params:\n","        # Calculate bytes: number of elements * size of each element\n","        bytes_per_param = param.size * param.dtype.itemsize\n","        total_bytes += bytes_per_param\n","    return total_bytes\n","\n","\n","def count_parameters(params):\n","    return sum(jnp.prod(jnp.array(p.shape)) for p in jax.tree_util.tree_leaves(params))\n","\n","\n","mem = calculate_memory_footprint(vars)\n","total_params = count_parameters(vars)\n","\n","\n","print(f\"Memory of custom: {mem / 1e6:.2f} MB with {total_params:,} parameters\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(4, 59, 26)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["batch.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_causal_mask(tensor: jnp.ndarray):\n","    \"\"\"Create a causal mask to mask out future values.\"\"\"\n","    mask = jnp.tril(jnp.ones((tensor.shape[0], tensor.shape[1])))\n","    return mask\n","\n","\n","def create_padding_mask(tensor: jnp.ndarray):\n","    \"\"\"Create a padding mask to mask out padded values.\"\"\"\n","    mask = jnp.isnan(tensor)\n","    return mask\n","\n","\n","def mask_array(tensor: jnp.array):\n","    \"\"\"Create a mask for the tensor\"\"\"\n","    causal_mask = create_causal_mask(tensor)\n","    padding_mask = create_padding_mask(tensor)\n","    mask = jnp.logical_or(causal_mask, padding_mask)\n","    return mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(59, 26)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["jnp.array(train_ds[0]).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;31mSignature:\u001b[0m\n","\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mquery_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mkey_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mpairwise_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mPjitFunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x12b55f250\u001b[0m\u001b[0;34m>>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mextra_batch_dims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportsDType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'jax.numpy.float32'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDocstring:\u001b[0m\n","Mask-making helper for attention weights.\n","\n","In case of 1d inputs (i.e., ``[batch..., len_q]``, ``[batch..., len_kv]``, the\n","attention weights will be ``[batch..., heads, len_q, len_kv]`` and this\n","function will produce ``[batch..., 1, len_q, len_kv]``.\n","\n","Args:\n","  query_input: a batched, flat input of query_length size\n","  key_input: a batched, flat input of key_length size\n","  pairwise_fn: broadcasting elementwise comparison function\n","  extra_batch_dims: number of extra batch dims to add singleton axes for, none\n","    by default\n","  dtype: mask return dtype\n","\n","Returns:\n","  A ``[batch..., 1, len_q, len_kv]`` shaped mask for 1d attention.\n","\u001b[0;31mFile:\u001b[0m      ~/Hephaestus/.venv/lib/python3.10/site-packages/flax/linen/attention.py\n","\u001b[0;31mType:\u001b[0m      function"]}],"source":["from flax import linen as nn\n","\n","?nn.make_attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[[ 1.,  2.,  3.,  4.,  5.],\n","        [ 2.,  4.,  6.,  8., 10.],\n","        [ 3.,  6.,  9., 12., 15.],\n","        [ 4.,  8., 12., 16., 20.],\n","        [ 5., 10., 15., 20., 25.],\n","        [ 6., 12., 18., 24., 30.],\n","        [ 7., 14., 21., 28., 35.],\n","        [ 8., 16., 24., 32., 40.],\n","        [ 9., 18., 27., 36., 45.],\n","        [10., 20., 30., 40., 50.]]], dtype=float32)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["nn.make_attention_mask(\n","    jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]),\n","    jnp.array([1, 2, 3, 4, 5]),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4dd64f565fcf4b259ef24944493477bf","25ce5408138f4cb28e163f1fdffdee5f","47793d3155614c8cbd7d3337dcb2f895","f9ec11073e484927a4cc1ee2e3da132f","62e750769d364ab2b80d5b9646b10ea6","8b35a70a3b9e4f3b87cf2a7280439ac6","0e26d28846fb449789510e4748c01c6a","f8093c8ddeec4c55ac6cc5f8f7df30bf","4151c7353de54909aa9deecbe8c1e1e1","9ced4485d5c641eda90ab0634e0691d3","6f5ca39406174a4fb1bee9eb1e35fccb","5e15315a77864badafe48c2baf31b030","dfd9dd713862479bba73b6c0a12a1902","88be535ce5a945f4979fe72d9f086365","31d37adf891a4da68675945509051210","4da9993585914618a35d8d5382fef850","acee2c1ed91e44188d5ca40bddace4b1","cc57eeb92d32434ca82b7c3f669865d1","f8382d8bbb7f42f6a0f4d4028203615f","851b29291123491a821b1ce8088ca785","055681c8159b4b6c8104d4e06279803c","9f5e5843559b4f9e8f3440ebd85743f8","a317a54aa1a349f490e388aacb2d1e4d","c470a61e692a4459988f63f0024f7eac","5edd903b07594d128ded9b4844835159","2ac0cceac38e43adb00a10b778fad2df","c7f61bdee3ca4ca0a3f7d021aa558deb","70c7b641da5c4b82bbd5b2e1750f3b39","462d9e93a94f44868fec1ece82f0a241","4bc81f6d94394d7f90e070d8b11a7059","d3bc58d04d5f42a5a24bd467a9569e01","ddb1791795134ac0a754748f9793c214","d95aea2b915b44f38b5090ee186abafd","01ca2dcb14e647dfb1e68750ca6de39c","a51aa7b827db4f768dce6315dbebf379","634935ff0a6b4d65b72f87359d9f82fc","09b63c98bee543dfb557a007d50c41d1","dc4a8a3b0a8b4ef49dcd6269a1b32e14","5f1fb4d40e154e27baa0d4f330df540e","948787e6434f419a86d9d7da831e2572","e4de75777bba4d72b61936baf3d84cbb","0481743e80634f7a8e718fb528950e54","2fb36a08ca1540228919af722727572c","3bd47d84fac442d4bcf49dceeb699d45"]},"executionInfo":{"elapsed":841688,"status":"ok","timestamp":1708904334771,"user":{"displayName":"Kai Lukowiak","userId":"12340107642472090190"},"user_tz":420},"id":"RIXu3GkdYzNA","outputId":"dee6137d-c096-4df6-fbb4-baa3764d359e"},"outputs":[],"source":["mts_root_key = random.PRNGKey(44)\n","mts_main_key, ts_params_key, ts_data_key = random.split(mts_root_key, 3)\n","\n","\n","def clip_gradients(gradients, max_norm):\n","    total_norm = jnp.sqrt(sum(jnp.sum(jnp.square(grad)) for grad in gradients.values()))\n","    scale = max_norm / (total_norm + 1e-6)\n","    clipped_gradients = jax.tree_map(\n","        lambda grad: jnp.where(total_norm > max_norm, grad * scale, grad), gradients\n","    )\n","    return clipped_gradients\n","\n","\n","def base_loss(inputs, outputs):\n","    # Create mask for nan inputs\n","    nan_mask = jnp.isnan(inputs)\n","    inputs = jnp.where(nan_mask, jnp.zeros_like(inputs), inputs)\n","    outputs = jnp.where(nan_mask, jnp.zeros_like(outputs), outputs)\n","\n","    raw_loss = optax.squared_error(outputs, inputs)\n","    masked_loss = jnp.where(nan_mask, 0.0, raw_loss)\n","    loss = masked_loss.sum() / (~nan_mask).sum()\n","\n","    return loss\n","\n","\n","def calculate_loss(params, state, inputs, dataset: SimpleDS, dropout_key, mask_key):\n","    outputs = state.apply_fn(\n","        {\"params\": params},\n","        # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","        inputs,\n","        rngs={\"dropout\": dropout_key},\n","        deterministic=False,\n","    )\n","    loss = base_loss(inputs, outputs)\n","    # Create mask for nan inputs\n","\n","    return loss\n","\n","\n","@jax.jit\n","def train_step(state: train_state.TrainState, batch, base_key):\n","    dropout_key, mask_key, new_key = jax.random.split(base_key, 3)\n","\n","    def loss_fn(params):\n","        return calculate_loss(params, state, batch, train_ds, dropout_key, mask_key)\n","\n","    grad_fn = jax.value_and_grad(loss_fn)\n","\n","    # (loss, individual_losses), grad = grad_fn(state.params)\n","    loss, grad = grad_fn(state.params)\n","    # grad = replace_nans(grad)\n","    # grad = clip_gradients(grad, 1.0)\n","    state = state.apply_gradients(grads=grad)\n","\n","    return state, loss, new_key\n","\n","\n","def evaluate(params, state, inputs, dataset: SimpleDS, dropout_key, mask_key):\n","    outputs = state.apply_fn(\n","        {\"params\": params},\n","        # hp.mask_tensor(inputs, dataset, prng_key=mask_key),\n","        inputs,\n","        deterministic=True,\n","    )\n","    loss = base_loss(inputs, outputs)\n","    return loss\n","\n","\n","@jax.jit\n","def eval_step(state: train_state.TrainState, batch, base_key):\n","    mask_key, dropout_key, new_key = jax.random.split(base_key, 3)\n","\n","    def loss_fn(params):\n","        return evaluate(params, state, batch, train_ds, dropout_key, mask_key)\n","\n","    # (loss, individual_losses), grad = grad_fn(state.params)\n","    loss = loss_fn(state.params)\n","    return loss, new_key\n","\n","\n","def create_train_state(model, prng, batch, lr):\n","    init_key, dropout_key = random.split(prng)\n","    params = model.init(\n","        {\"params\": init_key, \"dropout\": dropout_key}, batch, deterministic=False\n","    )\n","    # optimizer = optax.chain(optax.adam(lr))\n","    optimizer = optax.chain(optax.clip_by_global_norm(0.4), optax.adam(lr))\n","    # optimizer_state = optimizer.init(params)\n","    return train_state.TrainState.create(\n","        apply_fn=model.apply,\n","        params=params[\"params\"],\n","        tx=optimizer,\n","        # tx_state=optimizer_state,\n","    )\n","\n","\n","batch_size = 2\n","# batch = train_ds[0]\n","# state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)\n","state = create_train_state(time_series_regressor, mts_main_key, batch, 0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31296ba81c9a464b9c238f5c66ace6a7","version_major":2,"version_minor":0},"text/plain":["epochs for runs/2024-05-23T17:17:21CausalMask:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8adcda526cca477ba9132f908aa28ae8","version_major":2,"version_minor":0},"text/plain":["batches:   0%|          | 0/196 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["writer_name = \"CausalMask\"\n","\n","writer_time = dt.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n","\n","train_summary_writer = SummaryWriter(\"runs/\" + writer_time + writer_name)\n","\n","\n","test_set_key = random.PRNGKey(4454)\n","\n","train_data_loader = DataLoader(train_ds, batch_size=512, shuffle=True)\n","test_data_loader = DataLoader(test_ds, batch_size=512, shuffle=True)\n","batch_count = 0\n","base_key = random.PRNGKey(42)\n","\n","for j in trange(1, desc=f\"epochs for {train_summary_writer.log_dir}\"):\n","    # arrs = train_data_loader()\n","    for i in tqdm(train_data_loader, leave=False, desc=\"batches\"):\n","        # for i in trange(len(pre_train) // batch_size, leave=False):\n","        # for i in trange(len(pre_train) // batch_size //10, leave=False):\n","        # batch = make_batch(train_ds, i[0], 4)\n","\n","        state, loss, base_key = train_step(state, jnp.array(i), base_key)\n","        if jnp.isnan(loss):\n","            raise ValueError(\"Nan Value in loss, stopping\")\n","        batch_count += 1\n","\n","        if batch_count % 1 == 0:\n","            train_summary_writer.add_scalar(\n","                \"loss/loss\", np.array(loss.item()), batch_count\n","            )\n","        if batch_count % 10 == 0:\n","            test_loss, base_key = eval_step(\n","                state, jnp.array(next(iter(test_data_loader))), base_key\n","            )\n","            train_summary_writer.add_scalar(\n","                \"loss/test_loss\", np.array(test_loss.item()), batch_count\n","            )\n","\n","train_summary_writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from jax import random\n","\n","test_key = jax.random.key(12)\n","att = random.normal(test_key, (2, 10, 6, 16))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(1, 59, 26)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["def return_results(state, dataset, key):\n","    outputs = state.apply_fn(\n","        {\"params\": state.params},\n","        # hp.mask_tensor(jnp.array([train_ds[0]]), dataset, prng_key=key),\n","        jnp.array([dataset[0]]),\n","        deterministic=True,\n","    )\n","    return outputs\n","\n","\n","# test_result = jnp.squeeze(\n","#     state.apply_fn({\"params\": state.params}, jnp.array([train_ds[0]]))\n","# )\n","test_result = return_results(state, train_ds, test_key)\n","test_result.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(59, 26)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["jnp.squeeze(test_result).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_result = jnp.squeeze(test_result)\n","df_pred = pd.DataFrame(test_result)\n","df_actual = pd.DataFrame(train_ds[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["((5, 26), (5, 27))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_pred.head().shape, train_df.head().shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_pred.columns = train_df.drop(\"idx\", axis=1).columns\n","df_actual.columns = train_df.drop(\"idx\", axis=1).columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>planet0_e</th>\n","      <th>...</th>\n","      <th>planet3_x</th>\n","      <th>planet3_y</th>\n","      <th>planet3_m</th>\n","      <th>planet3_a</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>1.560060</td>\n","      <td>-0.854437</td>\n","      <td>0.720639</td>\n","      <td>0.691729</td>\n","      <td>0.944008</td>\n","      <td>2.700632</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.465116</td>\n","      <td>1.689858</td>\n","      <td>-0.514359</td>\n","      <td>0.333295</td>\n","      <td>0.942289</td>\n","      <td>0.681604</td>\n","      <td>2.785811</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.930233</td>\n","      <td>1.753589</td>\n","      <td>-0.154209</td>\n","      <td>-0.124995</td>\n","      <td>0.992368</td>\n","      <td>0.412951</td>\n","      <td>2.845461</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.395349</td>\n","      <td>1.748068</td>\n","      <td>0.212022</td>\n","      <td>-0.556775</td>\n","      <td>0.831727</td>\n","      <td>0.140540</td>\n","      <td>2.879232</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.860465</td>\n","      <td>1.673573</td>\n","      <td>0.569904</td>\n","      <td>-0.870579</td>\n","      <td>0.494812</td>\n","      <td>-0.133144</td>\n","      <td>2.887018</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.325581</td>\n","      <td>1.533811</td>\n","      <td>0.905607</td>\n","      <td>-1.000151</td>\n","      <td>0.053178</td>\n","      <td>-0.405638</td>\n","      <td>2.868949</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2.790698</td>\n","      <td>1.335526</td>\n","      <td>1.206832</td>\n","      <td>-0.918192</td>\n","      <td>-0.399688</td>\n","      <td>-0.674530</td>\n","      <td>2.825381</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3.255814</td>\n","      <td>1.087824</td>\n","      <td>1.463513</td>\n","      <td>-0.641980</td>\n","      <td>-0.767958</td>\n","      <td>-0.937474</td>\n","      <td>2.756889</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>3.720930</td>\n","      <td>0.801365</td>\n","      <td>1.668203</td>\n","      <td>-0.229808</td>\n","      <td>-0.973515</td>\n","      <td>-1.192211</td>\n","      <td>2.664256</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4.186047</td>\n","      <td>0.487549</td>\n","      <td>1.816168</td>\n","      <td>0.231092</td>\n","      <td>-0.972449</td>\n","      <td>-1.436585</td>\n","      <td>2.548458</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>4.651163</td>\n","      <td>0.157822</td>\n","      <td>1.905225</td>\n","      <td>0.642811</td>\n","      <td>-0.764575</td>\n","      <td>-1.668554</td>\n","      <td>2.410650</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>5.116279</td>\n","      <td>-0.176870</td>\n","      <td>1.935436</td>\n","      <td>0.917559</td>\n","      <td>-0.393801</td>\n","      <td>-1.886207</td>\n","      <td>2.252158</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5.581395</td>\n","      <td>-0.506443</td>\n","      <td>1.908720</td>\n","      <td>0.996574</td>\n","      <td>0.061000</td>\n","      <td>-2.087774</td>\n","      <td>2.074456</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>6.046512</td>\n","      <td>-0.821885</td>\n","      <td>1.828463</td>\n","      <td>0.862921</td>\n","      <td>0.502832</td>\n","      <td>-2.271633</td>\n","      <td>1.879159</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>6.511628</td>\n","      <td>-1.115352</td>\n","      <td>1.699162</td>\n","      <td>0.545212</td>\n","      <td>0.837490</td>\n","      <td>-2.436322</td>\n","      <td>1.668004</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>6.976744</td>\n","      <td>-1.380170</td>\n","      <td>1.526119</td>\n","      <td>0.111347</td>\n","      <td>0.993853</td>\n","      <td>-2.580544</td>\n","      <td>1.442838</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>7.441860</td>\n","      <td>-1.610795</td>\n","      <td>1.315203</td>\n","      <td>-0.346239</td>\n","      <td>0.939015</td>\n","      <td>-2.703172</td>\n","      <td>1.205599</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>7.906977</td>\n","      <td>-1.802741</td>\n","      <td>1.072663</td>\n","      <td>-0.730422</td>\n","      <td>0.685027</td>\n","      <td>-2.803255</td>\n","      <td>0.958309</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>8.372093</td>\n","      <td>-1.952503</td>\n","      <td>0.804994</td>\n","      <td>-0.959957</td>\n","      <td>0.286020</td>\n","      <td>-2.880023</td>\n","      <td>0.703051</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>8.837209</td>\n","      <td>-2.057485</td>\n","      <td>0.518845</td>\n","      <td>-0.986439</td>\n","      <td>-0.173427</td>\n","      <td>-2.932885</td>\n","      <td>0.441961</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>9.302326</td>\n","      <td>-2.115938</td>\n","      <td>0.220954</td>\n","      <td>-0.804305</td>\n","      <td>-0.596103</td>\n","      <td>-2.961438</td>\n","      <td>0.177211</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>9.767442</td>\n","      <td>-2.126912</td>\n","      <td>-0.081893</td>\n","      <td>-0.451965</td>\n","      <td>-0.892498</td>\n","      <td>-2.965464</td>\n","      <td>-0.089004</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>10.232558</td>\n","      <td>-2.090237</td>\n","      <td>-0.382893</td>\n","      <td>-0.003872</td>\n","      <td>-0.999585</td>\n","      <td>-2.944932</td>\n","      <td>-0.354477</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>10.697674</td>\n","      <td>-2.006509</td>\n","      <td>-0.675252</td>\n","      <td>0.444975</td>\n","      <td>-0.894252</td>\n","      <td>-2.899997</td>\n","      <td>-0.617010</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>11.162791</td>\n","      <td>-1.877113</td>\n","      <td>-0.952210</td>\n","      <td>0.799049</td>\n","      <td>-0.598498</td>\n","      <td>-2.831004</td>\n","      <td>-0.874419</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>11.627907</td>\n","      <td>-1.704255</td>\n","      <td>-1.207074</td>\n","      <td>0.982727</td>\n","      <td>-0.175061</td>\n","      <td>-2.738478</td>\n","      <td>-1.124556</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>12.093023</td>\n","      <td>-1.491017</td>\n","      <td>-1.433278</td>\n","      <td>0.956673</td>\n","      <td>0.285841</td>\n","      <td>-2.623132</td>\n","      <td>-1.365315</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>12.558140</td>\n","      <td>-1.241423</td>\n","      <td>-1.624455</td>\n","      <td>0.726448</td>\n","      <td>0.685888</td>\n","      <td>-2.485858</td>\n","      <td>-1.594656</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>13.023256</td>\n","      <td>-0.960518</td>\n","      <td>-1.774551</td>\n","      <td>0.341306</td>\n","      <td>0.939879</td>\n","      <td>-2.327724</td>\n","      <td>-1.810607</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>13.488372</td>\n","      <td>-0.654444</td>\n","      <td>-1.877989</td>\n","      <td>-0.116555</td>\n","      <td>0.994010</td>\n","      <td>-2.149972</td>\n","      <td>-2.011292</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>13.953488</td>\n","      <td>-0.330492</td>\n","      <td>-1.929876</td>\n","      <td>-0.549761</td>\n","      <td>0.837182</td>\n","      <td>-1.954013</td>\n","      <td>-2.194933</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>14.418605</td>\n","      <td>0.002871</td>\n","      <td>-1.926281</td>\n","      <td>-0.866538</td>\n","      <td>0.503039</td>\n","      <td>-1.741415</td>\n","      <td>-2.359874</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>14.883721</td>\n","      <td>0.336052</td>\n","      <td>-1.864565</td>\n","      <td>-1.000002</td>\n","      <td>0.062565</td>\n","      <td>-1.513904</td>\n","      <td>-2.504591</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>15.348837</td>\n","      <td>0.658485</td>\n","      <td>-1.743757</td>\n","      <td>-0.922043</td>\n","      <td>-0.390993</td>\n","      <td>-1.273345</td>\n","      <td>-2.627708</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>15.813953</td>\n","      <td>0.958914</td>\n","      <td>-1.564952</td>\n","      <td>-0.649103</td>\n","      <td>-0.761665</td>\n","      <td>-1.021741</td>\n","      <td>-2.728011</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>16.279070</td>\n","      <td>1.225853</td>\n","      <td>-1.331663</td>\n","      <td>-0.238785</td>\n","      <td>-0.970834</td>\n","      <td>-0.761211</td>\n","      <td>-2.804462</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>16.744186</td>\n","      <td>1.448211</td>\n","      <td>-1.050060</td>\n","      <td>0.222075</td>\n","      <td>-0.973830</td>\n","      <td>-0.493987</td>\n","      <td>-2.856214</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>17.209302</td>\n","      <td>1.616059</td>\n","      <td>-0.729007</td>\n","      <td>0.635585</td>\n","      <td>-0.769602</td>\n","      <td>-0.222387</td>\n","      <td>-2.882622</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>17.674419</td>\n","      <td>1.721456</td>\n","      <td>-0.379819</td>\n","      <td>0.913575</td>\n","      <td>-0.401274</td>\n","      <td>0.051193</td>\n","      <td>-2.883258</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>18.139535</td>\n","      <td>1.759203</td>\n","      <td>-0.015710</td>\n","      <td>0.996587</td>\n","      <td>0.052806</td>\n","      <td>0.324305</td>\n","      <td>-2.857916</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>18.604651</td>\n","      <td>1.727385</td>\n","      <td>0.349052</td>\n","      <td>0.866830</td>\n","      <td>0.495796</td>\n","      <td>0.594465</td>\n","      <td>-2.806627</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>19.069767</td>\n","      <td>1.627587</td>\n","      <td>0.700142</td>\n","      <td>0.552081</td>\n","      <td>0.833240</td>\n","      <td>0.859181</td>\n","      <td>-2.729662</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>19.534884</td>\n","      <td>1.464716</td>\n","      <td>1.024199</td>\n","      <td>0.119611</td>\n","      <td>0.993425</td>\n","      <td>1.115970</td>\n","      <td>-2.627536</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>20.000000</td>\n","      <td>1.246492</td>\n","      <td>1.309683</td>\n","      <td>-0.338443</td>\n","      <td>0.942632</td>\n","      <td>1.362393</td>\n","      <td>-2.501014</td>\n","      <td>1.312562</td>\n","      <td>1.944263</td>\n","      <td>1.897807</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>59 rows × 26 columns</p>\n","</div>"],"text/plain":["    time_step  planet0_x  planet0_y  planet1_x  planet1_y  planet2_x  \\\n","0    0.000000   1.560060  -0.854437   0.720639   0.691729   0.944008   \n","1    0.465116   1.689858  -0.514359   0.333295   0.942289   0.681604   \n","2    0.930233   1.753589  -0.154209  -0.124995   0.992368   0.412951   \n","3    1.395349   1.748068   0.212022  -0.556775   0.831727   0.140540   \n","4    1.860465   1.673573   0.569904  -0.870579   0.494812  -0.133144   \n","5    2.325581   1.533811   0.905607  -1.000151   0.053178  -0.405638   \n","6    2.790698   1.335526   1.206832  -0.918192  -0.399688  -0.674530   \n","7    3.255814   1.087824   1.463513  -0.641980  -0.767958  -0.937474   \n","8    3.720930   0.801365   1.668203  -0.229808  -0.973515  -1.192211   \n","9    4.186047   0.487549   1.816168   0.231092  -0.972449  -1.436585   \n","10   4.651163   0.157822   1.905225   0.642811  -0.764575  -1.668554   \n","11   5.116279  -0.176870   1.935436   0.917559  -0.393801  -1.886207   \n","12   5.581395  -0.506443   1.908720   0.996574   0.061000  -2.087774   \n","13   6.046512  -0.821885   1.828463   0.862921   0.502832  -2.271633   \n","14   6.511628  -1.115352   1.699162   0.545212   0.837490  -2.436322   \n","15   6.976744  -1.380170   1.526119   0.111347   0.993853  -2.580544   \n","16   7.441860  -1.610795   1.315203  -0.346239   0.939015  -2.703172   \n","17   7.906977  -1.802741   1.072663  -0.730422   0.685027  -2.803255   \n","18   8.372093  -1.952503   0.804994  -0.959957   0.286020  -2.880023   \n","19   8.837209  -2.057485   0.518845  -0.986439  -0.173427  -2.932885   \n","20   9.302326  -2.115938   0.220954  -0.804305  -0.596103  -2.961438   \n","21   9.767442  -2.126912  -0.081893  -0.451965  -0.892498  -2.965464   \n","22  10.232558  -2.090237  -0.382893  -0.003872  -0.999585  -2.944932   \n","23  10.697674  -2.006509  -0.675252   0.444975  -0.894252  -2.899997   \n","24  11.162791  -1.877113  -0.952210   0.799049  -0.598498  -2.831004   \n","25  11.627907  -1.704255  -1.207074   0.982727  -0.175061  -2.738478   \n","26  12.093023  -1.491017  -1.433278   0.956673   0.285841  -2.623132   \n","27  12.558140  -1.241423  -1.624455   0.726448   0.685888  -2.485858   \n","28  13.023256  -0.960518  -1.774551   0.341306   0.939879  -2.327724   \n","29  13.488372  -0.654444  -1.877989  -0.116555   0.994010  -2.149972   \n","30  13.953488  -0.330492  -1.929876  -0.549761   0.837182  -1.954013   \n","31  14.418605   0.002871  -1.926281  -0.866538   0.503039  -1.741415   \n","32  14.883721   0.336052  -1.864565  -1.000002   0.062565  -1.513904   \n","33  15.348837   0.658485  -1.743757  -0.922043  -0.390993  -1.273345   \n","34  15.813953   0.958914  -1.564952  -0.649103  -0.761665  -1.021741   \n","35  16.279070   1.225853  -1.331663  -0.238785  -0.970834  -0.761211   \n","36  16.744186   1.448211  -1.050060   0.222075  -0.973830  -0.493987   \n","37  17.209302   1.616059  -0.729007   0.635585  -0.769602  -0.222387   \n","38  17.674419   1.721456  -0.379819   0.913575  -0.401274   0.051193   \n","39  18.139535   1.759203  -0.015710   0.996587   0.052806   0.324305   \n","40  18.604651   1.727385   0.349052   0.866830   0.495796   0.594465   \n","41  19.069767   1.627587   0.700142   0.552081   0.833240   0.859181   \n","42  19.534884   1.464716   1.024199   0.119611   0.993425   1.115970   \n","43  20.000000   1.246492   1.309683  -0.338443   0.942632   1.362393   \n","44        NaN        NaN        NaN        NaN        NaN        NaN   \n","45        NaN        NaN        NaN        NaN        NaN        NaN   \n","46        NaN        NaN        NaN        NaN        NaN        NaN   \n","47        NaN        NaN        NaN        NaN        NaN        NaN   \n","48        NaN        NaN        NaN        NaN        NaN        NaN   \n","49        NaN        NaN        NaN        NaN        NaN        NaN   \n","50        NaN        NaN        NaN        NaN        NaN        NaN   \n","51        NaN        NaN        NaN        NaN        NaN        NaN   \n","52        NaN        NaN        NaN        NaN        NaN        NaN   \n","53        NaN        NaN        NaN        NaN        NaN        NaN   \n","54        NaN        NaN        NaN        NaN        NaN        NaN   \n","55        NaN        NaN        NaN        NaN        NaN        NaN   \n","56        NaN        NaN        NaN        NaN        NaN        NaN   \n","57        NaN        NaN        NaN        NaN        NaN        NaN   \n","58        NaN        NaN        NaN        NaN        NaN        NaN   \n","\n","    planet2_y  planet0_m  planet0_a  planet0_e  ...  planet3_x  planet3_y  \\\n","0    2.700632   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","1    2.785811   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","2    2.845461   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","3    2.879232   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","4    2.887018   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","5    2.868949   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","6    2.825381   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","7    2.756889   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","8    2.664256   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","9    2.548458   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","10   2.410650   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","11   2.252158   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","12   2.074456   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","13   1.879159   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","14   1.668004   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","15   1.442838   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","16   1.205599   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","17   0.958309   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","18   0.703051   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","19   0.441961   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","20   0.177211   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","21  -0.089004   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","22  -0.354477   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","23  -0.617010   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","24  -0.874419   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","25  -1.124556   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","26  -1.365315   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","27  -1.594656   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","28  -1.810607   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","29  -2.011292   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","30  -2.194933   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","31  -2.359874   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","32  -2.504591   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","33  -2.627708   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","34  -2.728011   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","35  -2.804462   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","36  -2.856214   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","37  -2.882622   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","38  -2.883258   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","39  -2.857916   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","40  -2.806627   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","41  -2.729662   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","42  -2.627536   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","43  -2.501014   1.312562   1.944263   1.897807  ...        NaN        NaN   \n","44        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","45        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","46        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","47        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","48        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","49        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","50        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","51        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","52        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","53        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","54        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","55        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","56        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","57        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","58        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","\n","    planet3_m  planet3_a  planet3_e  planet4_x  planet4_y  planet4_m  \\\n","0         NaN        NaN        NaN        NaN        NaN        NaN   \n","1         NaN        NaN        NaN        NaN        NaN        NaN   \n","2         NaN        NaN        NaN        NaN        NaN        NaN   \n","3         NaN        NaN        NaN        NaN        NaN        NaN   \n","4         NaN        NaN        NaN        NaN        NaN        NaN   \n","5         NaN        NaN        NaN        NaN        NaN        NaN   \n","6         NaN        NaN        NaN        NaN        NaN        NaN   \n","7         NaN        NaN        NaN        NaN        NaN        NaN   \n","8         NaN        NaN        NaN        NaN        NaN        NaN   \n","9         NaN        NaN        NaN        NaN        NaN        NaN   \n","10        NaN        NaN        NaN        NaN        NaN        NaN   \n","11        NaN        NaN        NaN        NaN        NaN        NaN   \n","12        NaN        NaN        NaN        NaN        NaN        NaN   \n","13        NaN        NaN        NaN        NaN        NaN        NaN   \n","14        NaN        NaN        NaN        NaN        NaN        NaN   \n","15        NaN        NaN        NaN        NaN        NaN        NaN   \n","16        NaN        NaN        NaN        NaN        NaN        NaN   \n","17        NaN        NaN        NaN        NaN        NaN        NaN   \n","18        NaN        NaN        NaN        NaN        NaN        NaN   \n","19        NaN        NaN        NaN        NaN        NaN        NaN   \n","20        NaN        NaN        NaN        NaN        NaN        NaN   \n","21        NaN        NaN        NaN        NaN        NaN        NaN   \n","22        NaN        NaN        NaN        NaN        NaN        NaN   \n","23        NaN        NaN        NaN        NaN        NaN        NaN   \n","24        NaN        NaN        NaN        NaN        NaN        NaN   \n","25        NaN        NaN        NaN        NaN        NaN        NaN   \n","26        NaN        NaN        NaN        NaN        NaN        NaN   \n","27        NaN        NaN        NaN        NaN        NaN        NaN   \n","28        NaN        NaN        NaN        NaN        NaN        NaN   \n","29        NaN        NaN        NaN        NaN        NaN        NaN   \n","30        NaN        NaN        NaN        NaN        NaN        NaN   \n","31        NaN        NaN        NaN        NaN        NaN        NaN   \n","32        NaN        NaN        NaN        NaN        NaN        NaN   \n","33        NaN        NaN        NaN        NaN        NaN        NaN   \n","34        NaN        NaN        NaN        NaN        NaN        NaN   \n","35        NaN        NaN        NaN        NaN        NaN        NaN   \n","36        NaN        NaN        NaN        NaN        NaN        NaN   \n","37        NaN        NaN        NaN        NaN        NaN        NaN   \n","38        NaN        NaN        NaN        NaN        NaN        NaN   \n","39        NaN        NaN        NaN        NaN        NaN        NaN   \n","40        NaN        NaN        NaN        NaN        NaN        NaN   \n","41        NaN        NaN        NaN        NaN        NaN        NaN   \n","42        NaN        NaN        NaN        NaN        NaN        NaN   \n","43        NaN        NaN        NaN        NaN        NaN        NaN   \n","44        NaN        NaN        NaN        NaN        NaN        NaN   \n","45        NaN        NaN        NaN        NaN        NaN        NaN   \n","46        NaN        NaN        NaN        NaN        NaN        NaN   \n","47        NaN        NaN        NaN        NaN        NaN        NaN   \n","48        NaN        NaN        NaN        NaN        NaN        NaN   \n","49        NaN        NaN        NaN        NaN        NaN        NaN   \n","50        NaN        NaN        NaN        NaN        NaN        NaN   \n","51        NaN        NaN        NaN        NaN        NaN        NaN   \n","52        NaN        NaN        NaN        NaN        NaN        NaN   \n","53        NaN        NaN        NaN        NaN        NaN        NaN   \n","54        NaN        NaN        NaN        NaN        NaN        NaN   \n","55        NaN        NaN        NaN        NaN        NaN        NaN   \n","56        NaN        NaN        NaN        NaN        NaN        NaN   \n","57        NaN        NaN        NaN        NaN        NaN        NaN   \n","58        NaN        NaN        NaN        NaN        NaN        NaN   \n","\n","    planet4_a  planet4_e  \n","0         NaN        NaN  \n","1         NaN        NaN  \n","2         NaN        NaN  \n","3         NaN        NaN  \n","4         NaN        NaN  \n","5         NaN        NaN  \n","6         NaN        NaN  \n","7         NaN        NaN  \n","8         NaN        NaN  \n","9         NaN        NaN  \n","10        NaN        NaN  \n","11        NaN        NaN  \n","12        NaN        NaN  \n","13        NaN        NaN  \n","14        NaN        NaN  \n","15        NaN        NaN  \n","16        NaN        NaN  \n","17        NaN        NaN  \n","18        NaN        NaN  \n","19        NaN        NaN  \n","20        NaN        NaN  \n","21        NaN        NaN  \n","22        NaN        NaN  \n","23        NaN        NaN  \n","24        NaN        NaN  \n","25        NaN        NaN  \n","26        NaN        NaN  \n","27        NaN        NaN  \n","28        NaN        NaN  \n","29        NaN        NaN  \n","30        NaN        NaN  \n","31        NaN        NaN  \n","32        NaN        NaN  \n","33        NaN        NaN  \n","34        NaN        NaN  \n","35        NaN        NaN  \n","36        NaN        NaN  \n","37        NaN        NaN  \n","38        NaN        NaN  \n","39        NaN        NaN  \n","40        NaN        NaN  \n","41        NaN        NaN  \n","42        NaN        NaN  \n","43        NaN        NaN  \n","44        NaN        NaN  \n","45        NaN        NaN  \n","46        NaN        NaN  \n","47        NaN        NaN  \n","48        NaN        NaN  \n","49        NaN        NaN  \n","50        NaN        NaN  \n","51        NaN        NaN  \n","52        NaN        NaN  \n","53        NaN        NaN  \n","54        NaN        NaN  \n","55        NaN        NaN  \n","56        NaN        NaN  \n","57        NaN        NaN  \n","58        NaN        NaN  \n","\n","[59 rows x 26 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df_actual"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>planet0_e</th>\n","      <th>...</th>\n","      <th>planet3_x</th>\n","      <th>planet3_y</th>\n","      <th>planet3_m</th>\n","      <th>planet3_a</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.129779</td>\n","      <td>1.276990</td>\n","      <td>-1.113853</td>\n","      <td>0.466538</td>\n","      <td>0.584730</td>\n","      <td>0.772767</td>\n","      <td>2.230249</td>\n","      <td>1.278194</td>\n","      <td>1.708518</td>\n","      <td>1.507068</td>\n","      <td>...</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","      <td>-0.639018</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.230372</td>\n","      <td>1.296181</td>\n","      <td>-0.785724</td>\n","      <td>0.045093</td>\n","      <td>0.736830</td>\n","      <td>0.486601</td>\n","      <td>2.369161</td>\n","      <td>1.222250</td>\n","      <td>1.701897</td>\n","      <td>1.493344</td>\n","      <td>...</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","      <td>-0.541599</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.702104</td>\n","      <td>1.353345</td>\n","      <td>-0.363297</td>\n","      <td>-0.301331</td>\n","      <td>0.800037</td>\n","      <td>0.275401</td>\n","      <td>2.452332</td>\n","      <td>1.148241</td>\n","      <td>1.765875</td>\n","      <td>1.395555</td>\n","      <td>...</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","      <td>-0.522309</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.286389</td>\n","      <td>1.520669</td>\n","      <td>0.054826</td>\n","      <td>-0.691738</td>\n","      <td>0.740064</td>\n","      <td>-0.056749</td>\n","      <td>2.415805</td>\n","      <td>1.139834</td>\n","      <td>1.826742</td>\n","      <td>1.365391</td>\n","      <td>...</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","      <td>-0.660973</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.719420</td>\n","      <td>1.463765</td>\n","      <td>0.388306</td>\n","      <td>-1.070150</td>\n","      <td>0.295924</td>\n","      <td>-0.387331</td>\n","      <td>2.406039</td>\n","      <td>1.061205</td>\n","      <td>1.893298</td>\n","      <td>1.529187</td>\n","      <td>...</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","      <td>-0.557054</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.137065</td>\n","      <td>1.219271</td>\n","      <td>0.667881</td>\n","      <td>-1.247213</td>\n","      <td>-0.196632</td>\n","      <td>-0.669946</td>\n","      <td>2.397131</td>\n","      <td>1.135307</td>\n","      <td>1.912996</td>\n","      <td>1.670964</td>\n","      <td>...</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","      <td>-0.667889</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2.631853</td>\n","      <td>1.086166</td>\n","      <td>0.956922</td>\n","      <td>-1.021363</td>\n","      <td>-0.608486</td>\n","      <td>-0.937920</td>\n","      <td>2.407536</td>\n","      <td>1.133973</td>\n","      <td>1.855832</td>\n","      <td>1.674547</td>\n","      <td>...</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","      <td>-0.720146</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3.077583</td>\n","      <td>0.858803</td>\n","      <td>1.199127</td>\n","      <td>-0.742976</td>\n","      <td>-1.070087</td>\n","      <td>-1.178423</td>\n","      <td>2.345323</td>\n","      <td>1.076176</td>\n","      <td>1.702887</td>\n","      <td>1.605244</td>\n","      <td>...</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","      <td>-0.654299</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>3.487717</td>\n","      <td>0.713117</td>\n","      <td>1.407663</td>\n","      <td>-0.363890</td>\n","      <td>-1.277772</td>\n","      <td>-1.372497</td>\n","      <td>2.276455</td>\n","      <td>1.187819</td>\n","      <td>1.781125</td>\n","      <td>1.641924</td>\n","      <td>...</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","      <td>-0.494838</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3.890983</td>\n","      <td>0.405671</td>\n","      <td>1.473674</td>\n","      <td>0.062575</td>\n","      <td>-1.231541</td>\n","      <td>-1.604967</td>\n","      <td>2.176264</td>\n","      <td>1.172601</td>\n","      <td>1.831603</td>\n","      <td>1.505546</td>\n","      <td>...</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","      <td>-0.489024</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>4.526108</td>\n","      <td>0.074890</td>\n","      <td>1.578450</td>\n","      <td>0.487381</td>\n","      <td>-0.866097</td>\n","      <td>-1.746363</td>\n","      <td>2.085141</td>\n","      <td>1.100165</td>\n","      <td>1.860657</td>\n","      <td>1.532498</td>\n","      <td>...</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","      <td>-0.430391</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>4.930260</td>\n","      <td>-0.368767</td>\n","      <td>1.650496</td>\n","      <td>0.672143</td>\n","      <td>-0.551959</td>\n","      <td>-2.012173</td>\n","      <td>1.913148</td>\n","      <td>0.992719</td>\n","      <td>1.854664</td>\n","      <td>1.554701</td>\n","      <td>...</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","      <td>-0.504417</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5.379725</td>\n","      <td>-0.725693</td>\n","      <td>1.731604</td>\n","      <td>0.781253</td>\n","      <td>-0.117560</td>\n","      <td>-2.183394</td>\n","      <td>1.795093</td>\n","      <td>0.946394</td>\n","      <td>1.828693</td>\n","      <td>1.540674</td>\n","      <td>...</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","      <td>-0.563121</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>5.913692</td>\n","      <td>-0.976582</td>\n","      <td>1.628411</td>\n","      <td>0.736956</td>\n","      <td>0.407039</td>\n","      <td>-2.395091</td>\n","      <td>1.620431</td>\n","      <td>1.075026</td>\n","      <td>1.753695</td>\n","      <td>1.560303</td>\n","      <td>...</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","      <td>-0.556639</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>6.406076</td>\n","      <td>-1.340909</td>\n","      <td>1.487077</td>\n","      <td>0.510861</td>\n","      <td>0.801185</td>\n","      <td>-2.588814</td>\n","      <td>1.569560</td>\n","      <td>1.126441</td>\n","      <td>1.816869</td>\n","      <td>1.580807</td>\n","      <td>...</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","      <td>-0.453604</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>6.842285</td>\n","      <td>-1.663366</td>\n","      <td>1.364845</td>\n","      <td>0.015780</td>\n","      <td>0.823321</td>\n","      <td>-2.645043</td>\n","      <td>1.303736</td>\n","      <td>1.029034</td>\n","      <td>1.783284</td>\n","      <td>1.447943</td>\n","      <td>...</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","      <td>-0.494110</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>7.331274</td>\n","      <td>-1.847591</td>\n","      <td>1.232422</td>\n","      <td>-0.382747</td>\n","      <td>0.839208</td>\n","      <td>-2.651482</td>\n","      <td>1.138186</td>\n","      <td>1.087480</td>\n","      <td>1.777187</td>\n","      <td>1.426475</td>\n","      <td>...</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","      <td>-0.551068</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>7.804724</td>\n","      <td>-1.968247</td>\n","      <td>1.024274</td>\n","      <td>-0.873570</td>\n","      <td>0.595858</td>\n","      <td>-2.701486</td>\n","      <td>0.882148</td>\n","      <td>1.155397</td>\n","      <td>1.714155</td>\n","      <td>1.451859</td>\n","      <td>...</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","      <td>-0.601167</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>8.276508</td>\n","      <td>-2.081481</td>\n","      <td>0.665088</td>\n","      <td>-1.227898</td>\n","      <td>0.238346</td>\n","      <td>-2.769236</td>\n","      <td>0.594997</td>\n","      <td>1.113662</td>\n","      <td>1.834216</td>\n","      <td>1.584571</td>\n","      <td>...</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","      <td>-0.592351</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>8.672872</td>\n","      <td>-2.247115</td>\n","      <td>0.421833</td>\n","      <td>-1.369333</td>\n","      <td>-0.323619</td>\n","      <td>-2.794824</td>\n","      <td>0.291968</td>\n","      <td>1.056704</td>\n","      <td>1.789958</td>\n","      <td>1.595191</td>\n","      <td>...</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","      <td>-0.663329</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>9.110424</td>\n","      <td>-2.305948</td>\n","      <td>0.103579</td>\n","      <td>-1.123517</td>\n","      <td>-0.872181</td>\n","      <td>-2.816496</td>\n","      <td>0.055560</td>\n","      <td>1.080117</td>\n","      <td>1.705281</td>\n","      <td>1.677664</td>\n","      <td>...</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","      <td>-0.550310</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>9.592447</td>\n","      <td>-2.329369</td>\n","      <td>-0.185319</td>\n","      <td>-0.540287</td>\n","      <td>-1.203520</td>\n","      <td>-2.789422</td>\n","      <td>-0.177331</td>\n","      <td>1.034755</td>\n","      <td>1.740515</td>\n","      <td>1.630541</td>\n","      <td>...</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","      <td>-0.499726</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>9.937389</td>\n","      <td>-2.322689</td>\n","      <td>-0.425054</td>\n","      <td>-0.034409</td>\n","      <td>-1.411075</td>\n","      <td>-2.769550</td>\n","      <td>-0.434636</td>\n","      <td>1.041534</td>\n","      <td>1.743612</td>\n","      <td>1.638722</td>\n","      <td>...</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","      <td>-0.483084</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>10.419077</td>\n","      <td>-2.244623</td>\n","      <td>-0.868882</td>\n","      <td>0.260457</td>\n","      <td>-1.326258</td>\n","      <td>-2.695150</td>\n","      <td>-0.859879</td>\n","      <td>0.982449</td>\n","      <td>1.772692</td>\n","      <td>1.664573</td>\n","      <td>...</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","      <td>-0.632224</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>10.927031</td>\n","      <td>-2.065266</td>\n","      <td>-1.100733</td>\n","      <td>0.633586</td>\n","      <td>-0.839698</td>\n","      <td>-2.643176</td>\n","      <td>-1.121538</td>\n","      <td>1.067951</td>\n","      <td>1.864918</td>\n","      <td>1.651537</td>\n","      <td>...</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","      <td>-0.538990</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>11.367567</td>\n","      <td>-1.932984</td>\n","      <td>-1.357284</td>\n","      <td>0.798295</td>\n","      <td>-0.265570</td>\n","      <td>-2.592191</td>\n","      <td>-1.320164</td>\n","      <td>1.041677</td>\n","      <td>1.774406</td>\n","      <td>1.646040</td>\n","      <td>...</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","      <td>-0.536059</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>11.836048</td>\n","      <td>-1.732841</td>\n","      <td>-1.564873</td>\n","      <td>0.790549</td>\n","      <td>0.112267</td>\n","      <td>-2.571561</td>\n","      <td>-1.570048</td>\n","      <td>1.024223</td>\n","      <td>1.708670</td>\n","      <td>1.688384</td>\n","      <td>...</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","      <td>-0.565007</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>12.388813</td>\n","      <td>-1.398659</td>\n","      <td>-1.721036</td>\n","      <td>0.653132</td>\n","      <td>0.530170</td>\n","      <td>-2.420645</td>\n","      <td>-1.718034</td>\n","      <td>1.025162</td>\n","      <td>1.791935</td>\n","      <td>1.690045</td>\n","      <td>...</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","      <td>-0.516095</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>12.995836</td>\n","      <td>-1.161124</td>\n","      <td>-2.023673</td>\n","      <td>0.228322</td>\n","      <td>0.812391</td>\n","      <td>-2.364125</td>\n","      <td>-1.984516</td>\n","      <td>1.045707</td>\n","      <td>1.829063</td>\n","      <td>1.642089</td>\n","      <td>...</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","      <td>-0.510638</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>13.571556</td>\n","      <td>-0.871912</td>\n","      <td>-2.235144</td>\n","      <td>-0.264219</td>\n","      <td>0.873653</td>\n","      <td>-2.238477</td>\n","      <td>-2.189211</td>\n","      <td>1.081278</td>\n","      <td>1.864307</td>\n","      <td>1.664799</td>\n","      <td>...</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","      <td>-0.438158</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>14.183084</td>\n","      <td>-0.606483</td>\n","      <td>-2.260261</td>\n","      <td>-0.877193</td>\n","      <td>0.722970</td>\n","      <td>-2.076186</td>\n","      <td>-2.276486</td>\n","      <td>1.027428</td>\n","      <td>1.829258</td>\n","      <td>1.639458</td>\n","      <td>...</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","      <td>-0.452740</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>14.519562</td>\n","      <td>-0.188800</td>\n","      <td>-2.096589</td>\n","      <td>-1.222556</td>\n","      <td>0.360371</td>\n","      <td>-1.883746</td>\n","      <td>-2.266328</td>\n","      <td>0.920324</td>\n","      <td>1.769783</td>\n","      <td>1.592835</td>\n","      <td>...</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","      <td>-0.441954</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>14.928218</td>\n","      <td>0.149169</td>\n","      <td>-1.902574</td>\n","      <td>-1.305064</td>\n","      <td>-0.161078</td>\n","      <td>-1.689152</td>\n","      <td>-2.292991</td>\n","      <td>0.922220</td>\n","      <td>1.764835</td>\n","      <td>1.526650</td>\n","      <td>...</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","      <td>-0.534540</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>15.356603</td>\n","      <td>0.483690</td>\n","      <td>-1.757596</td>\n","      <td>-1.212735</td>\n","      <td>-0.600248</td>\n","      <td>-1.498291</td>\n","      <td>-2.296011</td>\n","      <td>1.036764</td>\n","      <td>1.823431</td>\n","      <td>1.584097</td>\n","      <td>...</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","      <td>-0.535835</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>15.828008</td>\n","      <td>0.762643</td>\n","      <td>-1.684668</td>\n","      <td>-0.907911</td>\n","      <td>-1.000689</td>\n","      <td>-1.231661</td>\n","      <td>-2.306762</td>\n","      <td>1.018258</td>\n","      <td>1.824626</td>\n","      <td>1.536489</td>\n","      <td>...</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","      <td>-0.479549</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>16.459253</td>\n","      <td>1.068771</td>\n","      <td>-1.491499</td>\n","      <td>-0.456699</td>\n","      <td>-1.228673</td>\n","      <td>-1.040451</td>\n","      <td>-2.436315</td>\n","      <td>1.066915</td>\n","      <td>1.855383</td>\n","      <td>1.606034</td>\n","      <td>...</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","      <td>-0.329235</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>17.165976</td>\n","      <td>1.287271</td>\n","      <td>-1.230231</td>\n","      <td>0.051646</td>\n","      <td>-1.260914</td>\n","      <td>-0.748149</td>\n","      <td>-2.524335</td>\n","      <td>1.035942</td>\n","      <td>1.813738</td>\n","      <td>1.608039</td>\n","      <td>...</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","      <td>-0.452739</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>17.715517</td>\n","      <td>1.381360</td>\n","      <td>-0.891999</td>\n","      <td>0.453685</td>\n","      <td>-1.061253</td>\n","      <td>-0.407764</td>\n","      <td>-2.563766</td>\n","      <td>1.042460</td>\n","      <td>1.834876</td>\n","      <td>1.581045</td>\n","      <td>...</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","      <td>-0.643077</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>18.047337</td>\n","      <td>1.437932</td>\n","      <td>-0.547429</td>\n","      <td>0.667262</td>\n","      <td>-0.673850</td>\n","      <td>-0.160879</td>\n","      <td>-2.555243</td>\n","      <td>1.054903</td>\n","      <td>1.804921</td>\n","      <td>1.548482</td>\n","      <td>...</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","      <td>-0.679766</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>18.430576</td>\n","      <td>1.387202</td>\n","      <td>-0.253689</td>\n","      <td>0.661471</td>\n","      <td>-0.186800</td>\n","      <td>0.061072</td>\n","      <td>-2.414970</td>\n","      <td>1.109001</td>\n","      <td>1.871669</td>\n","      <td>1.668251</td>\n","      <td>...</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","      <td>-0.549166</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>18.829754</td>\n","      <td>1.332733</td>\n","      <td>0.132456</td>\n","      <td>0.507340</td>\n","      <td>0.240157</td>\n","      <td>0.383342</td>\n","      <td>-2.369414</td>\n","      <td>1.121432</td>\n","      <td>1.842363</td>\n","      <td>1.714509</td>\n","      <td>...</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","      <td>-0.534501</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>19.272270</td>\n","      <td>1.339564</td>\n","      <td>0.570101</td>\n","      <td>0.258337</td>\n","      <td>0.563087</td>\n","      <td>0.755913</td>\n","      <td>-2.416730</td>\n","      <td>1.124258</td>\n","      <td>1.840353</td>\n","      <td>1.776434</td>\n","      <td>...</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","      <td>-0.509714</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>19.593084</td>\n","      <td>1.303834</td>\n","      <td>0.890983</td>\n","      <td>-0.130705</td>\n","      <td>0.752123</td>\n","      <td>1.049053</td>\n","      <td>-2.522687</td>\n","      <td>1.157077</td>\n","      <td>1.869405</td>\n","      <td>1.794315</td>\n","      <td>...</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","      <td>-0.524381</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>19.794355</td>\n","      <td>1.155405</td>\n","      <td>1.113374</td>\n","      <td>-0.675724</td>\n","      <td>0.690979</td>\n","      <td>1.273476</td>\n","      <td>-2.535037</td>\n","      <td>1.180793</td>\n","      <td>1.825145</td>\n","      <td>1.675815</td>\n","      <td>...</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","      <td>-0.622756</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>...</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","      <td>1.788335</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>...</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","      <td>1.948326</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>...</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","      <td>1.964934</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>...</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","      <td>1.914927</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>...</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","      <td>1.841033</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>...</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","      <td>1.725511</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>...</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","      <td>1.724814</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>...</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","      <td>1.728697</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>...</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","      <td>1.607063</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>...</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","      <td>1.548548</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>...</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","      <td>1.549906</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>...</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","      <td>1.309136</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>...</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","      <td>0.928203</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>...</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","      <td>0.921361</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>...</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","      <td>0.968530</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>59 rows × 26 columns</p>\n","</div>"],"text/plain":["    time_step  planet0_x  planet0_y  planet1_x  planet1_y  planet2_x  \\\n","0   -0.129779   1.276990  -1.113853   0.466538   0.584730   0.772767   \n","1    0.230372   1.296181  -0.785724   0.045093   0.736830   0.486601   \n","2    0.702104   1.353345  -0.363297  -0.301331   0.800037   0.275401   \n","3    1.286389   1.520669   0.054826  -0.691738   0.740064  -0.056749   \n","4    1.719420   1.463765   0.388306  -1.070150   0.295924  -0.387331   \n","5    2.137065   1.219271   0.667881  -1.247213  -0.196632  -0.669946   \n","6    2.631853   1.086166   0.956922  -1.021363  -0.608486  -0.937920   \n","7    3.077583   0.858803   1.199127  -0.742976  -1.070087  -1.178423   \n","8    3.487717   0.713117   1.407663  -0.363890  -1.277772  -1.372497   \n","9    3.890983   0.405671   1.473674   0.062575  -1.231541  -1.604967   \n","10   4.526108   0.074890   1.578450   0.487381  -0.866097  -1.746363   \n","11   4.930260  -0.368767   1.650496   0.672143  -0.551959  -2.012173   \n","12   5.379725  -0.725693   1.731604   0.781253  -0.117560  -2.183394   \n","13   5.913692  -0.976582   1.628411   0.736956   0.407039  -2.395091   \n","14   6.406076  -1.340909   1.487077   0.510861   0.801185  -2.588814   \n","15   6.842285  -1.663366   1.364845   0.015780   0.823321  -2.645043   \n","16   7.331274  -1.847591   1.232422  -0.382747   0.839208  -2.651482   \n","17   7.804724  -1.968247   1.024274  -0.873570   0.595858  -2.701486   \n","18   8.276508  -2.081481   0.665088  -1.227898   0.238346  -2.769236   \n","19   8.672872  -2.247115   0.421833  -1.369333  -0.323619  -2.794824   \n","20   9.110424  -2.305948   0.103579  -1.123517  -0.872181  -2.816496   \n","21   9.592447  -2.329369  -0.185319  -0.540287  -1.203520  -2.789422   \n","22   9.937389  -2.322689  -0.425054  -0.034409  -1.411075  -2.769550   \n","23  10.419077  -2.244623  -0.868882   0.260457  -1.326258  -2.695150   \n","24  10.927031  -2.065266  -1.100733   0.633586  -0.839698  -2.643176   \n","25  11.367567  -1.932984  -1.357284   0.798295  -0.265570  -2.592191   \n","26  11.836048  -1.732841  -1.564873   0.790549   0.112267  -2.571561   \n","27  12.388813  -1.398659  -1.721036   0.653132   0.530170  -2.420645   \n","28  12.995836  -1.161124  -2.023673   0.228322   0.812391  -2.364125   \n","29  13.571556  -0.871912  -2.235144  -0.264219   0.873653  -2.238477   \n","30  14.183084  -0.606483  -2.260261  -0.877193   0.722970  -2.076186   \n","31  14.519562  -0.188800  -2.096589  -1.222556   0.360371  -1.883746   \n","32  14.928218   0.149169  -1.902574  -1.305064  -0.161078  -1.689152   \n","33  15.356603   0.483690  -1.757596  -1.212735  -0.600248  -1.498291   \n","34  15.828008   0.762643  -1.684668  -0.907911  -1.000689  -1.231661   \n","35  16.459253   1.068771  -1.491499  -0.456699  -1.228673  -1.040451   \n","36  17.165976   1.287271  -1.230231   0.051646  -1.260914  -0.748149   \n","37  17.715517   1.381360  -0.891999   0.453685  -1.061253  -0.407764   \n","38  18.047337   1.437932  -0.547429   0.667262  -0.673850  -0.160879   \n","39  18.430576   1.387202  -0.253689   0.661471  -0.186800   0.061072   \n","40  18.829754   1.332733   0.132456   0.507340   0.240157   0.383342   \n","41  19.272270   1.339564   0.570101   0.258337   0.563087   0.755913   \n","42  19.593084   1.303834   0.890983  -0.130705   0.752123   1.049053   \n","43  19.794355   1.155405   1.113374  -0.675724   0.690979   1.273476   \n","44   1.788335   1.788335   1.788335   1.788335   1.788335   1.788335   \n","45   1.948326   1.948326   1.948326   1.948326   1.948326   1.948326   \n","46   1.964934   1.964934   1.964934   1.964934   1.964934   1.964934   \n","47   1.914927   1.914927   1.914927   1.914927   1.914927   1.914927   \n","48   1.841033   1.841033   1.841033   1.841033   1.841033   1.841033   \n","49   1.725511   1.725511   1.725511   1.725511   1.725511   1.725511   \n","50   1.724814   1.724814   1.724814   1.724814   1.724814   1.724814   \n","51   1.728697   1.728697   1.728697   1.728697   1.728697   1.728697   \n","52   1.607063   1.607063   1.607063   1.607063   1.607063   1.607063   \n","53   1.548548   1.548548   1.548548   1.548548   1.548548   1.548548   \n","54   1.549906   1.549906   1.549906   1.549906   1.549906   1.549906   \n","55   1.309136   1.309136   1.309136   1.309136   1.309136   1.309136   \n","56   0.928203   0.928203   0.928203   0.928203   0.928203   0.928203   \n","57   0.921361   0.921361   0.921361   0.921361   0.921361   0.921361   \n","58   0.968530   0.968530   0.968530   0.968530   0.968530   0.968530   \n","\n","    planet2_y  planet0_m  planet0_a  planet0_e  ...  planet3_x  planet3_y  \\\n","0    2.230249   1.278194   1.708518   1.507068  ...  -0.639018  -0.639018   \n","1    2.369161   1.222250   1.701897   1.493344  ...  -0.541599  -0.541599   \n","2    2.452332   1.148241   1.765875   1.395555  ...  -0.522309  -0.522309   \n","3    2.415805   1.139834   1.826742   1.365391  ...  -0.660973  -0.660973   \n","4    2.406039   1.061205   1.893298   1.529187  ...  -0.557054  -0.557054   \n","5    2.397131   1.135307   1.912996   1.670964  ...  -0.667889  -0.667889   \n","6    2.407536   1.133973   1.855832   1.674547  ...  -0.720146  -0.720146   \n","7    2.345323   1.076176   1.702887   1.605244  ...  -0.654299  -0.654299   \n","8    2.276455   1.187819   1.781125   1.641924  ...  -0.494838  -0.494838   \n","9    2.176264   1.172601   1.831603   1.505546  ...  -0.489024  -0.489024   \n","10   2.085141   1.100165   1.860657   1.532498  ...  -0.430391  -0.430391   \n","11   1.913148   0.992719   1.854664   1.554701  ...  -0.504417  -0.504417   \n","12   1.795093   0.946394   1.828693   1.540674  ...  -0.563121  -0.563121   \n","13   1.620431   1.075026   1.753695   1.560303  ...  -0.556639  -0.556639   \n","14   1.569560   1.126441   1.816869   1.580807  ...  -0.453604  -0.453604   \n","15   1.303736   1.029034   1.783284   1.447943  ...  -0.494110  -0.494110   \n","16   1.138186   1.087480   1.777187   1.426475  ...  -0.551068  -0.551068   \n","17   0.882148   1.155397   1.714155   1.451859  ...  -0.601167  -0.601167   \n","18   0.594997   1.113662   1.834216   1.584571  ...  -0.592351  -0.592351   \n","19   0.291968   1.056704   1.789958   1.595191  ...  -0.663329  -0.663329   \n","20   0.055560   1.080117   1.705281   1.677664  ...  -0.550310  -0.550310   \n","21  -0.177331   1.034755   1.740515   1.630541  ...  -0.499726  -0.499726   \n","22  -0.434636   1.041534   1.743612   1.638722  ...  -0.483084  -0.483084   \n","23  -0.859879   0.982449   1.772692   1.664573  ...  -0.632224  -0.632224   \n","24  -1.121538   1.067951   1.864918   1.651537  ...  -0.538990  -0.538990   \n","25  -1.320164   1.041677   1.774406   1.646040  ...  -0.536059  -0.536059   \n","26  -1.570048   1.024223   1.708670   1.688384  ...  -0.565007  -0.565007   \n","27  -1.718034   1.025162   1.791935   1.690045  ...  -0.516095  -0.516095   \n","28  -1.984516   1.045707   1.829063   1.642089  ...  -0.510638  -0.510638   \n","29  -2.189211   1.081278   1.864307   1.664799  ...  -0.438158  -0.438158   \n","30  -2.276486   1.027428   1.829258   1.639458  ...  -0.452740  -0.452740   \n","31  -2.266328   0.920324   1.769783   1.592835  ...  -0.441954  -0.441954   \n","32  -2.292991   0.922220   1.764835   1.526650  ...  -0.534540  -0.534540   \n","33  -2.296011   1.036764   1.823431   1.584097  ...  -0.535835  -0.535835   \n","34  -2.306762   1.018258   1.824626   1.536489  ...  -0.479549  -0.479549   \n","35  -2.436315   1.066915   1.855383   1.606034  ...  -0.329235  -0.329235   \n","36  -2.524335   1.035942   1.813738   1.608039  ...  -0.452739  -0.452739   \n","37  -2.563766   1.042460   1.834876   1.581045  ...  -0.643077  -0.643077   \n","38  -2.555243   1.054903   1.804921   1.548482  ...  -0.679766  -0.679766   \n","39  -2.414970   1.109001   1.871669   1.668251  ...  -0.549166  -0.549166   \n","40  -2.369414   1.121432   1.842363   1.714509  ...  -0.534501  -0.534501   \n","41  -2.416730   1.124258   1.840353   1.776434  ...  -0.509714  -0.509714   \n","42  -2.522687   1.157077   1.869405   1.794315  ...  -0.524381  -0.524381   \n","43  -2.535037   1.180793   1.825145   1.675815  ...  -0.622756  -0.622756   \n","44   1.788335   1.788335   1.788335   1.788335  ...   1.788335   1.788335   \n","45   1.948326   1.948326   1.948326   1.948326  ...   1.948326   1.948326   \n","46   1.964934   1.964934   1.964934   1.964934  ...   1.964934   1.964934   \n","47   1.914927   1.914927   1.914927   1.914927  ...   1.914927   1.914927   \n","48   1.841033   1.841033   1.841033   1.841033  ...   1.841033   1.841033   \n","49   1.725511   1.725511   1.725511   1.725511  ...   1.725511   1.725511   \n","50   1.724814   1.724814   1.724814   1.724814  ...   1.724814   1.724814   \n","51   1.728697   1.728697   1.728697   1.728697  ...   1.728697   1.728697   \n","52   1.607063   1.607063   1.607063   1.607063  ...   1.607063   1.607063   \n","53   1.548548   1.548548   1.548548   1.548548  ...   1.548548   1.548548   \n","54   1.549906   1.549906   1.549906   1.549906  ...   1.549906   1.549906   \n","55   1.309136   1.309136   1.309136   1.309136  ...   1.309136   1.309136   \n","56   0.928203   0.928203   0.928203   0.928203  ...   0.928203   0.928203   \n","57   0.921361   0.921361   0.921361   0.921361  ...   0.921361   0.921361   \n","58   0.968530   0.968530   0.968530   0.968530  ...   0.968530   0.968530   \n","\n","    planet3_m  planet3_a  planet3_e  planet4_x  planet4_y  planet4_m  \\\n","0   -0.639018  -0.639018  -0.639018  -0.639018  -0.639018  -0.639018   \n","1   -0.541599  -0.541599  -0.541599  -0.541599  -0.541599  -0.541599   \n","2   -0.522309  -0.522309  -0.522309  -0.522309  -0.522309  -0.522309   \n","3   -0.660973  -0.660973  -0.660973  -0.660973  -0.660973  -0.660973   \n","4   -0.557054  -0.557054  -0.557054  -0.557054  -0.557054  -0.557054   \n","5   -0.667889  -0.667889  -0.667889  -0.667889  -0.667889  -0.667889   \n","6   -0.720146  -0.720146  -0.720146  -0.720146  -0.720146  -0.720146   \n","7   -0.654299  -0.654299  -0.654299  -0.654299  -0.654299  -0.654299   \n","8   -0.494838  -0.494838  -0.494838  -0.494838  -0.494838  -0.494838   \n","9   -0.489024  -0.489024  -0.489024  -0.489024  -0.489024  -0.489024   \n","10  -0.430391  -0.430391  -0.430391  -0.430391  -0.430391  -0.430391   \n","11  -0.504417  -0.504417  -0.504417  -0.504417  -0.504417  -0.504417   \n","12  -0.563121  -0.563121  -0.563121  -0.563121  -0.563121  -0.563121   \n","13  -0.556639  -0.556639  -0.556639  -0.556639  -0.556639  -0.556639   \n","14  -0.453604  -0.453604  -0.453604  -0.453604  -0.453604  -0.453604   \n","15  -0.494110  -0.494110  -0.494110  -0.494110  -0.494110  -0.494110   \n","16  -0.551068  -0.551068  -0.551068  -0.551068  -0.551068  -0.551068   \n","17  -0.601167  -0.601167  -0.601167  -0.601167  -0.601167  -0.601167   \n","18  -0.592351  -0.592351  -0.592351  -0.592351  -0.592351  -0.592351   \n","19  -0.663329  -0.663329  -0.663329  -0.663329  -0.663329  -0.663329   \n","20  -0.550310  -0.550310  -0.550310  -0.550310  -0.550310  -0.550310   \n","21  -0.499726  -0.499726  -0.499726  -0.499726  -0.499726  -0.499726   \n","22  -0.483084  -0.483084  -0.483084  -0.483084  -0.483084  -0.483084   \n","23  -0.632224  -0.632224  -0.632224  -0.632224  -0.632224  -0.632224   \n","24  -0.538990  -0.538990  -0.538990  -0.538990  -0.538990  -0.538990   \n","25  -0.536059  -0.536059  -0.536059  -0.536059  -0.536059  -0.536059   \n","26  -0.565007  -0.565007  -0.565007  -0.565007  -0.565007  -0.565007   \n","27  -0.516095  -0.516095  -0.516095  -0.516095  -0.516095  -0.516095   \n","28  -0.510638  -0.510638  -0.510638  -0.510638  -0.510638  -0.510638   \n","29  -0.438158  -0.438158  -0.438158  -0.438158  -0.438158  -0.438158   \n","30  -0.452740  -0.452740  -0.452740  -0.452740  -0.452740  -0.452740   \n","31  -0.441954  -0.441954  -0.441954  -0.441954  -0.441954  -0.441954   \n","32  -0.534540  -0.534540  -0.534540  -0.534540  -0.534540  -0.534540   \n","33  -0.535835  -0.535835  -0.535835  -0.535835  -0.535835  -0.535835   \n","34  -0.479549  -0.479549  -0.479549  -0.479549  -0.479549  -0.479549   \n","35  -0.329235  -0.329235  -0.329235  -0.329235  -0.329235  -0.329235   \n","36  -0.452739  -0.452739  -0.452739  -0.452739  -0.452739  -0.452739   \n","37  -0.643077  -0.643077  -0.643077  -0.643077  -0.643077  -0.643077   \n","38  -0.679766  -0.679766  -0.679766  -0.679766  -0.679766  -0.679766   \n","39  -0.549166  -0.549166  -0.549166  -0.549166  -0.549166  -0.549166   \n","40  -0.534501  -0.534501  -0.534501  -0.534501  -0.534501  -0.534501   \n","41  -0.509714  -0.509714  -0.509714  -0.509714  -0.509714  -0.509714   \n","42  -0.524381  -0.524381  -0.524381  -0.524381  -0.524381  -0.524381   \n","43  -0.622756  -0.622756  -0.622756  -0.622756  -0.622756  -0.622756   \n","44   1.788335   1.788335   1.788335   1.788335   1.788335   1.788335   \n","45   1.948326   1.948326   1.948326   1.948326   1.948326   1.948326   \n","46   1.964934   1.964934   1.964934   1.964934   1.964934   1.964934   \n","47   1.914927   1.914927   1.914927   1.914927   1.914927   1.914927   \n","48   1.841033   1.841033   1.841033   1.841033   1.841033   1.841033   \n","49   1.725511   1.725511   1.725511   1.725511   1.725511   1.725511   \n","50   1.724814   1.724814   1.724814   1.724814   1.724814   1.724814   \n","51   1.728697   1.728697   1.728697   1.728697   1.728697   1.728697   \n","52   1.607063   1.607063   1.607063   1.607063   1.607063   1.607063   \n","53   1.548548   1.548548   1.548548   1.548548   1.548548   1.548548   \n","54   1.549906   1.549906   1.549906   1.549906   1.549906   1.549906   \n","55   1.309136   1.309136   1.309136   1.309136   1.309136   1.309136   \n","56   0.928203   0.928203   0.928203   0.928203   0.928203   0.928203   \n","57   0.921361   0.921361   0.921361   0.921361   0.921361   0.921361   \n","58   0.968530   0.968530   0.968530   0.968530   0.968530   0.968530   \n","\n","    planet4_a  planet4_e  \n","0   -0.639018  -0.639018  \n","1   -0.541599  -0.541599  \n","2   -0.522309  -0.522309  \n","3   -0.660973  -0.660973  \n","4   -0.557054  -0.557054  \n","5   -0.667889  -0.667889  \n","6   -0.720146  -0.720146  \n","7   -0.654299  -0.654299  \n","8   -0.494838  -0.494838  \n","9   -0.489024  -0.489024  \n","10  -0.430391  -0.430391  \n","11  -0.504417  -0.504417  \n","12  -0.563121  -0.563121  \n","13  -0.556639  -0.556639  \n","14  -0.453604  -0.453604  \n","15  -0.494110  -0.494110  \n","16  -0.551068  -0.551068  \n","17  -0.601167  -0.601167  \n","18  -0.592351  -0.592351  \n","19  -0.663329  -0.663329  \n","20  -0.550310  -0.550310  \n","21  -0.499726  -0.499726  \n","22  -0.483084  -0.483084  \n","23  -0.632224  -0.632224  \n","24  -0.538990  -0.538990  \n","25  -0.536059  -0.536059  \n","26  -0.565007  -0.565007  \n","27  -0.516095  -0.516095  \n","28  -0.510638  -0.510638  \n","29  -0.438158  -0.438158  \n","30  -0.452740  -0.452740  \n","31  -0.441954  -0.441954  \n","32  -0.534540  -0.534540  \n","33  -0.535835  -0.535835  \n","34  -0.479549  -0.479549  \n","35  -0.329235  -0.329235  \n","36  -0.452739  -0.452739  \n","37  -0.643077  -0.643077  \n","38  -0.679766  -0.679766  \n","39  -0.549166  -0.549166  \n","40  -0.534501  -0.534501  \n","41  -0.509714  -0.509714  \n","42  -0.524381  -0.524381  \n","43  -0.622756  -0.622756  \n","44   1.788335   1.788335  \n","45   1.948326   1.948326  \n","46   1.964934   1.964934  \n","47   1.914927   1.914927  \n","48   1.841033   1.841033  \n","49   1.725511   1.725511  \n","50   1.724814   1.724814  \n","51   1.728697   1.728697  \n","52   1.607063   1.607063  \n","53   1.548548   1.548548  \n","54   1.549906   1.549906  \n","55   1.309136   1.309136  \n","56   0.928203   0.928203  \n","57   0.921361   0.921361  \n","58   0.968530   0.968530  \n","\n","[59 rows x 26 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time_step</th>\n","      <th>planet0_x</th>\n","      <th>planet0_y</th>\n","      <th>planet1_x</th>\n","      <th>planet1_y</th>\n","      <th>planet2_x</th>\n","      <th>planet2_y</th>\n","      <th>planet0_m</th>\n","      <th>planet0_a</th>\n","      <th>planet0_e</th>\n","      <th>...</th>\n","      <th>planet3_x</th>\n","      <th>planet3_y</th>\n","      <th>planet3_m</th>\n","      <th>planet3_a</th>\n","      <th>planet3_e</th>\n","      <th>planet4_x</th>\n","      <th>planet4_y</th>\n","      <th>planet4_m</th>\n","      <th>planet4_a</th>\n","      <th>planet4_e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.129779</td>\n","      <td>-0.283071</td>\n","      <td>-0.259416</td>\n","      <td>-0.254101</td>\n","      <td>-0.106999</td>\n","      <td>-0.171241</td>\n","      <td>-0.470383</td>\n","      <td>-0.034368</td>\n","      <td>-0.235745</td>\n","      <td>-0.390739</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.234744</td>\n","      <td>-0.393677</td>\n","      <td>-0.271366</td>\n","      <td>-0.288201</td>\n","      <td>-0.205459</td>\n","      <td>-0.195003</td>\n","      <td>-0.416649</td>\n","      <td>-0.090312</td>\n","      <td>-0.242366</td>\n","      <td>-0.404463</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.228129</td>\n","      <td>-0.400244</td>\n","      <td>-0.209089</td>\n","      <td>-0.176335</td>\n","      <td>-0.192331</td>\n","      <td>-0.137551</td>\n","      <td>-0.393129</td>\n","      <td>-0.164321</td>\n","      <td>-0.178387</td>\n","      <td>-0.502252</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.108960</td>\n","      <td>-0.227399</td>\n","      <td>-0.157196</td>\n","      <td>-0.134963</td>\n","      <td>-0.091663</td>\n","      <td>-0.197289</td>\n","      <td>-0.463427</td>\n","      <td>-0.172728</td>\n","      <td>-0.117520</td>\n","      <td>-0.532415</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.141045</td>\n","      <td>-0.209807</td>\n","      <td>-0.181598</td>\n","      <td>-0.199570</td>\n","      <td>-0.198887</td>\n","      <td>-0.254187</td>\n","      <td>-0.480979</td>\n","      <td>-0.251357</td>\n","      <td>-0.050965</td>\n","      <td>-0.368620</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-0.188516</td>\n","      <td>-0.314540</td>\n","      <td>-0.237726</td>\n","      <td>-0.247062</td>\n","      <td>-0.249810</td>\n","      <td>-0.264308</td>\n","      <td>-0.471818</td>\n","      <td>-0.177255</td>\n","      <td>-0.031267</td>\n","      <td>-0.226843</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>-0.158845</td>\n","      <td>-0.249360</td>\n","      <td>-0.249911</td>\n","      <td>-0.103172</td>\n","      <td>-0.208799</td>\n","      <td>-0.263390</td>\n","      <td>-0.417845</td>\n","      <td>-0.178589</td>\n","      <td>-0.088431</td>\n","      <td>-0.223260</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>-0.178231</td>\n","      <td>-0.229022</td>\n","      <td>-0.264386</td>\n","      <td>-0.100996</td>\n","      <td>-0.302129</td>\n","      <td>-0.240949</td>\n","      <td>-0.411566</td>\n","      <td>-0.236386</td>\n","      <td>-0.241375</td>\n","      <td>-0.292563</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>-0.233213</td>\n","      <td>-0.088247</td>\n","      <td>-0.260541</td>\n","      <td>-0.134082</td>\n","      <td>-0.304257</td>\n","      <td>-0.180285</td>\n","      <td>-0.387802</td>\n","      <td>-0.124743</td>\n","      <td>-0.163138</td>\n","      <td>-0.255883</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>-0.295064</td>\n","      <td>-0.081878</td>\n","      <td>-0.342495</td>\n","      <td>-0.168517</td>\n","      <td>-0.259092</td>\n","      <td>-0.168382</td>\n","      <td>-0.372194</td>\n","      <td>-0.139961</td>\n","      <td>-0.112660</td>\n","      <td>-0.392261</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>-0.125055</td>\n","      <td>-0.082932</td>\n","      <td>-0.326775</td>\n","      <td>-0.155430</td>\n","      <td>-0.101522</td>\n","      <td>-0.077809</td>\n","      <td>-0.325509</td>\n","      <td>-0.212397</td>\n","      <td>-0.083605</td>\n","      <td>-0.365309</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>-0.186019</td>\n","      <td>-0.191897</td>\n","      <td>-0.284940</td>\n","      <td>-0.245417</td>\n","      <td>-0.158158</td>\n","      <td>-0.125966</td>\n","      <td>-0.339009</td>\n","      <td>-0.319843</td>\n","      <td>-0.089599</td>\n","      <td>-0.343106</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>-0.201670</td>\n","      <td>-0.219250</td>\n","      <td>-0.177116</td>\n","      <td>-0.215321</td>\n","      <td>-0.178561</td>\n","      <td>-0.095621</td>\n","      <td>-0.279363</td>\n","      <td>-0.366168</td>\n","      <td>-0.115569</td>\n","      <td>-0.357132</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>-0.132820</td>\n","      <td>-0.154698</td>\n","      <td>-0.200052</td>\n","      <td>-0.125966</td>\n","      <td>-0.095793</td>\n","      <td>-0.123458</td>\n","      <td>-0.258727</td>\n","      <td>-0.237536</td>\n","      <td>-0.190567</td>\n","      <td>-0.337504</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>-0.105551</td>\n","      <td>-0.225557</td>\n","      <td>-0.212085</td>\n","      <td>-0.034352</td>\n","      <td>-0.036305</td>\n","      <td>-0.152492</td>\n","      <td>-0.098444</td>\n","      <td>-0.186121</td>\n","      <td>-0.127393</td>\n","      <td>-0.317000</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>-0.134460</td>\n","      <td>-0.283196</td>\n","      <td>-0.161274</td>\n","      <td>-0.095567</td>\n","      <td>-0.170532</td>\n","      <td>-0.064500</td>\n","      <td>-0.139102</td>\n","      <td>-0.283528</td>\n","      <td>-0.160979</td>\n","      <td>-0.449863</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>-0.110586</td>\n","      <td>-0.236796</td>\n","      <td>-0.082782</td>\n","      <td>-0.036509</td>\n","      <td>-0.099808</td>\n","      <td>0.051690</td>\n","      <td>-0.067414</td>\n","      <td>-0.225082</td>\n","      <td>-0.167075</td>\n","      <td>-0.471332</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>-0.102253</td>\n","      <td>-0.165506</td>\n","      <td>-0.048390</td>\n","      <td>-0.143148</td>\n","      <td>-0.089169</td>\n","      <td>0.101769</td>\n","      <td>-0.076161</td>\n","      <td>-0.157165</td>\n","      <td>-0.230108</td>\n","      <td>-0.445948</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>-0.095585</td>\n","      <td>-0.128977</td>\n","      <td>-0.139906</td>\n","      <td>-0.267941</td>\n","      <td>-0.047674</td>\n","      <td>0.110787</td>\n","      <td>-0.108054</td>\n","      <td>-0.198899</td>\n","      <td>-0.110047</td>\n","      <td>-0.313236</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>-0.164338</td>\n","      <td>-0.189630</td>\n","      <td>-0.097011</td>\n","      <td>-0.382893</td>\n","      <td>-0.150192</td>\n","      <td>0.138061</td>\n","      <td>-0.149993</td>\n","      <td>-0.255858</td>\n","      <td>-0.154305</td>\n","      <td>-0.302616</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>-0.191902</td>\n","      <td>-0.190010</td>\n","      <td>-0.117374</td>\n","      <td>-0.319212</td>\n","      <td>-0.276078</td>\n","      <td>0.144942</td>\n","      <td>-0.121650</td>\n","      <td>-0.232444</td>\n","      <td>-0.238982</td>\n","      <td>-0.220143</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>-0.174995</td>\n","      <td>-0.202457</td>\n","      <td>-0.103426</td>\n","      <td>-0.088322</td>\n","      <td>-0.311022</td>\n","      <td>0.176042</td>\n","      <td>-0.088327</td>\n","      <td>-0.277807</td>\n","      <td>-0.203747</td>\n","      <td>-0.267265</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>-0.295169</td>\n","      <td>-0.232452</td>\n","      <td>-0.042161</td>\n","      <td>-0.030537</td>\n","      <td>-0.411491</td>\n","      <td>0.175381</td>\n","      <td>-0.080159</td>\n","      <td>-0.271028</td>\n","      <td>-0.200651</td>\n","      <td>-0.259084</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>-0.278597</td>\n","      <td>-0.238114</td>\n","      <td>-0.193629</td>\n","      <td>-0.184518</td>\n","      <td>-0.432006</td>\n","      <td>0.204847</td>\n","      <td>-0.242869</td>\n","      <td>-0.330113</td>\n","      <td>-0.171571</td>\n","      <td>-0.233233</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>-0.235760</td>\n","      <td>-0.188152</td>\n","      <td>-0.148523</td>\n","      <td>-0.165463</td>\n","      <td>-0.241200</td>\n","      <td>0.187828</td>\n","      <td>-0.247119</td>\n","      <td>-0.244610</td>\n","      <td>-0.079345</td>\n","      <td>-0.246269</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>-0.260340</td>\n","      <td>-0.228729</td>\n","      <td>-0.150210</td>\n","      <td>-0.184432</td>\n","      <td>-0.090509</td>\n","      <td>0.146287</td>\n","      <td>-0.195608</td>\n","      <td>-0.270885</td>\n","      <td>-0.169857</td>\n","      <td>-0.251767</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>-0.256975</td>\n","      <td>-0.241824</td>\n","      <td>-0.131595</td>\n","      <td>-0.166124</td>\n","      <td>-0.173574</td>\n","      <td>0.051571</td>\n","      <td>-0.204733</td>\n","      <td>-0.288339</td>\n","      <td>-0.235593</td>\n","      <td>-0.209423</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>-0.169327</td>\n","      <td>-0.157237</td>\n","      <td>-0.096581</td>\n","      <td>-0.073316</td>\n","      <td>-0.155718</td>\n","      <td>0.065213</td>\n","      <td>-0.123379</td>\n","      <td>-0.287400</td>\n","      <td>-0.152327</td>\n","      <td>-0.207762</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>-0.027420</td>\n","      <td>-0.200605</td>\n","      <td>-0.249122</td>\n","      <td>-0.112984</td>\n","      <td>-0.127488</td>\n","      <td>-0.036402</td>\n","      <td>-0.173909</td>\n","      <td>-0.266855</td>\n","      <td>-0.115200</td>\n","      <td>-0.255718</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.083184</td>\n","      <td>-0.217469</td>\n","      <td>-0.357156</td>\n","      <td>-0.147664</td>\n","      <td>-0.120357</td>\n","      <td>-0.088505</td>\n","      <td>-0.177919</td>\n","      <td>-0.231283</td>\n","      <td>-0.079955</td>\n","      <td>-0.233007</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.229595</td>\n","      <td>-0.275992</td>\n","      <td>-0.330385</td>\n","      <td>-0.327432</td>\n","      <td>-0.114212</td>\n","      <td>-0.122173</td>\n","      <td>-0.081553</td>\n","      <td>-0.285134</td>\n","      <td>-0.115004</td>\n","      <td>-0.258349</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.100957</td>\n","      <td>-0.191670</td>\n","      <td>-0.170308</td>\n","      <td>-0.356018</td>\n","      <td>-0.142668</td>\n","      <td>-0.142331</td>\n","      <td>0.093546</td>\n","      <td>-0.392238</td>\n","      <td>-0.174480</td>\n","      <td>-0.304971</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.044497</td>\n","      <td>-0.186883</td>\n","      <td>-0.038009</td>\n","      <td>-0.305063</td>\n","      <td>-0.223643</td>\n","      <td>-0.175248</td>\n","      <td>0.211600</td>\n","      <td>-0.390342</td>\n","      <td>-0.179427</td>\n","      <td>-0.371156</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.007765</td>\n","      <td>-0.174795</td>\n","      <td>-0.013839</td>\n","      <td>-0.290693</td>\n","      <td>-0.209255</td>\n","      <td>-0.224946</td>\n","      <td>0.331697</td>\n","      <td>-0.275798</td>\n","      <td>-0.120832</td>\n","      <td>-0.313710</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.014054</td>\n","      <td>-0.196271</td>\n","      <td>-0.119715</td>\n","      <td>-0.258808</td>\n","      <td>-0.239024</td>\n","      <td>-0.209921</td>\n","      <td>0.421249</td>\n","      <td>-0.294304</td>\n","      <td>-0.119637</td>\n","      <td>-0.361318</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.180184</td>\n","      <td>-0.157082</td>\n","      <td>-0.159836</td>\n","      <td>-0.217913</td>\n","      <td>-0.257839</td>\n","      <td>-0.279239</td>\n","      <td>0.368147</td>\n","      <td>-0.245647</td>\n","      <td>-0.088880</td>\n","      <td>-0.291773</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.421790</td>\n","      <td>-0.160939</td>\n","      <td>-0.180171</td>\n","      <td>-0.170429</td>\n","      <td>-0.287084</td>\n","      <td>-0.254163</td>\n","      <td>0.331878</td>\n","      <td>-0.276620</td>\n","      <td>-0.130525</td>\n","      <td>-0.289768</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.506215</td>\n","      <td>-0.234699</td>\n","      <td>-0.162992</td>\n","      <td>-0.181900</td>\n","      <td>-0.291651</td>\n","      <td>-0.185377</td>\n","      <td>0.318856</td>\n","      <td>-0.270102</td>\n","      <td>-0.109387</td>\n","      <td>-0.316761</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.372918</td>\n","      <td>-0.283524</td>\n","      <td>-0.167609</td>\n","      <td>-0.246312</td>\n","      <td>-0.272576</td>\n","      <td>-0.212073</td>\n","      <td>0.328015</td>\n","      <td>-0.257659</td>\n","      <td>-0.139342</td>\n","      <td>-0.349324</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.291041</td>\n","      <td>-0.372001</td>\n","      <td>-0.237979</td>\n","      <td>-0.335116</td>\n","      <td>-0.239606</td>\n","      <td>-0.263233</td>\n","      <td>0.442946</td>\n","      <td>-0.203561</td>\n","      <td>-0.072594</td>\n","      <td>-0.229556</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.225103</td>\n","      <td>-0.394653</td>\n","      <td>-0.216596</td>\n","      <td>-0.359490</td>\n","      <td>-0.255639</td>\n","      <td>-0.211123</td>\n","      <td>0.437214</td>\n","      <td>-0.191130</td>\n","      <td>-0.101899</td>\n","      <td>-0.183298</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.202503</td>\n","      <td>-0.288023</td>\n","      <td>-0.130042</td>\n","      <td>-0.293744</td>\n","      <td>-0.270153</td>\n","      <td>-0.103268</td>\n","      <td>0.312931</td>\n","      <td>-0.188304</td>\n","      <td>-0.103910</td>\n","      <td>-0.121373</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.058201</td>\n","      <td>-0.160882</td>\n","      <td>-0.133216</td>\n","      <td>-0.250316</td>\n","      <td>-0.241302</td>\n","      <td>-0.066918</td>\n","      <td>0.104849</td>\n","      <td>-0.155485</td>\n","      <td>-0.074857</td>\n","      <td>-0.103491</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>-0.205645</td>\n","      <td>-0.091087</td>\n","      <td>-0.196309</td>\n","      <td>-0.337282</td>\n","      <td>-0.251653</td>\n","      <td>-0.088917</td>\n","      <td>-0.034023</td>\n","      <td>-0.131769</td>\n","      <td>-0.119117</td>\n","      <td>-0.221992</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>59 rows × 26 columns</p>\n","</div>"],"text/plain":["    time_step  planet0_x  planet0_y  planet1_x  planet1_y  planet2_x  \\\n","0   -0.129779  -0.283071  -0.259416  -0.254101  -0.106999  -0.171241   \n","1   -0.234744  -0.393677  -0.271366  -0.288201  -0.205459  -0.195003   \n","2   -0.228129  -0.400244  -0.209089  -0.176335  -0.192331  -0.137551   \n","3   -0.108960  -0.227399  -0.157196  -0.134963  -0.091663  -0.197289   \n","4   -0.141045  -0.209807  -0.181598  -0.199570  -0.198887  -0.254187   \n","5   -0.188516  -0.314540  -0.237726  -0.247062  -0.249810  -0.264308   \n","6   -0.158845  -0.249360  -0.249911  -0.103172  -0.208799  -0.263390   \n","7   -0.178231  -0.229022  -0.264386  -0.100996  -0.302129  -0.240949   \n","8   -0.233213  -0.088247  -0.260541  -0.134082  -0.304257  -0.180285   \n","9   -0.295064  -0.081878  -0.342495  -0.168517  -0.259092  -0.168382   \n","10  -0.125055  -0.082932  -0.326775  -0.155430  -0.101522  -0.077809   \n","11  -0.186019  -0.191897  -0.284940  -0.245417  -0.158158  -0.125966   \n","12  -0.201670  -0.219250  -0.177116  -0.215321  -0.178561  -0.095621   \n","13  -0.132820  -0.154698  -0.200052  -0.125966  -0.095793  -0.123458   \n","14  -0.105551  -0.225557  -0.212085  -0.034352  -0.036305  -0.152492   \n","15  -0.134460  -0.283196  -0.161274  -0.095567  -0.170532  -0.064500   \n","16  -0.110586  -0.236796  -0.082782  -0.036509  -0.099808   0.051690   \n","17  -0.102253  -0.165506  -0.048390  -0.143148  -0.089169   0.101769   \n","18  -0.095585  -0.128977  -0.139906  -0.267941  -0.047674   0.110787   \n","19  -0.164338  -0.189630  -0.097011  -0.382893  -0.150192   0.138061   \n","20  -0.191902  -0.190010  -0.117374  -0.319212  -0.276078   0.144942   \n","21  -0.174995  -0.202457  -0.103426  -0.088322  -0.311022   0.176042   \n","22  -0.295169  -0.232452  -0.042161  -0.030537  -0.411491   0.175381   \n","23  -0.278597  -0.238114  -0.193629  -0.184518  -0.432006   0.204847   \n","24  -0.235760  -0.188152  -0.148523  -0.165463  -0.241200   0.187828   \n","25  -0.260340  -0.228729  -0.150210  -0.184432  -0.090509   0.146287   \n","26  -0.256975  -0.241824  -0.131595  -0.166124  -0.173574   0.051571   \n","27  -0.169327  -0.157237  -0.096581  -0.073316  -0.155718   0.065213   \n","28  -0.027420  -0.200605  -0.249122  -0.112984  -0.127488  -0.036402   \n","29   0.083184  -0.217469  -0.357156  -0.147664  -0.120357  -0.088505   \n","30   0.229595  -0.275992  -0.330385  -0.327432  -0.114212  -0.122173   \n","31   0.100957  -0.191670  -0.170308  -0.356018  -0.142668  -0.142331   \n","32   0.044497  -0.186883  -0.038009  -0.305063  -0.223643  -0.175248   \n","33   0.007765  -0.174795  -0.013839  -0.290693  -0.209255  -0.224946   \n","34   0.014054  -0.196271  -0.119715  -0.258808  -0.239024  -0.209921   \n","35   0.180184  -0.157082  -0.159836  -0.217913  -0.257839  -0.279239   \n","36   0.421790  -0.160939  -0.180171  -0.170429  -0.287084  -0.254163   \n","37   0.506215  -0.234699  -0.162992  -0.181900  -0.291651  -0.185377   \n","38   0.372918  -0.283524  -0.167609  -0.246312  -0.272576  -0.212073   \n","39   0.291041  -0.372001  -0.237979  -0.335116  -0.239606  -0.263233   \n","40   0.225103  -0.394653  -0.216596  -0.359490  -0.255639  -0.211123   \n","41   0.202503  -0.288023  -0.130042  -0.293744  -0.270153  -0.103268   \n","42   0.058201  -0.160882  -0.133216  -0.250316  -0.241302  -0.066918   \n","43  -0.205645  -0.091087  -0.196309  -0.337282  -0.251653  -0.088917   \n","44        NaN        NaN        NaN        NaN        NaN        NaN   \n","45        NaN        NaN        NaN        NaN        NaN        NaN   \n","46        NaN        NaN        NaN        NaN        NaN        NaN   \n","47        NaN        NaN        NaN        NaN        NaN        NaN   \n","48        NaN        NaN        NaN        NaN        NaN        NaN   \n","49        NaN        NaN        NaN        NaN        NaN        NaN   \n","50        NaN        NaN        NaN        NaN        NaN        NaN   \n","51        NaN        NaN        NaN        NaN        NaN        NaN   \n","52        NaN        NaN        NaN        NaN        NaN        NaN   \n","53        NaN        NaN        NaN        NaN        NaN        NaN   \n","54        NaN        NaN        NaN        NaN        NaN        NaN   \n","55        NaN        NaN        NaN        NaN        NaN        NaN   \n","56        NaN        NaN        NaN        NaN        NaN        NaN   \n","57        NaN        NaN        NaN        NaN        NaN        NaN   \n","58        NaN        NaN        NaN        NaN        NaN        NaN   \n","\n","    planet2_y  planet0_m  planet0_a  planet0_e  ...  planet3_x  planet3_y  \\\n","0   -0.470383  -0.034368  -0.235745  -0.390739  ...        NaN        NaN   \n","1   -0.416649  -0.090312  -0.242366  -0.404463  ...        NaN        NaN   \n","2   -0.393129  -0.164321  -0.178387  -0.502252  ...        NaN        NaN   \n","3   -0.463427  -0.172728  -0.117520  -0.532415  ...        NaN        NaN   \n","4   -0.480979  -0.251357  -0.050965  -0.368620  ...        NaN        NaN   \n","5   -0.471818  -0.177255  -0.031267  -0.226843  ...        NaN        NaN   \n","6   -0.417845  -0.178589  -0.088431  -0.223260  ...        NaN        NaN   \n","7   -0.411566  -0.236386  -0.241375  -0.292563  ...        NaN        NaN   \n","8   -0.387802  -0.124743  -0.163138  -0.255883  ...        NaN        NaN   \n","9   -0.372194  -0.139961  -0.112660  -0.392261  ...        NaN        NaN   \n","10  -0.325509  -0.212397  -0.083605  -0.365309  ...        NaN        NaN   \n","11  -0.339009  -0.319843  -0.089599  -0.343106  ...        NaN        NaN   \n","12  -0.279363  -0.366168  -0.115569  -0.357132  ...        NaN        NaN   \n","13  -0.258727  -0.237536  -0.190567  -0.337504  ...        NaN        NaN   \n","14  -0.098444  -0.186121  -0.127393  -0.317000  ...        NaN        NaN   \n","15  -0.139102  -0.283528  -0.160979  -0.449863  ...        NaN        NaN   \n","16  -0.067414  -0.225082  -0.167075  -0.471332  ...        NaN        NaN   \n","17  -0.076161  -0.157165  -0.230108  -0.445948  ...        NaN        NaN   \n","18  -0.108054  -0.198899  -0.110047  -0.313236  ...        NaN        NaN   \n","19  -0.149993  -0.255858  -0.154305  -0.302616  ...        NaN        NaN   \n","20  -0.121650  -0.232444  -0.238982  -0.220143  ...        NaN        NaN   \n","21  -0.088327  -0.277807  -0.203747  -0.267265  ...        NaN        NaN   \n","22  -0.080159  -0.271028  -0.200651  -0.259084  ...        NaN        NaN   \n","23  -0.242869  -0.330113  -0.171571  -0.233233  ...        NaN        NaN   \n","24  -0.247119  -0.244610  -0.079345  -0.246269  ...        NaN        NaN   \n","25  -0.195608  -0.270885  -0.169857  -0.251767  ...        NaN        NaN   \n","26  -0.204733  -0.288339  -0.235593  -0.209423  ...        NaN        NaN   \n","27  -0.123379  -0.287400  -0.152327  -0.207762  ...        NaN        NaN   \n","28  -0.173909  -0.266855  -0.115200  -0.255718  ...        NaN        NaN   \n","29  -0.177919  -0.231283  -0.079955  -0.233007  ...        NaN        NaN   \n","30  -0.081553  -0.285134  -0.115004  -0.258349  ...        NaN        NaN   \n","31   0.093546  -0.392238  -0.174480  -0.304971  ...        NaN        NaN   \n","32   0.211600  -0.390342  -0.179427  -0.371156  ...        NaN        NaN   \n","33   0.331697  -0.275798  -0.120832  -0.313710  ...        NaN        NaN   \n","34   0.421249  -0.294304  -0.119637  -0.361318  ...        NaN        NaN   \n","35   0.368147  -0.245647  -0.088880  -0.291773  ...        NaN        NaN   \n","36   0.331878  -0.276620  -0.130525  -0.289768  ...        NaN        NaN   \n","37   0.318856  -0.270102  -0.109387  -0.316761  ...        NaN        NaN   \n","38   0.328015  -0.257659  -0.139342  -0.349324  ...        NaN        NaN   \n","39   0.442946  -0.203561  -0.072594  -0.229556  ...        NaN        NaN   \n","40   0.437214  -0.191130  -0.101899  -0.183298  ...        NaN        NaN   \n","41   0.312931  -0.188304  -0.103910  -0.121373  ...        NaN        NaN   \n","42   0.104849  -0.155485  -0.074857  -0.103491  ...        NaN        NaN   \n","43  -0.034023  -0.131769  -0.119117  -0.221992  ...        NaN        NaN   \n","44        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","45        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","46        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","47        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","48        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","49        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","50        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","51        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","52        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","53        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","54        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","55        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","56        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","57        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","58        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n","\n","    planet3_m  planet3_a  planet3_e  planet4_x  planet4_y  planet4_m  \\\n","0         NaN        NaN        NaN        NaN        NaN        NaN   \n","1         NaN        NaN        NaN        NaN        NaN        NaN   \n","2         NaN        NaN        NaN        NaN        NaN        NaN   \n","3         NaN        NaN        NaN        NaN        NaN        NaN   \n","4         NaN        NaN        NaN        NaN        NaN        NaN   \n","5         NaN        NaN        NaN        NaN        NaN        NaN   \n","6         NaN        NaN        NaN        NaN        NaN        NaN   \n","7         NaN        NaN        NaN        NaN        NaN        NaN   \n","8         NaN        NaN        NaN        NaN        NaN        NaN   \n","9         NaN        NaN        NaN        NaN        NaN        NaN   \n","10        NaN        NaN        NaN        NaN        NaN        NaN   \n","11        NaN        NaN        NaN        NaN        NaN        NaN   \n","12        NaN        NaN        NaN        NaN        NaN        NaN   \n","13        NaN        NaN        NaN        NaN        NaN        NaN   \n","14        NaN        NaN        NaN        NaN        NaN        NaN   \n","15        NaN        NaN        NaN        NaN        NaN        NaN   \n","16        NaN        NaN        NaN        NaN        NaN        NaN   \n","17        NaN        NaN        NaN        NaN        NaN        NaN   \n","18        NaN        NaN        NaN        NaN        NaN        NaN   \n","19        NaN        NaN        NaN        NaN        NaN        NaN   \n","20        NaN        NaN        NaN        NaN        NaN        NaN   \n","21        NaN        NaN        NaN        NaN        NaN        NaN   \n","22        NaN        NaN        NaN        NaN        NaN        NaN   \n","23        NaN        NaN        NaN        NaN        NaN        NaN   \n","24        NaN        NaN        NaN        NaN        NaN        NaN   \n","25        NaN        NaN        NaN        NaN        NaN        NaN   \n","26        NaN        NaN        NaN        NaN        NaN        NaN   \n","27        NaN        NaN        NaN        NaN        NaN        NaN   \n","28        NaN        NaN        NaN        NaN        NaN        NaN   \n","29        NaN        NaN        NaN        NaN        NaN        NaN   \n","30        NaN        NaN        NaN        NaN        NaN        NaN   \n","31        NaN        NaN        NaN        NaN        NaN        NaN   \n","32        NaN        NaN        NaN        NaN        NaN        NaN   \n","33        NaN        NaN        NaN        NaN        NaN        NaN   \n","34        NaN        NaN        NaN        NaN        NaN        NaN   \n","35        NaN        NaN        NaN        NaN        NaN        NaN   \n","36        NaN        NaN        NaN        NaN        NaN        NaN   \n","37        NaN        NaN        NaN        NaN        NaN        NaN   \n","38        NaN        NaN        NaN        NaN        NaN        NaN   \n","39        NaN        NaN        NaN        NaN        NaN        NaN   \n","40        NaN        NaN        NaN        NaN        NaN        NaN   \n","41        NaN        NaN        NaN        NaN        NaN        NaN   \n","42        NaN        NaN        NaN        NaN        NaN        NaN   \n","43        NaN        NaN        NaN        NaN        NaN        NaN   \n","44        NaN        NaN        NaN        NaN        NaN        NaN   \n","45        NaN        NaN        NaN        NaN        NaN        NaN   \n","46        NaN        NaN        NaN        NaN        NaN        NaN   \n","47        NaN        NaN        NaN        NaN        NaN        NaN   \n","48        NaN        NaN        NaN        NaN        NaN        NaN   \n","49        NaN        NaN        NaN        NaN        NaN        NaN   \n","50        NaN        NaN        NaN        NaN        NaN        NaN   \n","51        NaN        NaN        NaN        NaN        NaN        NaN   \n","52        NaN        NaN        NaN        NaN        NaN        NaN   \n","53        NaN        NaN        NaN        NaN        NaN        NaN   \n","54        NaN        NaN        NaN        NaN        NaN        NaN   \n","55        NaN        NaN        NaN        NaN        NaN        NaN   \n","56        NaN        NaN        NaN        NaN        NaN        NaN   \n","57        NaN        NaN        NaN        NaN        NaN        NaN   \n","58        NaN        NaN        NaN        NaN        NaN        NaN   \n","\n","    planet4_a  planet4_e  \n","0         NaN        NaN  \n","1         NaN        NaN  \n","2         NaN        NaN  \n","3         NaN        NaN  \n","4         NaN        NaN  \n","5         NaN        NaN  \n","6         NaN        NaN  \n","7         NaN        NaN  \n","8         NaN        NaN  \n","9         NaN        NaN  \n","10        NaN        NaN  \n","11        NaN        NaN  \n","12        NaN        NaN  \n","13        NaN        NaN  \n","14        NaN        NaN  \n","15        NaN        NaN  \n","16        NaN        NaN  \n","17        NaN        NaN  \n","18        NaN        NaN  \n","19        NaN        NaN  \n","20        NaN        NaN  \n","21        NaN        NaN  \n","22        NaN        NaN  \n","23        NaN        NaN  \n","24        NaN        NaN  \n","25        NaN        NaN  \n","26        NaN        NaN  \n","27        NaN        NaN  \n","28        NaN        NaN  \n","29        NaN        NaN  \n","30        NaN        NaN  \n","31        NaN        NaN  \n","32        NaN        NaN  \n","33        NaN        NaN  \n","34        NaN        NaN  \n","35        NaN        NaN  \n","36        NaN        NaN  \n","37        NaN        NaN  \n","38        NaN        NaN  \n","39        NaN        NaN  \n","40        NaN        NaN  \n","41        NaN        NaN  \n","42        NaN        NaN  \n","43        NaN        NaN  \n","44        NaN        NaN  \n","45        NaN        NaN  \n","46        NaN        NaN  \n","47        NaN        NaN  \n","48        NaN        NaN  \n","49        NaN        NaN  \n","50        NaN        NaN  \n","51        NaN        NaN  \n","52        NaN        NaN  \n","53        NaN        NaN  \n","54        NaN        NaN  \n","55        NaN        NaN  \n","56        NaN        NaN  \n","57        NaN        NaN  \n","58        NaN        NaN  \n","\n","[59 rows x 26 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Subtract the actual from the predicted\n","df_diff = df_pred - df_actual\n","df_diff"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_name = f\"big_train_{dt.now()}_\"\n","\n","current_dir = os.getcwd()\n","\n","if not os.path.exists(\"./pre_trained_models/\"):\n","    os.makedirs(\"./pre_trained_models/\")\n","\n","path = os.path.join(current_dir, \"./pre_trained_models/\")\n","\n","\n","ckpt_dir = f\"./pre_trained_models/{model_name}\"\n","\n","# checkpoints.save_checkpoint(\n","#     ckpt_dir=path, target=state, step=batch_count, overwrite=True, prefix=model_name\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["First x shape: (1, 20, 512), causal_mask shape: (1, 1, 20, 20)\n","X Final Shape: (1, 20, 512)\n","X + Attention Shape: (1, 20, 512)\n","[[[2.2598886  1.763012   0.49513417 ... 1.458744   1.3766336  0.28646338]\n","  [2.2598886  1.763012   0.49513417 ... 1.458744   1.3766336  0.28646338]\n","  [2.2598886  1.763012   0.49513412 ... 1.458744   1.3766339  0.28646338]\n","  ...\n","  [2.2598886  1.7630117  0.495134   ... 1.458744   1.3766335  0.28646338]\n","  [2.2598891  1.763012   0.495134   ... 1.4587443  1.3766336  0.28646314]\n","  [2.2598886  1.7630124  0.49513382 ... 1.4587442  1.3766336  0.28646314]]]\n","First x shape: (1, 20, 512), causal_mask shape: (1, 1, 20, 20)\n","X Final Shape: (1, 20, 512)\n","X + Attention Shape: (1, 20, 512)\n","[[[ 3.1042538  -1.2391928  -2.27371    ...  1.3665593  -0.4227026\n","    0.98595935]\n","  [ 3.1042538  -1.2391928  -2.27371    ...  1.3665593  -0.4227026\n","    0.98595935]\n","  [ 3.104254   -1.2391927  -2.2737103  ...  1.3665593  -0.4227022\n","    0.9859587 ]\n","  ...\n","  [ 3.1042542  -1.2391931  -2.273711   ...  1.3665587  -0.4227031\n","    0.98595905]\n","  [ 3.1042547  -1.2391924  -2.273711   ...  1.3665595  -0.42270285\n","    0.98595816]\n","  [ 3.1042545  -1.239192   -2.273711   ...  1.3665593  -0.42270228\n","    0.9859579 ]]]\n","First x shape: (1, 20, 512), causal_mask shape: (1, 1, 20, 20)\n","X Final Shape: (1, 20, 512)\n","X + Attention Shape: (1, 20, 512)\n","[[[2.2598886  1.763012   0.49513417 ... 1.458744   1.3766336  0.28646338]\n","  [2.2598886  1.763012   0.49513417 ... 1.458744   1.3766336  0.28646338]\n","  [2.2598886  1.763012   0.49513412 ... 1.458744   1.3766339  0.28646338]\n","  ...\n","  [2.2598886  1.7630117  0.495134   ... 1.458744   1.3766335  0.28646338]\n","  [2.2598891  1.763012   0.495134   ... 1.4587443  1.3766336  0.28646314]\n","  [2.2598886  1.7630124  0.49513382 ... 1.4587442  1.3766336  0.28646314]]]\n","First x shape: (1, 20, 512), causal_mask shape: (1, 1, 20, 20)\n","X Final Shape: (1, 20, 512)\n","X + Attention Shape: (1, 20, 512)\n","[[[ 3.1042538  -1.2391928  -2.27371    ...  1.3665593  -0.4227026\n","    0.98595935]\n","  [ 3.1042538  -1.2391928  -2.27371    ...  1.3665593  -0.4227026\n","    0.98595935]\n","  [ 3.104254   -1.2391927  -2.2737103  ...  1.3665593  -0.4227022\n","    0.9859587 ]\n","  ...\n","  [ 3.1042542  -1.2391931  -2.273711   ...  1.3665587  -0.4227031\n","    0.98595905]\n","  [ 3.1042547  -1.2391924  -2.273711   ...  1.3665595  -0.42270285\n","    0.98595816]\n","  [ 3.1042545  -1.239192   -2.273711   ...  1.3665593  -0.42270228\n","    0.9859579 ]]]\n"]}],"source":["import jax.numpy as jnp\n","from flax import linen as nn\n","\n","\n","class FeedForwardNetwork(nn.Module):\n","    d_model: int\n","    d_ff: int\n","    dropout_rate: float\n","\n","    @nn.compact\n","    def __call__(self, x, deterministic: bool):\n","        x = nn.Dense(self.d_ff)(x)\n","        x = nn.relu(x)\n","        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=deterministic)\n","        x = nn.Dense(self.d_model)(x)\n","        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=deterministic)\n","        return x\n","\n","\n","class TransformerBlock(nn.Module):\n","    num_heads: int\n","    d_model: int\n","    d_ff: int\n","    dropout_rate: float\n","\n","    @nn.compact\n","    def __call__(self, x, deterministic: bool):\n","        # Generate the causal mask using make_causal_mask\n","        causal_mask = nn.make_causal_mask(\n","            x[:, :, 0], dtype=jnp.float32\n","        )  # shape: (batch, 1, seq_len, seq_len)\n","        print(f\"First x shape: {x.shape}, causal_mask shape: {causal_mask.shape}\")\n","        # Multi-head self-attention with causal mask\n","        attention = nn.MultiHeadDotProductAttention(\n","            num_heads=self.num_heads,\n","            qkv_features=self.d_model,\n","            dropout_rate=self.dropout_rate,\n","            broadcast_dropout=False,\n","        )(x, x, mask=causal_mask, deterministic=deterministic)\n","        print(f\"X Final Shape: {x.shape}\")\n","        x = x + attention\n","        print(f\"X + Attention Shape: {x.shape}\")\n","        print(x)\n","        x = nn.LayerNorm()(x)\n","\n","        # Feed Forward Network\n","        ffn = FeedForwardNetwork(\n","            d_model=self.d_model, d_ff=self.d_ff, dropout_rate=self.dropout_rate\n","        )(x, deterministic=deterministic)\n","\n","        x = x + ffn\n","        x = nn.LayerNorm()(x)\n","\n","        return x\n","\n","\n","# Example usage:\n","class Transformer(nn.Module):\n","    num_layers: int\n","    num_heads: int\n","    d_model: int\n","    d_ff: int\n","    dropout_rate: float\n","\n","    @nn.compact\n","    def __call__(self, x, deterministic: bool):\n","        for _ in range(self.num_layers):\n","            x = TransformerBlock(\n","                num_heads=self.num_heads,\n","                d_model=self.d_model,\n","                d_ff=self.d_ff,\n","                dropout_rate=self.dropout_rate,\n","            )(x, deterministic=deterministic)\n","        return x\n","\n","\n","# Dummy input for demonstration\n","x = jnp.ones((1, 20, 512))  # Batch size: 1, Sequence length: 20, Model dimension: 512\n","\n","# Create the model instance\n","model = Transformer(num_layers=2, num_heads=8, d_model=512, d_ff=2048, dropout_rate=0.1)\n","\n","# Initialize parameters\n","variables = model.init(jax.random.PRNGKey(0), x, deterministic=True)\n","\n","# Apply the model\n","output = model.apply(variables, x, deterministic=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x37f4f34c0>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 600x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(6, 6))\n","plt.imshow(output[0], cmap=\"viridis\", aspect=\"auto\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          0., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 0., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 0., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 0., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 0.],\n","         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          1., 1., 1., 1., 1.]]]], dtype=float32)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["nn.make_causal_mask(x[:, :, 0], dtype=jnp.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["Array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["(jnp.arange(59) < 50).astype(jnp.float32)[None, :]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Incompatible shapes for broadcasting: shapes=[(4, 1, 59, 1, 1, 59), (1, 1, 1, 1, 26, 1, 1, 1)]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/util.py:287\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/util.py:280\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached\u001b[39m(_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 280\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:155\u001b[0m, in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;129m@cache\u001b[39m()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_shapes_cached\u001b[39m(\u001b[38;5;241m*\u001b[39mshapes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:171\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_shape\n","\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(4, 1, 59, 1, 1, 59), (1, 1, 1, 1, 26, 1, 1, 1)]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m model \u001b[38;5;241m=\u001b[39m Transformer(num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m272\u001b[39m, d_ff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Initialize parameters\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    123\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Apply the model\u001b[39;00m\n\u001b[1;32m    126\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    127\u001b[0m     variables, x, time_padding_mask, col_padding_mask, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    128\u001b[0m )\n","    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n","Cell \u001b[0;32mIn[33], line 97\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, x, time_padding_mask, col_padding_mask, deterministic)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, time_padding_mask, col_padding_mask, deterministic: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m---> 97\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_ff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n","Cell \u001b[0;32mIn[33], line 61\u001b[0m, in \u001b[0;36mTransformerBlock.__call__\u001b[0;34m(self, x, time_padding_mask, col_padding_mask, deterministic)\u001b[0m\n\u001b[1;32m     55\u001b[0m combined_time_mask \u001b[38;5;241m=\u001b[39m combined_time_mask[\n\u001b[1;32m     56\u001b[0m     :, :, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     57\u001b[0m ]  \u001b[38;5;66;03m# shape: (batch, 1, time_steps, 1, 1)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Combine the time and column masks\u001b[39;00m\n\u001b[1;32m     60\u001b[0m combined_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mcombined_time_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol_padding_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     62\u001b[0m )  \u001b[38;5;66;03m# shape: (batch, 1, time_steps, columns, columns)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Multi-head self-attention with combined mask\u001b[39;00m\n\u001b[1;32m     65\u001b[0m attention \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMultiHeadDotProductAttention(\n\u001b[1;32m     66\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m     67\u001b[0m     qkv_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model,\n\u001b[1;32m     68\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate,\n\u001b[1;32m     69\u001b[0m     broadcast_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     70\u001b[0m )(x, x, mask\u001b[38;5;241m=\u001b[39mcombined_mask, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:264\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    262\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n","    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/ufuncs.py:99\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2, \u001b[38;5;241m/\u001b[39m):\n\u001b[0;32m---> 99\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m \u001b[43mpromote_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_fn(x1, x2) \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/util.py:381\u001b[0m, in \u001b[0;36mpromote_args\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    379\u001b[0m _check_no_float0s(fun_name, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    380\u001b[0m check_for_prngkeys(fun_name, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpromote_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpromote_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/numpy/util.py:250\u001b[0m, in \u001b[0;36mpromote_shapes\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mnumpy_rank_promotion\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    249\u001b[0m   _rank_promotion_warning_or_error(fun_name, shapes)\n\u001b[0;32m--> 250\u001b[0m result_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [_broadcast_to(arg, (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (result_rank \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(shp)) \u001b[38;5;241m+\u001b[39m shp)\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m arg, shp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, shapes)]\n","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","File \u001b[0;32m~/environment/Hephaestus/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:171\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    169\u001b[0m result_shape \u001b[38;5;241m=\u001b[39m _try_broadcast_shapes(shape_list)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_shape\n","\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(4, 1, 59, 1, 1, 59), (1, 1, 1, 1, 26, 1, 1, 1)]"]}],"source":["import jax.numpy as jnp\n","from flax import linen as nn\n","\n","\n","class FeedForwardNetwork(nn.Module):\n","    d_model: int\n","    d_ff: int\n","    dropout_rate: float\n","\n","    @nn.compact\n","    def __call__(self, x, deterministic: bool):\n","        x = nn.Dense(self.d_ff)(x)\n","        x = nn.relu(x)\n","        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=deterministic)\n","        x = nn.Dense(self.d_model)(x)\n","        x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=deterministic)\n","        return x\n","\n","\n","class TransformerBlock(nn.Module):\n","    num_heads: int\n","    d_model: int\n","    d_ff: int\n","    dropout_rate: float\n","\n","    @nn.compact\n","    def __call__(self, x, time_padding_mask, col_padding_mask, deterministic: bool):\n","        # Generate the causal mask for the time dimension\n","        causal_mask = nn.make_causal_mask(\n","            x[:, :, 0, 0], dtype=jnp.float32\n","        )  # shape: (batch, 1, time_steps, time_steps)\n","\n","        # Generate the time padding mask using make_attention_mask\n","        time_padding_mask = nn.make_attention_mask(\n","            time_padding_mask, time_padding_mask, dtype=jnp.float32\n","        )  # shape: (batch, 1, time_steps, time_steps)\n","\n","        # Combine the causal mask and the time padding mask\n","        combined_time_mask = jnp.logical_and(causal_mask, time_padding_mask).astype(\n","            jnp.float32\n","        )  # shape: (batch, 1, time_steps, time_steps)\n","\n","        # Generate the column padding mask\n","        col_padding_mask = col_padding_mask[\n","            :, None, :, None\n","        ]  # shape: (batch, 1, columns, 1)\n","\n","        # Apply the column padding mask to the attention weights\n","        col_padding_mask = nn.make_attention_mask(\n","            col_padding_mask, col_padding_mask, dtype=jnp.float32\n","        )  # shape: (batch, 1, columns, columns)\n","\n","        # Expand the combined time mask to match the dimensions required by the\n","        # attention mechanism\n","        combined_time_mask = combined_time_mask[\n","            :, :, :, None, None\n","        ]  # shape: (batch, 1, time_steps, 1, 1)\n","\n","        # Combine the time and column masks\n","        combined_mask = (\n","            combined_time_mask * col_padding_mask[:, None, None, :, :]\n","        )  # shape: (batch, 1, time_steps, columns, columns)\n","\n","        # Multi-head self-attention with combined mask\n","        attention = nn.MultiHeadDotProductAttention(\n","            num_heads=self.num_heads,\n","            qkv_features=self.d_model,\n","            dropout_rate=self.dropout_rate,\n","            broadcast_dropout=False,\n","        )(x, x, mask=combined_mask, deterministic=deterministic)\n","\n","        x = x + attention\n","        x = nn.LayerNorm()(x)\n","\n","        # Feed Forward Network\n","        ffn = FeedForwardNetwork(\n","            d_model=self.d_model, d_ff=self.d_ff, dropout_rate=self.dropout_rate\n","        )(x, deterministic=deterministic)\n","\n","        x = x + ffn\n","        x = nn.LayerNorm()(x)\n","\n","        return x\n","\n","\n","# Example usage:\n","class Transformer(nn.Module):\n","    num_layers: int\n","    num_heads: int\n","    d_model: int\n","    d_ff: int\n","    dropout_rate: float\n","\n","    @nn.compact\n","    def __call__(self, x, time_padding_mask, col_padding_mask, deterministic: bool):\n","        for _ in range(self.num_layers):\n","            x = TransformerBlock(\n","                num_heads=self.num_heads,\n","                d_model=self.d_model,\n","                d_ff=self.d_ff,\n","                dropout_rate=self.dropout_rate,\n","            )(x, time_padding_mask, col_padding_mask, deterministic=deterministic)\n","        return x\n","\n","\n","# Dummy input for demonstration\n","x = jnp.ones(\n","    (4, 59, 26, 272)\n",")  # Batch size: 4, Time steps: 59, Columns: 26, Embedding dimension: 272\n","time_padding_mask = (jnp.arange(59) < 50).astype(jnp.float32)[\n","    None, :\n","]  # Mask first 50 time steps\n","col_padding_mask = (jnp.arange(26) < 20).astype(jnp.float32)[\n","    None, :\n","]  # Mask first 20 columns\n","\n","# Create the model instance\n","model = Transformer(num_layers=2, num_heads=8, d_model=272, d_ff=1024, dropout_rate=0.1)\n","\n","# Initialize parameters\n","variables = model.init(\n","    jax.random.PRNGKey(0), x, time_padding_mask, col_padding_mask, deterministic=True\n",")\n","\n","# Apply the model\n","output = model.apply(\n","    variables, x, time_padding_mask, col_padding_mask, deterministic=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ True  True  True  True]\n","  [ True  True  True  True]\n","  [ True  True  True  True]]\n","\n"," [[ True  True  True  True]\n","  [ True  True  True  True]\n","  [ True  True  True  True]]]\n"]}],"source":["import jax\n","import jax.numpy as jnp\n","import flax.linen as nn\n","\n","\n","def create_attention_mask(batch_size, time_steps, columns):\n","    # Assume these are your masks for time_steps and columns\n","    # They should have the shape (batch_size, time_steps) and (batch_size, columns) respectively\n","    time_steps_mask = jnp.ones(\n","        (batch_size, time_steps), dtype=bool\n","    )  # Change as per your mask\n","    columns_mask = jnp.ones(\n","        (batch_size, columns), dtype=bool\n","    )  # Change as per your mask\n","\n","    # Expand dimensions to match (batch_size, time_steps, columns)\n","    time_steps_mask_expanded = jnp.expand_dims(\n","        time_steps_mask, axis=-1\n","    )  # Shape: (batch_size, time_steps, 1)\n","    columns_mask_expanded = jnp.expand_dims(\n","        columns_mask, axis=-2\n","    )  # Shape: (batch_size, 1, columns)\n","\n","    # Combine masks: logical AND to create the final mask\n","    attention_mask = (\n","        time_steps_mask_expanded & columns_mask_expanded\n","    )  # Shape: (batch_size, time_steps, columns)\n","\n","    return attention_mask\n","\n","\n","# Example usage\n","batch_size = 2\n","time_steps = 3\n","columns = 4\n","\n","attention_mask = create_attention_mask(batch_size, time_steps, columns)\n","print(attention_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;31mSignature:\u001b[0m\n","\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mquery_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mkey_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mpairwise_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mPjitFunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x1178b3520\u001b[0m\u001b[0;34m>>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mextra_batch_dims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportsDType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'jax.numpy.float32'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n","\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDocstring:\u001b[0m\n","Mask-making helper for attention weights.\n","\n","In case of 1d inputs (i.e., ``[batch..., len_q]``, ``[batch..., len_kv]``, the\n","attention weights will be ``[batch..., heads, len_q, len_kv]`` and this\n","function will produce ``[batch..., 1, len_q, len_kv]``.\n","\n","Args:\n","  query_input: a batched, flat input of query_length size\n","  key_input: a batched, flat input of key_length size\n","  pairwise_fn: broadcasting elementwise comparison function\n","  extra_batch_dims: number of extra batch dims to add singleton axes for, none\n","    by default\n","  dtype: mask return dtype\n","\n","Returns:\n","  A ``[batch..., 1, len_q, len_kv]`` shaped mask for 1d attention.\n","\u001b[0;31mFile:\u001b[0m      ~/Hephaestus/.venv/lib/python3.10/site-packages/flax/linen/attention.py\n","\u001b[0;31mType:\u001b[0m      function"]}],"source":["?nn.make_attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[[1. 1. 1. 1.]\n","   [1. 1. 1. 1.]\n","   [1. 1. 1. 1.]]]\n","\n","\n"," [[[1. 1. 0. 1.]\n","   [0. 0. 0. 0.]\n","   [1. 1. 0. 1.]]]]\n"]}],"source":["import jax\n","import jax.numpy as jnp\n","import flax.linen as nn\n","\n","# Example inputs\n","batch_size = 2\n","query_length = 3\n","key_length = 4\n","\n","# Dummy query and key inputs with batch and sequence lengths\n","query_input = jnp.array([[1, 1, 1], [1, 0, 1]])  # Shape: (batch_size, query_length)\n","key_input = jnp.array([[1, 1, 1, 1], [1, 1, 0, 1]])  # Shape: (batch_size, key_length)\n","\n","# Create attention mask\n","attention_mask = nn.make_attention_mask(query_input, key_input)\n","\n","print(attention_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[[1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n","   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n","   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n","   [1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n","\n","\n"," [[[1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n","   [1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n","   [1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n","   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","   [1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.]]]]\n","(2, 1, 12, 12)\n"]}],"source":["import jax\n","import jax.numpy as jnp\n","import flax.linen\n","\n","\n","def create_combined_attention_mask(time_steps_mask, columns_mask):\n","    # Expand dimensions to match (batch_size, time_steps, columns)\n","    time_steps_mask_expanded = jnp.expand_dims(\n","        time_steps_mask, axis=-1\n","    )  # Shape: (batch_size, time_steps, 1)\n","    columns_mask_expanded = jnp.expand_dims(\n","        columns_mask, axis=-2\n","    )  # Shape: (batch_size, 1, columns)\n","\n","    # Combine masks: logical AND to create the final mask\n","    combined_mask = (\n","        time_steps_mask_expanded & columns_mask_expanded\n","    )  # Shape: (batch_size, time_steps, columns)\n","\n","    # Flatten masks for nn.make_attention_mask\n","    combined_mask_flat = combined_mask.reshape(combined_mask.shape[0], -1)\n","\n","    return combined_mask_flat\n","\n","\n","# Example inputs\n","batch_size = 2\n","time_steps = 3\n","columns = 4\n","\n","# Example masks\n","time_steps_mask = jnp.array([[1, 1, 0], [1, 0, 1]])  # Shape: (batch_size, time_steps)\n","columns_mask = jnp.array([[1, 0, 1, 1], [1, 1, 0, 1]])  # Shape: (batch_size, columns)\n","\n","# Create combined attention mask\n","combined_mask = create_combined_attention_mask(time_steps_mask, columns_mask)\n","\n","# Create attention mask using nn.make_attention_mask\n","attention_mask = nn.make_attention_mask(combined_mask, combined_mask)\n","\n","print(attention_mask)\n","print(attention_mask.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import jax\n","import jax.numpy as jnp\n","import flax.linen as nn\n","\n","\n","class SimpleDecoder(nn.Module):\n","    vocab_size: int\n","    hidden_size: int\n","    num_heads: int\n","\n","    @nn.compact\n","    def __call__(self, x):\n","        # x is the input sequence of token ids\n","        embeddings = nn.Embed(self.vocab_size, self.hidden_size)(x)\n","        seq_len = x.shape[1]\n","\n","        # Create a causal mask\n","        causal_mask = nn.make_causal_mask(jnp.ones((seq_len, seq_len), dtype=bool))\n","\n","        # Apply multi-head attention\n","        attn_output = nn.MultiHeadDotProductAttention(num_heads=self.num_heads)(\n","            embeddings, embeddings, embeddings, mask=causal_mask\n","        )\n","\n","        # Predict the next token\n","        logits = nn.Dense(self.vocab_size)(attn_output)\n","        return logits, attn_output, causal_mask\n","\n","\n","# Define the model\n","vocab_size = 10000  # Example vocabulary size\n","hidden_size = 512  # Example hidden size\n","num_heads = 8  # Example number of attention heads\n","\n","model = SimpleDecoder(\n","    vocab_size=vocab_size, hidden_size=hidden_size, num_heads=num_heads\n",")\n","\n","# Example input\n","input_tokens = jnp.array([[1, 2, 3, 4, 5]])  # Example token ids\n","rng = jax.random.PRNGKey(0)\n","\n","# Initialize parameters\n","params = model.init(rng, input_tokens)\n","\n","# Forward pass\n","logits, attn_output, causal_mask = model.apply(params, input_tokens)\n","# print(logits)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(5, 1, 5, 5)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["causal_mask.shape"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP1swsXnq2jqt/Hz4IBTZm2","gpuType":"V100","machine_shape":"hm","mount_file_id":"1zHmvVqlKJh0x9vjCRSkYKkko5buvMMEd","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01ca2dcb14e647dfb1e68750ca6de39c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a51aa7b827db4f768dce6315dbebf379","IPY_MODEL_634935ff0a6b4d65b72f87359d9f82fc","IPY_MODEL_09b63c98bee543dfb557a007d50c41d1"],"layout":"IPY_MODEL_dc4a8a3b0a8b4ef49dcd6269a1b32e14"}},"0481743e80634f7a8e718fb528950e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"055681c8159b4b6c8104d4e06279803c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b63c98bee543dfb557a007d50c41d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb36a08ca1540228919af722727572c","placeholder":"​","style":"IPY_MODEL_3bd47d84fac442d4bcf49dceeb699d45","value":" 807/807 [04:29&lt;00:00,  3.10it/s]"}},"0e26d28846fb449789510e4748c01c6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ce5408138f4cb28e163f1fdffdee5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b35a70a3b9e4f3b87cf2a7280439ac6","placeholder":"​","style":"IPY_MODEL_0e26d28846fb449789510e4748c01c6a","value":"100%"}},"2ac0cceac38e43adb00a10b778fad2df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddb1791795134ac0a754748f9793c214","placeholder":"​","style":"IPY_MODEL_d95aea2b915b44f38b5090ee186abafd","value":" 807/807 [04:31&lt;00:00,  2.80it/s]"}},"2fb36a08ca1540228919af722727572c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d37adf891a4da68675945509051210":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_055681c8159b4b6c8104d4e06279803c","placeholder":"​","style":"IPY_MODEL_9f5e5843559b4f9e8f3440ebd85743f8","value":" 807/807 [04:52&lt;00:00,  3.03it/s]"}},"3bd47d84fac442d4bcf49dceeb699d45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4151c7353de54909aa9deecbe8c1e1e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"462d9e93a94f44868fec1ece82f0a241":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47793d3155614c8cbd7d3337dcb2f895":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8093c8ddeec4c55ac6cc5f8f7df30bf","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4151c7353de54909aa9deecbe8c1e1e1","value":3}},"4bc81f6d94394d7f90e070d8b11a7059":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da9993585914618a35d8d5382fef850":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4dd64f565fcf4b259ef24944493477bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25ce5408138f4cb28e163f1fdffdee5f","IPY_MODEL_47793d3155614c8cbd7d3337dcb2f895","IPY_MODEL_f9ec11073e484927a4cc1ee2e3da132f"],"layout":"IPY_MODEL_62e750769d364ab2b80d5b9646b10ea6"}},"5e15315a77864badafe48c2baf31b030":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd9dd713862479bba73b6c0a12a1902","IPY_MODEL_88be535ce5a945f4979fe72d9f086365","IPY_MODEL_31d37adf891a4da68675945509051210"],"layout":"IPY_MODEL_4da9993585914618a35d8d5382fef850"}},"5edd903b07594d128ded9b4844835159":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bc81f6d94394d7f90e070d8b11a7059","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3bc58d04d5f42a5a24bd467a9569e01","value":807}},"5f1fb4d40e154e27baa0d4f330df540e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e750769d364ab2b80d5b9646b10ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"634935ff0a6b4d65b72f87359d9f82fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4de75777bba4d72b61936baf3d84cbb","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0481743e80634f7a8e718fb528950e54","value":807}},"6f5ca39406174a4fb1bee9eb1e35fccb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70c7b641da5c4b82bbd5b2e1750f3b39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851b29291123491a821b1ce8088ca785":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88be535ce5a945f4979fe72d9f086365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8382d8bbb7f42f6a0f4d4028203615f","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_851b29291123491a821b1ce8088ca785","value":807}},"8b35a70a3b9e4f3b87cf2a7280439ac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"948787e6434f419a86d9d7da831e2572":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ced4485d5c641eda90ab0634e0691d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f5e5843559b4f9e8f3440ebd85743f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a317a54aa1a349f490e388aacb2d1e4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c470a61e692a4459988f63f0024f7eac","IPY_MODEL_5edd903b07594d128ded9b4844835159","IPY_MODEL_2ac0cceac38e43adb00a10b778fad2df"],"layout":"IPY_MODEL_c7f61bdee3ca4ca0a3f7d021aa558deb"}},"a51aa7b827db4f768dce6315dbebf379":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f1fb4d40e154e27baa0d4f330df540e","placeholder":"​","style":"IPY_MODEL_948787e6434f419a86d9d7da831e2572","value":"100%"}},"acee2c1ed91e44188d5ca40bddace4b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c470a61e692a4459988f63f0024f7eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c7b641da5c4b82bbd5b2e1750f3b39","placeholder":"​","style":"IPY_MODEL_462d9e93a94f44868fec1ece82f0a241","value":"100%"}},"c7f61bdee3ca4ca0a3f7d021aa558deb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cc57eeb92d32434ca82b7c3f669865d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3bc58d04d5f42a5a24bd467a9569e01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d95aea2b915b44f38b5090ee186abafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc4a8a3b0a8b4ef49dcd6269a1b32e14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ddb1791795134ac0a754748f9793c214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd9dd713862479bba73b6c0a12a1902":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acee2c1ed91e44188d5ca40bddace4b1","placeholder":"​","style":"IPY_MODEL_cc57eeb92d32434ca82b7c3f669865d1","value":"100%"}},"e4de75777bba4d72b61936baf3d84cbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8093c8ddeec4c55ac6cc5f8f7df30bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8382d8bbb7f42f6a0f4d4028203615f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9ec11073e484927a4cc1ee2e3da132f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ced4485d5c641eda90ab0634e0691d3","placeholder":"​","style":"IPY_MODEL_6f5ca39406174a4fb1bee9eb1e35fccb","value":" 3/3 [13:53&lt;00:00, 275.36s/it]"}}}}},"nbformat":4,"nbformat_minor":0}
